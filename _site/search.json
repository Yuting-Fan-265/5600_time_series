[
  {
    "objectID": "data.html#github-repository",
    "href": "data.html#github-repository",
    "title": "Data",
    "section": "",
    "text": "Please refer to the GitHub Repository / Data that contains the code used in this analysis."
  },
  {
    "objectID": "data.html#file-structure",
    "href": "data.html#file-structure",
    "title": "Data",
    "section": "File Structure",
    "text": "File Structure"
  },
  {
    "objectID": "univariate_ts_model.html",
    "href": "univariate_ts_model.html",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "",
    "text": "Code\ncanada &lt;- read.csv(\"data/clean_data/24monthly_canada_freight.csv\")\ncanada &lt;- canada[,c(\"Date\",\"Value\")]\ncanada_ts &lt;- ts(canada$Value, start = decimal_date(as.Date(\"2006-01-01\", format = \"%Y-%m-%d\")), end = decimal_date(as.Date(\"2023-01-01\", format = \"%Y-%m-%d\")), frequency = 12)\n\n\nemployment &lt;- read.csv(\"data/clean_data/32monthly_employment.csv\")\nemployment &lt;- employment[,c(\"Date\",\"Transportation.Employment...Air.Transportation\")]\nemployment_ts &lt;- ts(employment$Transportation.Employment...Air.Transportation, start = decimal_date(as.Date(\"2005-01-01\", format = \"%Y-%m-%d\")), end = decimal_date(as.Date(\"2024-01-01\", format = \"%Y-%m-%d\")), frequency = 12)\n\n\ntsi &lt;- read.csv(\"data/clean_data/35monthly_TSI.csv\")\ntsi_ts &lt;- ts(tsi$Transportation.Services.Index...Freight, start = decimal_date(as.Date(\"2000-01-01\", format = \"%Y-%m-%d\")), end = decimal_date(as.Date(\"2023-01-01\", format = \"%Y-%m-%d\")), frequency = 12)\n\n\nair &lt;- read.csv(\"data/clean_data/33revenue.csv\")\nair &lt;- air[air$Mode==\"Air carrier, domestic\",c(\"Year\",\"Value\")]\nair &lt;- air[order(air$Year), ]\nair_ts &lt;- ts(air$Value, start = decimal_date(as.Date(\"2000-01-01\", format = \"%Y-%m-%d\")), end = decimal_date(as.Date(\"2021-01-01\", format = \"%Y-%m-%d\")), frequency = 1)\n\n\nups &lt;- getSymbols(\"UPS\",auto.assign = FALSE, from = \"2017-01-01\", to = \"2024-01-01\",src=\"yahoo\") \nups=data.frame(ups)\nups &lt;- data.frame(ups,rownames(ups))\ncolnames(ups)[7] = \"date\"\nups$date&lt;-as.Date(ups$date,\"%Y-%m-%d\")\nups_ts &lt;- ts(ups$UPS.Adjusted, start = decimal_date(as.Date(\"2017-01-03\", format = \"%Y-%m-%d\")), frequency = 365.25)"
  },
  {
    "objectID": "other.html",
    "href": "other.html",
    "title": "Other: Interrupted TS/ARFIMA/ Spectral Analysis",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "introduction.html",
    "href": "introduction.html",
    "title": "Introduction",
    "section": "",
    "text": "Over the past few years, the freight transportation landscape in the United States has undergone significant changes, driven by various factors such as globalization, rapid technological advancements, and evolving consumer demands. These dynamic shifts have fundamentally altered the fundamentals of the freight transportation industry, making it crucial to conduct a comprehensive exploration through the lens of time series data.\nThis analysis aims to unravel the intricacies of the industry’s evolution by considering the temporal dimensions that contribute to its multifaceted nature. To achieve this, advanced time series analysis techniques will be employed to uncover underlying patterns, trends, and pivotal moments that have shaped its trajectory. This in-depth analysis will provide a detailed understanding of the industry’s historical development and its current state, enabling stakeholders to make informed decisions for the future.\n\n\n\nThis exploration focuses on unraveling the temporal evolution of the freight trasportation industry across multiple sectors, utilizing comprehensive time series data. The first sector analyzes domestic freight movement, considering changes in values and weights of shipments across different transportation modes within the United States. The second sector takes a global perspective, focusing on the temporal dynamics of U.S. international freight trade. The third sector examines the industry’s contribution to the U.S. economy over time, analyzing the long-term trend in the freight industry’s impact on the nation’s GDP and employment dynamics. The fourth sector delves into the stock performance of key industry players during economic downturns, aiming to shed light on the adaptability and resilience of the U.S. freight transportation industry in challenging economic landscapes.\n\n\n\n\nExtensive research has been conducted by scholars and researchers to understand the evolution of the freight transportation industry and identify challenges and opportunities. The literature review encompasses several sources of information related to this industry.\n1. Overview of U.S. Freight Transportation Trends:\nReports from the U.S. Department of Transportation (DOT) provide comprehensive insights into the state of U.S. freight transportation.\nA study by the Bureau of Transportation Statistics (BTS) provides an overview of recent trends in U.S. freight transportation. It highlights the growth in freight movement, modal shares, and the impact of economic factors on the industry.\nAmerican Transportation Research Institute (ATRI) produces research reports on various aspects of freight transportation, including congestion analysis, infrastructure challenges, and industry trends.\n2. Impact of E-commerce on Freight Transportation:\nWith the rise of e-commerce, several research papers discuss the transformational impact on freight transportation. The increased demand for last-mile delivery and changes in supply chain strategies have implications for freight movement patterns. (Wang and Zhou 2015)\n3. Sustainability and Green Freight Initiatives:\nScholars have explored the environmental sustainability of freight transportation. The focus is on reducing emissions, improving fuel efficiency, and adopting green technologies. Government policies and industry initiatives are discussed in the context of sustainable freight.(Horvath 2006)\n4. Resilience and Adaptation in Freight Networks:\nGiven disruptions like the COVID-19 pandemic, studies explore the resilience and adaptive capacity of U.S. freight networks. This includes the ability of the system to cope with unexpected shocks and disturbances. (Bhattacharjee et al. 2020)\n5. Future Trends and Scenarios:\nScholars and experts provide insights into future trends and potential scenarios for U.S. freight transportation. This involves projections related to technology adoption, infrastructure development, and changing market dynamics. (Southworth 2018)\n\n\n\nThis exploration is designed to provide a comprehensive and nuanced understanding of the U.S. freight transportation industry’s dynamics. By addressing these key questions, I seek to contribute to a holistic perspective on how the industry has evolved and adapted to various economic and global shifts in recent years.\n\n\nIn this sector, I delve into the changes in shipments over time, scrutinizing the values and weights across diverse freight transportation modes. Additionally, I will analyze the overall trend in freight volume, considering shifts in distance, to provide a comprehensive understanding of how goods move within the United States.\n\n\n\nThe international dimension of freight trade is investigated in this sector. I want to assess how the value of international freight trade in the U.S. has evolved across different transportation modes. Furthermore, explore regional and modal variations in international freight flows, unraveling patterns that shape the global interconnectedness of the U.S. freight industry.\n\n\n\nThis sector focuses on the industry’s contributions to the U.S. economy. I will examine the long-term trend in the U.S. Freight Industry’s contribution to the nation’s GDP, providing insights into its economic significance. Additionally, scrutinize the employment dynamics within the transportation sector, track the average revenue generated from freight services, and explore the impact of fuel price fluctuations on overall revenue. The U.S. Transportation Services Index is investigated to understand how it reflects changes in freight movement patterns over time.\n\n\n\nThe final sector delves into the stock performance of the industry’s major players during economic recessions, particularly those triggered by the recent global pandemic. By analyzing how these vital stocks responded to challenging economic periods, I aim to gain valuable insights into the industry’s resilience and adaptability.\n\n\n\n\n\n\nShipment Changes Over Time:\n\nHow have the values and weights of shipments evolved across various freight transportation modes in the U.S. over recent years?\n\nTotal Freight Movement:\n\nWhat is the overall freight volume trend in the U.S. when considering changes in distance over the past several years?\n\nInternational Freight Trade:\n\nHow has the value of international freight trade in the U.S. shifted, categorized by different freight transportation modes, over the past several years?\n\nRegional and Modal Changes in International Freight:\n\nWhat are the patterns in the value of U.S. international freight flows concerning both regions and transportation modes over the past several years?\n\nLong-Term Industry Contribution:\n\nWhat is the long-term trend in the contribution of the U.S. Freight Industry to the nation’s GDP over the years?\n\nEmployment Dynamics:\n\nHow does the employment landscape within the U.S. transportation sector change over time?\n\nAverage Freight Revenue:\n\nHow does the average revenue generated from freight services in the U.S. evolve over time?\n\nFuel Price Impact on Freight Revenue:\n\nTo what extent do fluctuations in diesel and jet fuel prices influence the overall freight revenue in the U.S. over time?\n\nTransportation Services Index:\n\nHow does the U.S. Transportation Services Index reflect changes in freight movement patterns over time?\n\nStock Performance During Recessions:\n\nHow did the stock of the most crucial industry players respond to economic recessions triggered by the pandemic?"
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "Conclusions",
    "section": "",
    "text": "Abstract\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "deep_learning_ts.html",
    "href": "deep_learning_ts.html",
    "title": "Deep Learning for TS",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "code.html#github-repository",
    "href": "code.html#github-repository",
    "title": "Code",
    "section": "",
    "text": "Please refer to the GitHub Repository / Code that contains the code used in this analysis."
  },
  {
    "objectID": "code.html#file-structure",
    "href": "code.html#file-structure",
    "title": "Code",
    "section": "File Structure",
    "text": "File Structure"
  },
  {
    "objectID": "financial_ts_model.html",
    "href": "financial_ts_model.html",
    "title": "Financial Time Series Models (ARCH/GARCH)",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "data_visualization.html",
    "href": "data_visualization.html",
    "title": "Data Visualization",
    "section": "",
    "text": "To gain a comprehensive understanding of the dataset, I will utilize various visualization techniques to explore the data extracted from the sources listed in the data sources tab. By creating different types of visualizations, I aim to uncover patterns, trends, and relationships within the dataset, facilitating a deeper understanding of its underlying structure and characteristics."
  },
  {
    "objectID": "eda.html",
    "href": "eda.html",
    "title": "Exploratory Data Analysis",
    "section": "",
    "text": "Conducting exploratory data analysis (EDA) forms the bedrock of data analysis practices. Through EDA, analysts delve into the intricate dynamics of their data, unraveling hidden patterns, trends, and anomalies. By identifying the underlying components and understanding their nature—be it multiplicative or additive—insights are gained into the fundamental structure of the data.\nLag plots and auto-correlation visualizations shed light on temporal dependencies, helping to uncover relationships between observations at different time points. Testing for stationarity aids in assessing the stability of statistical properties over time, a critical consideration in time series analysis.\nFurthermore, employing differencing and detrending methodologies enables analysts to mitigate trends and achieve stationarity, facilitating more accurate modeling and forecasting."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Time Series",
    "section": "",
    "text": "What is a Time Series ?\n\nAny metric that is measured over regular time intervals makes a Time Series. A time series is a sequence of data points or observations collected or recorded over a period of time at specific, equally spaced intervals. Each data point in a time series is associated with a particular timestamp or time period, making it possible to analyze and study how a particular variable or phenomenon changes over time. Time series data can be found in various domains and can represent a wide range of phenomena, including financial data, economic indicators, weather measurements, stock prices, sales figures, and more.\n\nExample: Weather data, Stock prices, Industry forecasts, etc are some of the common ones.\n\nThe analysis of experimental data that have been observed at different points in time leads to new and unique problems in statistical modeling and inference.\nThe obvious correlation introduced by the sampling of adjacent points in time can severely restrict the applicability of the many conventional statistical methods traditionally dependent on the assumption that these adjacent observations are independent and identically distributed.\n\nKey characteristics of time series data include:\nTemporal Order: Time series data is ordered chronologically, with each data point representing an observation at a specific point in time. The order of data points is critical for understanding trends and patterns over time.\nEqually Spaced Intervals: In most cases, time series data is collected at regular intervals, such as hourly, daily, weekly, monthly, or yearly. However, irregularly spaced time series data can also exist.\nDependency: Time series data often exhibits temporal dependency, meaning that the value at a given time is influenced by or related to the values at previous times. This dependency can take various forms, including trends, seasonality. This serial correlation is called as autocorrelation.\nComponents: Time series data can typically be decomposed into various components, including:\nTrend: The long-term movement or direction in the data. Seasonality: Repeating patterns or cycles that occur at fixed intervals. Noise/Irregularity: Random fluctuations or variability in the data that cannot be attributed to the trend or seasonality.\nApplications: Time series data is widely used for various applications, including forecasting future values, identifying patterns and anomalies, understanding underlying trends, and making informed decisions based on historical data.\nAnalyzing time series data involves techniques like time series decomposition, smoothing, statistical modeling, and forecasting. This class will cover but not be limited to traditional time series modeling including ARIMA, SARIMA, the multivariate Time Series modeling including; ARIMAX, SARIMAX, and VAR models, Financial Time Series modeling including; ARCH, GARCH models, and E-GARCH, M-GARCH..ect, Bayesian structural time series (BSTS) models, Spectral Analysis and Deep Learning Techniques for Time Series. Researchers and analysts use software tools like Python, R, and specialized time series libraries to work with and analyze time series data effectively.\nTime series analysis is essential in fields such as finance, economics, epidemiology, environmental science, engineering, and many others, as it provides insights into how variables change over time and allows for the development of predictive models to forecast future trends and outcomes.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n\n\n Back to top"
  },
  {
    "objectID": "author.html",
    "href": "author.html",
    "title": "Author",
    "section": "",
    "text": "Yuting Fan comes from Guangzhou, a southern city of China. She received a Master of Public Administration from South China University of Technology, and a Bachelor of Management Science in Public Relations from Sun Yat-sen University. She used to be a Senior Project Manager at Sun Yat-sen University. Her main responsibility was to liaise with various medical professors and organize Continuing Medical Education programs for hospitals across the country in China.\n\n\n\n\n\n\nEducation\n\n2023-2025: Master of Science in Data Science and Analytics, Georgetown University\n2017: Master of Public Administration, South China University of Technology\n2009: Bachelor of Management Science in Public Relations, Sun Yat-sen University\n\n\n\n\nAcademic Interests\n\nDatabase Systems and SQL\nDigital Storytelling\nNatural Language Processing\nImage Mining and Computer Vision Analytics\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "multivariate_ts_model.html",
    "href": "multivariate_ts_model.html",
    "title": "Multivariate TS Models (ARIMAX/SARIMAX/VAR)",
    "section": "",
    "text": "U.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexU.S. Domestic Air Carrier Average Freight RevenueUPS Stock Price\n\n\n\n\nCode\n#canada_ts\n\n\n\n\n\n\nCode\n#employment_ts\n\n\n\n\n\n\nCode\n#tsi_ts\n\n\n\n\n\n\nCode\n#air_ts\n\n\n\n\n\n\nCode\n#ups_ts\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "data_sources.html",
    "href": "data_sources.html",
    "title": "Data Sources",
    "section": "",
    "text": "The U.S. Bureau of Transportation Statistics (BTS) is a prominent agency within the United States Department of Transportation. Established to provide comprehensive and objective transportation statistics, the BTS plays a crucial role in collecting, analyzing, and disseminating data related to various modes of transportation. This includes air, water, rail, and road transport, as well as aspects like freight movement, passenger travel, and economic indicators within the transportation sector. By offering reliable and up-to-date information, the BTS serves as a valuable resource for policymakers, researchers, and the general public, contributing to informed decision-making and a deeper understanding of the nation’s transportation landscape. You can access this data at website.\nSource download data\n\n\n\n\n\n\nCode\ndf1 &lt;- read.csv(\"data/clean_data/11value_us.csv\")\n#df1$Year &lt;- as.Date(ISOdate(df1$Year, 1, 1))\nhead(df1)\n\n\n                         Mode              Measure.Names Year Trade.Type\n1           Other and Unknown Value (billions of 2017 $) 2017     Import\n2                    Pipeline Value (billions of 2017 $) 2017     Import\n3 Multiple Dms Modes and Mail Value (billions of 2017 $) 2017     Import\n4    Air (includes truck-air) Value (billions of 2017 $) 2017     Import\n5                       Water Value (billions of 2017 $) 2017     Import\n6                        Rail Value (billions of 2017 $) 2017     Import\n  Measure.Values\n1       11.84428\n2       63.44107\n3     1037.25672\n4      571.16543\n5      120.53570\n6      113.05147\n\n\n\n\n\n\n\nCode\ndf2 &lt;- read.csv(\"data/clean_data/12weight_us.csv\")\nhead(df2)\n\n\n  Trade.Type                        Mode Year   Measure.Names Measure.Values\n1   Domestic    Air (includes truck-air) 2021 Tons (millions)       2.062421\n2   Domestic    Air (includes truck-air) 2020 Tons (millions)       2.049576\n3   Domestic    Air (includes truck-air) 2019 Tons (millions)       2.126921\n4   Domestic    Air (includes truck-air) 2018 Tons (millions)       2.162104\n5   Domestic    Air (includes truck-air) 2017 Tons (millions)       2.136208\n6   Domestic Multiple Dms Modes and Mail 2021 Tons (millions)     507.931713\n\n\n\n\n\n\n\nCode\ndf3 &lt;- read.csv(\"data/clean_data/13distance_us.csv\")\nhead(df3)\n\n\n  Year Distance.band..miles.                                  Measure.Names\n1 2017            Over 2,000 % of Total Running Sum of ton-miles (millions)\n2 2017         1,500 - 2,000 % of Total Running Sum of ton-miles (millions)\n3 2017         1,000 - 1,499 % of Total Running Sum of ton-miles (millions)\n4 2017             750 - 999 % of Total Running Sum of ton-miles (millions)\n5 2017             500 - 749 % of Total Running Sum of ton-miles (millions)\n6 2017             250 - 499 % of Total Running Sum of ton-miles (millions)\n  Measure.Values\n1      1.0000000\n2      0.8880109\n3      0.8020772\n4      0.6103572\n5      0.5091046\n6      0.4247276\n\n\n\n\n\n\n\n\n\n\nCode\ndf4 &lt;- read.csv(\"data/clean_data/21international_value.csv\")\nhead(df4)\n\n\n  Year             Mode                  Measure  Trade.Type      Value\n1 2017            Water Billions of U.S. Dollars Total trade 1601.74488\n2 2017            Truck Billions of U.S. Dollars Total trade  720.82734\n3 2017 Total, all modes Billions of U.S. Dollars Total trade 3886.78673\n4 2017             Rail Billions of U.S. Dollars Total trade  174.14326\n5 2017         Pipeline Billions of U.S. Dollars Total trade   65.24362\n6 2017    Other/unknown Billions of U.S. Dollars Total trade  256.06434\n\n\n\n\n\n\n\nCode\ndf5 &lt;- read.csv(\"data/clean_data/22international_Region.csv\")\nhead(df5)\n\n\n  Mode Year                                      Measure Region  Value\n1  Air 2022 Value of freight flows (millions of dollars)  Other 105226\n2  Air 2021 Value of freight flows (millions of dollars)  Other  98610\n3  Air 2020 Value of freight flows (millions of dollars)  Other  80459\n4  Air 2019 Value of freight flows (millions of dollars)  Other  93690\n5  Air 2018 Value of freight flows (millions of dollars)  Other  91088\n6  Air 2017 Value of freight flows (millions of dollars)  Other  88959\n\n\n\n\n\n\n\n\n\n\nCode\ndf6 &lt;- read.csv(\"data/clean_data/31GDP.csv\")\nhead(df6)\n\n\n  Year                         Mode      Type Current....billions.\n1 2021                    Household Household               411.48\n2 2021                     Pipeline Household                   NA\n3 2021 Transit and ground passenger Household                   NA\n4 2021                        Water Household                   NA\n5 2021                         Rail Household                   NA\n6 2021                          Air Household                   NA\n\n\n\n\n\n\n\nCode\ndf7 &lt;- read.csv(\"data/clean_data/32monthly_employment.csv\")\nhead(df7)\n\n\n                    Date Transportation.Employment...Pipeline.Transportation\n1 01/01/2005 12:00:00 AM                                               38100\n2 02/01/2005 12:00:00 AM                                               37700\n3 03/01/2005 12:00:00 AM                                               37600\n4 04/01/2005 12:00:00 AM                                               37800\n5 05/01/2005 12:00:00 AM                                               37500\n6 06/01/2005 12:00:00 AM                                               37800\n  Transportation.Employment...Water.Transportation\n1                                            55500\n2                                            55100\n3                                            56700\n4                                            59400\n5                                            61100\n6                                            62600\n  Transportation.Employment...Rail.Transportation\n1                                          191000\n2                                          191400\n3                                          191900\n4                                          193300\n5                                          193900\n6                                          193900\n  Transportation.Employment...Air.Transportation\n1                                         505200\n2                                         503400\n3                                         504200\n4                                         507300\n5                                         507800\n6                                         508300\n  Transportation.Employment...Transit.and.ground.passenger.transportation\n1                                                                  407900\n2                                                                  407700\n3                                                                  409200\n4                                                                  413700\n5                                                                  415300\n6                                                                  383900\n  Transportation.Employment...Truck.Transportation\n1                                          1348500\n2                                          1349000\n3                                          1359900\n4                                          1377300\n5                                          1391700\n6                                          1418900\n\n\n\n\n\n\n\nCode\ndf8 &lt;- read.csv(\"data/clean_data/33revenue.csv\")\nhead(df8)\n\n\n                                       Measure                  Mode Year\n1 Freight revenue per ton-mile (current cents) Air carrier, domestic 2021\n2 Freight revenue per ton-mile (current cents) Air carrier, domestic 2020\n3 Freight revenue per ton-mile (current cents) Air carrier, domestic 2019\n4 Freight revenue per ton-mile (current cents) Air carrier, domestic 2018\n5 Freight revenue per ton-mile (current cents) Air carrier, domestic 2017\n6 Freight revenue per ton-mile (current cents) Air carrier, domestic 2016\n     Value\n1  97.8600\n2 122.9800\n3 137.6700\n4 137.4876\n5 125.1505\n6 119.8993\n\n\n\n\n\n\n\nCode\ndf9 &lt;- read.csv(\"data/clean_data/34monthly_fuel_prices.csv\")\nhead(df9)\n\n\n  Month.of.Date  Diesel Jet.Fuel\n1  January 2000 $135.60   $78.10\n2 February 2000 $146.10   $78.00\n3    March 2000 $147.90   $77.10\n4    April 2000 $142.20   $71.90\n5      May 2000 $142.00   $76.20\n6     June 2000 $142.10   $78.50\n\n\n\n\n\n\n\nCode\ndf10 &lt;- read.csv(\"data/clean_data/35monthly_TSI.csv\")\nhead(df10)\n\n\n                    Date Transportation.Services.Index...Freight\n1 01/01/2000 12:00:00 AM                                   105.1\n2 02/01/2000 12:00:00 AM                                   103.3\n3 03/01/2000 12:00:00 AM                                    99.7\n4 04/01/2000 12:00:00 AM                                    97.9\n5 05/01/2000 12:00:00 AM                                    98.8\n6 06/01/2000 12:00:00 AM                                    99.7"
  },
  {
    "objectID": "data.html",
    "href": "data.html",
    "title": "Data",
    "section": "",
    "text": "Please refer to the GitHub Repository / Data that contains the code used in this analysis."
  },
  {
    "objectID": "code.html",
    "href": "code.html",
    "title": "Code",
    "section": "",
    "text": "Please refer to the GitHub Repository / Code that contains the code used in this analysis."
  },
  {
    "objectID": "dv.html",
    "href": "dv.html",
    "title": "Time Series Data Visualization",
    "section": "",
    "text": "Importing Libraries\nlibrary(tidyverse)\nlibrary(ggplot2)\nlibrary(forecast)\nlibrary(astsa) \nlibrary(xts)\nlibrary(tseries)\nlibrary(fpp2)\nlibrary(fma)\nlibrary(lubridate)\nlibrary(tidyverse)\nlibrary(TSstudio)\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(plotly)\nlibrary(ggplot2)\nlibrary(imputeTS)\nlibrary(gridExtra)\nlibrary(reticulate)\nlibrary(readxl)\n#use_python(\"/usr/local/bin/python3\", require = T)\n#knitr::knit_engines$set(python = reticulate::eng_python)\n#py_install(\"tensorflow\")\n\n\n\nTime Series Data Visualization\nIn time series data visualization, the importance lies in presenting temporal patterns and trends in a clear and comprehensible manner. Effective visualization allows analysts and decision-makers to extract meaningful insights from the data, aiding in better understanding the dynamics of a system over time. The choice of visualization techniques is crucial, as it directly influences the interpretation of patterns within the time series.\nThe ability to discern seasonality, identify anomalies, and recognize patterns is vital for making informed predictions and strategic decisions. Furthermore, interactive features in visualizations enable users to delve deeper into the data, offering a dynamic and exploratory experience.\nUltimately, the clarity and accuracy of time series data visualization contribute significantly to enhancing decision-making processes across various domains, such as finance, healthcare, environmental monitoring and many other areas.\n\nData Visualization with Stock DataInteractive PlotLitecoin plot using plotlycandlestick plotState annual personal income plot using plotly\n\n\nThe following graph shows overall trends in United Airlines, Delta Airlines, American Airlines, Southwest Airlines and JetBlue Airways stock prices.\n\n\nCode\noptions(\"getSymbols.warning4.0\"=FALSE)\noptions(\"getSymbols.yahoo.warning\"=FALSE)\n\ntickers = c(\"UAL\",\"DAL\", \"AAL\",\"LUV\", \"JBLU\" )\nfor (i in tickers){\n  getSymbols(i,\n             from = \"2012-10-01\",\n             to = \"2024-01-01\")}\n\nx &lt;- list(\n  title = \"date\"\n)\ny &lt;- list(\n  title = \"value\"\n)\n\nstock &lt;- data.frame(UAL$UAL.Adjusted,\n                    DAL$DAL.Adjusted,\n                    AAL$AAL.Adjusted,\n                    LUV$LUV.Adjusted,\n                    JBLU$JBLU.Adjusted)\n\n\nstock &lt;- data.frame(stock,rownames(stock))\ncolnames(stock) &lt;- append(tickers,'Dates')\n\nstock$date&lt;-as.Date(stock$Dates,\"%Y-%m-%d\")\nhead(stock)\n\n\n             UAL      DAL      AAL      LUV JBLU      Dates       date\n2012-10-01 19.79 8.370638 10.13447 8.041387 4.87 2012-10-01 2012-10-01\n2012-10-02 19.94 8.635812 10.25703 8.150298 4.98 2012-10-02 2012-10-02\n2012-10-03 21.14 8.980537 11.10549 8.295518 5.13 2012-10-03 2012-10-03\n2012-10-04 20.81 8.962860 11.00179 8.259212 5.14 2012-10-04 2012-10-04\n2012-10-05 21.07 9.086608 10.99236 8.141223 5.15 2012-10-05 2012-10-05\n2012-10-08 20.90 8.954021 10.90752 8.041387 5.09 2012-10-08 2012-10-08\n\n\nCode\n################################################\n\nggplot(stock, aes(x=date)) +\n  geom_line(aes(y=UAL, colour=\"UAL\"))+\n  geom_line(aes(y=DAL, colour=\"DAL\"))+\n  geom_line(aes(y=AAL, colour=\"AAL\"))+\n  geom_line(aes(y=LUV, colour=\"LUV\"))+\n  geom_line(aes(y=JBLU, colour=\"JBLU\"))+\n   labs(\n    title = \"Stock Prices for the Airline Companies\",\n    subtitle = \"From 2012-2023\",\n    x = \"Date\",\n    y = \"Adjusted Closing Prices\")+\n    theme(panel.background = element_rect(fill = \"white\", colour = \"grey50\"))+\n    guides(colour=guide_legend(title=\"Airline Companies\")) \n\n\n\n\n\nThe plot displays the adjusted closing prices of five airline companies (UAL, DAL, AAL, LUV, JBLU) over the period from October 1, 2012, to January 1, 2024. Each line represents one airline company, and the colors are used to distinguish between them. Investors and analysts can visually compare the stock performance of these companies over the specified time frame. Observing trends, patterns, or divergences in the lines may provide insights into the relative performance of these airline stocks.\n\n\nHover over the plot to see the difference.\n\n\nCode\ng4&lt;- ggplot(stock, aes(x=date)) +\n  geom_line(aes(y=UAL, colour=\"UAL\"))+\n  geom_line(aes(y=DAL, colour=\"DAL\"))+\n  geom_line(aes(y=AAL, colour=\"AAL\"))+\n  geom_line(aes(y=LUV, colour=\"LUV\"))+\n  geom_line(aes(y=JBLU, colour=\"JBLU\"))+\n   labs(\n    title = \"Stock Prices for the Airline Companies\",\n    subtitle = \"From 2012-2023\",\n    x = \"Date\",\n    y = \"Adjusted Closing Prices\")+\n    guides(colour=guide_legend(title=\"Airline Companies\")) \n\n\nggplotly(g4) %&gt;%\n  layout(hovermode = \"x\")\n\n\n\n\n\n\nThe interactive plot displays the adjusted closing prices of five major airline companies (UAL, DAL, AAL, LUV, JBLU) over the period from 2012 to 2023. Each colored line corresponds to one airline company. Users can hover over the plot to view specific data points for each date. This facilitates a more detailed analysis of relative stock performance.\n\n\nOR you can obtain a single stock price\n\n\nCode\nlitc &lt;- getSymbols(\"LTC\",auto.assign = FALSE, from = \"2021-09-15\",src=\"yahoo\") \nhead(litc)\n\n\n           LTC.Open LTC.High LTC.Low LTC.Close LTC.Volume LTC.Adjusted\n2021-09-15    33.57    33.81   33.19     33.23     270800     28.41918\n2021-09-16    33.23    33.80   33.13     33.47     259100     28.62444\n2021-09-17    33.50    33.59   33.09     33.36     665200     28.53036\n2021-09-20    33.00    33.52   32.90     33.28     263600     28.46194\n2021-09-21    33.24    33.37   32.72     32.72     220700     28.14369\n2021-09-22    32.89    33.13   32.55     32.56     228500     28.00607\n\n\nCode\nstart(litc)\n\n\n[1] \"2021-09-15\"\n\n\nCode\nend(litc)\n\n\n[1] \"2024-02-14\"\n\n\nCode\nlitc=data.frame(litc)\nlitc &lt;- data.frame(litc,rownames(litc))\nhead(litc)\n\n\n           LTC.Open LTC.High LTC.Low LTC.Close LTC.Volume LTC.Adjusted\n2021-09-15    33.57    33.81   33.19     33.23     270800     28.41918\n2021-09-16    33.23    33.80   33.13     33.47     259100     28.62444\n2021-09-17    33.50    33.59   33.09     33.36     665200     28.53036\n2021-09-20    33.00    33.52   32.90     33.28     263600     28.46194\n2021-09-21    33.24    33.37   32.72     32.72     220700     28.14369\n2021-09-22    32.89    33.13   32.55     32.56     228500     28.00607\n           rownames.litc.\n2021-09-15     2021-09-15\n2021-09-16     2021-09-16\n2021-09-17     2021-09-17\n2021-09-20     2021-09-20\n2021-09-21     2021-09-21\n2021-09-22     2021-09-22\n\n\nCode\ncolnames(litc)[7] = \"date\"\nhead(litc)\n\n\n           LTC.Open LTC.High LTC.Low LTC.Close LTC.Volume LTC.Adjusted\n2021-09-15    33.57    33.81   33.19     33.23     270800     28.41918\n2021-09-16    33.23    33.80   33.13     33.47     259100     28.62444\n2021-09-17    33.50    33.59   33.09     33.36     665200     28.53036\n2021-09-20    33.00    33.52   32.90     33.28     263600     28.46194\n2021-09-21    33.24    33.37   32.72     32.72     220700     28.14369\n2021-09-22    32.89    33.13   32.55     32.56     228500     28.00607\n                 date\n2021-09-15 2021-09-15\n2021-09-16 2021-09-16\n2021-09-17 2021-09-17\n2021-09-20 2021-09-20\n2021-09-21 2021-09-21\n2021-09-22 2021-09-22\n\n\nCode\nlitc$date&lt;-as.Date(litc$date,\"%Y-%m-%d\")\nstr(litc)\n\n\n'data.frame':   608 obs. of  7 variables:\n $ LTC.Open    : num  33.6 33.2 33.5 33 33.2 ...\n $ LTC.High    : num  33.8 33.8 33.6 33.5 33.4 ...\n $ LTC.Low     : num  33.2 33.1 33.1 32.9 32.7 ...\n $ LTC.Close   : num  33.2 33.5 33.4 33.3 32.7 ...\n $ LTC.Volume  : num  270800 259100 665200 263600 220700 ...\n $ LTC.Adjusted: num  28.4 28.6 28.5 28.5 28.1 ...\n $ date        : Date, format: \"2021-09-15\" \"2021-09-16\" ...\n\n\nCode\n## ggplot\nlitc %&gt;%\n  ggplot()+\n  geom_line(aes(y=LTC.Adjusted,x=date),color=\"blue\")\n\n\n\n\n\nCode\n## plotly\nfig &lt;- plot_ly(litc, x = ~date, y = ~LTC.Adjusted, type = 'scatter', mode = 'lines')\n\nfig &lt;- fig %&gt;% layout(title = \"Basic line Plot\")\nfig\n\n\n\n\n\n\nThe ggplot line plot illustrates the adjusted closing prices of Litecoin (LTC) over the specified time period, ranging from September 15, 2021, to the latest available date. The x-axis represents the date, while the blue line depicts the trend in LTC’s adjusted closing prices. Investors can visually assess how the cryptocurrency’s value has changed over time, identifying trends, patterns, or fluctuations in LTC prices. Steep inclines or declines may indicate periods of higher volatility, potentially associated with significant market events or trading activities. Analysts may use the plot to identify potential support and resistance levels, aiding in making informed decisions about buying or selling LTC.\nThe plotly interactive scatter plot provides an engaging and exploratory visualization of Litecoin’s adjusted closing prices. Users can hover over data points to obtain detailed information about the date and corresponding adjusted closing price. This interactive feature facilitates precise data inspection, allowing users to identify trends or anomalies on specific dates. The plot offers zoom and pan capabilities, enabling users to focus on particular time periods or trends. Its high customizability allows users to tailor the visualization to their preferences, making it a versatile tool for cryptocurrency market analysis.\n\n\n\n\nCode\n#plotly\n# candlestick plot\n\n\ndf &lt;- tail(litc, 30)\n\nfigc &lt;- df %&gt;% plot_ly(x = ~date, type=\"candlestick\",\n          open = ~LTC.Open, close = ~LTC.Close,\n          high = ~LTC.High, low = ~LTC.Low) \nfigc &lt;- figc %&gt;% layout(title = \"Basic Candlestick Chart\")\n\nfigc\n\n\n\n\n\n\nThe candlestick chart illustrates the recent 30-day price movements of Litecoin (LTC), providing a snapshot of daily opening, closing, high, and low prices. Each candlestick’s color indicates upward or downward price movement, while the thin lines above and below represent intraday highs and lows. Traders can discern trends and patterns, such as upward or downward trends, aiding in decision-making. The visualization serves as a powerful tool for technical analysis, offering insights into price action and potential trading signals.\n\n\n\n\nCode\nlibrary(tidyverse)\nlibrary(tidyquant)\nlibrary(plotly)\n\ndf1 &lt;- read.csv(\"data/DMVincome.csv\")\ncolnames(df1) &lt;- sub(\"X\", \"\", colnames(df1))\ndf1 &lt;- dplyr::select(df1, -1)\ndf2 &lt;- as.data.frame(t(df1))\ncolnames(df2) &lt;- c(\"DC\", \"MD\", \"VA\")\ndf2[\"Year\"] &lt;- 1997:2022\ndf2 &lt;- df2[-1, ]\n(head(df2))\n\n\n           DC       MD       VA Year\n1998  21514.7 163509.0 199883.6 1998\n1999  22625.2 173125.8 214025.7 1999\n2000  24827.6 188437.2 231869.8 2000\n2001  25742.9 198926.9 244314.3 2001\n2002  25863.4 206707.3 251357.7 2002\n2003  26138.6 215973.4 266325.2 2003\n\n\nCode\nfig &lt;- plot_ly(df2, type = 'scatter', mode = 'lines')%&gt;%\n  add_trace(x = ~Year, y = ~DC, name = 'DC')%&gt;%\n  add_trace(x = ~Year, y = ~MD, name = 'MD')%&gt;%\n  add_trace(x = ~Year, y = ~VA, name = 'VA')%&gt;%\n  layout(title = \"State annual personal income summary(Millions of current dollars)\",\n  yaxis = list(title = \"Total Annual Personal Income(Millions of current dollars)\"),\n  legend=list(title=list(text='State')))\n\nfig\n\n\n\n\n\n\nThe plot illustrates the annual personal income trends for Washington, D.C. (DC), Maryland (MD), and Virginia (VA) from 1998 to 2022. Each line represents the respective state’s income trajectory, providing a visual comparison over the specified time frame. Notably, D.C., Maryland, and Virginia exhibit distinctive patterns, allowing for insights into regional economic dynamics. The y-axis denotes the state total annual personal income, and the legend clarifies the association between each line and its corresponding state. This visualization offers a concise overview of the income trends across the three regions, aiding in the analysis of economic disparities or growth patterns.\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "introduction.html#literature-review",
    "href": "introduction.html#literature-review",
    "title": "Introduction",
    "section": "",
    "text": "Extensive research has been conducted by scholars and researchers to understand the evolution of the freight transportation industry and identify challenges and opportunities. The literature review encompasses several sources of information related to this industry.\n1. Overview of U.S. Freight Transportation Trends:\nReports from the U.S. Department of Transportation (DOT) provide comprehensive insights into the state of U.S. freight transportation.\nA study by the Bureau of Transportation Statistics (BTS) provides an overview of recent trends in U.S. freight transportation. It highlights the growth in freight movement, modal shares, and the impact of economic factors on the industry.\nAmerican Transportation Research Institute (ATRI) produces research reports on various aspects of freight transportation, including congestion analysis, infrastructure challenges, and industry trends.\n2. Impact of E-commerce on Freight Transportation:\nWith the rise of e-commerce, several research papers discuss the transformational impact on freight transportation. The increased demand for last-mile delivery and changes in supply chain strategies have implications for freight movement patterns. (Wang and Zhou 2015)\n3. Sustainability and Green Freight Initiatives:\nScholars have explored the environmental sustainability of freight transportation. The focus is on reducing emissions, improving fuel efficiency, and adopting green technologies. Government policies and industry initiatives are discussed in the context of sustainable freight.(Horvath 2006)\n4. Resilience and Adaptation in Freight Networks:\nGiven disruptions like the COVID-19 pandemic, studies explore the resilience and adaptive capacity of U.S. freight networks. This includes the ability of the system to cope with unexpected shocks and disturbances. (Bhattacharjee et al. 2020)\n5. Future Trends and Scenarios:\nScholars and experts provide insights into future trends and potential scenarios for U.S. freight transportation. This involves projections related to technology adoption, infrastructure development, and changing market dynamics. (Southworth 2018)"
  },
  {
    "objectID": "introduction.html#analytical-angles",
    "href": "introduction.html#analytical-angles",
    "title": "Introduction",
    "section": "",
    "text": "This exploration is designed to provide a comprehensive and nuanced understanding of the U.S. freight transportation industry’s dynamics. By addressing these key questions, I seek to contribute to a holistic perspective on how the industry has evolved and adapted to various economic and global shifts in recent years.\n\n\nIn this sector, I delve into the changes in shipments over time, scrutinizing the values and weights across diverse freight transportation modes. Additionally, I will analyze the overall trend in freight volume, considering shifts in distance, to provide a comprehensive understanding of how goods move within the United States.\n\n\n\nThe international dimension of freight trade is investigated in this sector. I want to assess how the value of international freight trade in the U.S. has evolved across different transportation modes. Furthermore, explore regional and modal variations in international freight flows, unraveling patterns that shape the global interconnectedness of the U.S. freight industry.\n\n\n\nThis sector focuses on the industry’s contributions to the U.S. economy. I will examine the long-term trend in the U.S. Freight Industry’s contribution to the nation’s GDP, providing insights into its economic significance. Additionally, scrutinize the employment dynamics within the transportation sector, track the average revenue generated from freight services, and explore the impact of fuel price fluctuations on overall revenue. The U.S. Transportation Services Index is investigated to understand how it reflects changes in freight movement patterns over time.\n\n\n\nThe final sector delves into the stock performance of the industry’s major players during economic recessions, particularly those triggered by the recent global pandemic. By analyzing how these vital stocks responded to challenging economic periods, I aim to gain valuable insights into the industry’s resilience and adaptability."
  },
  {
    "objectID": "introduction.html#guiding-question",
    "href": "introduction.html#guiding-question",
    "title": "Introduction",
    "section": "",
    "text": "Shipment Changes Over Time:\n\nHow have the values and weights of shipments evolved across various freight transportation modes in the U.S. over recent years?\n\nTotal Freight Movement:\n\nWhat is the overall freight volume trend in the U.S. when considering changes in distance over the past several years?\n\nInternational Freight Trade:\n\nHow has the value of international freight trade in the U.S. shifted, categorized by different freight transportation modes, over the past several years?\n\nRegional and Modal Changes in International Freight:\n\nWhat are the patterns in the value of U.S. international freight flows concerning both regions and transportation modes over the past several years?\n\nLong-Term Industry Contribution:\n\nWhat is the long-term trend in the contribution of the U.S. Freight Industry to the nation’s GDP over the years?\n\nEmployment Dynamics:\n\nHow does the employment landscape within the U.S. transportation sector change over time?\n\nAverage Freight Revenue:\n\nHow does the average revenue generated from freight services in the U.S. evolve over time?\n\nFuel Price Impact on Freight Revenue:\n\nTo what extent do fluctuations in diesel and jet fuel prices influence the overall freight revenue in the U.S. over time?\n\nTransportation Services Index:\n\nHow does the U.S. Transportation Services Index reflect changes in freight movement patterns over time?\n\nStock Performance During Recessions:\n\nHow did the stock of the most crucial industry players respond to economic recessions triggered by the pandemic?"
  },
  {
    "objectID": "data_sources.html#yahoo-stocks-data",
    "href": "data_sources.html#yahoo-stocks-data",
    "title": "Data Sources",
    "section": "Yahoo Stocks Data",
    "text": "Yahoo Stocks Data\nYahoo! Finance, a media property within the Yahoo! network, is a comprehensive platform offering financial news, data, commentary, stock quotes, press releases, financial reports, and original content. Not only does it furnish online tools for personal finance management, but it also publishes both partner content and original stories by its in-house journalists. Holding the 20th position in SimilarWeb’s major news and media websites ranking, Yahoo! Finance has been a prominent player in delivering financial information. In 2017, the platform expanded its coverage to include cryptocurrency news, providing insights into more than 9,000 unique coins, including popular ones like Bitcoin and Ethereum. website\n\nSource:\n\n\nCode\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(ggfortify)\noptions(\"getSymbols.warning4.0\"=FALSE)\noptions(\"getSymbols.yahoo.warning\"=FALSE)\n\ntickers = c(\"UPS\",\"UNP\",\"JBHT\",\"KEX\")\nfor (i in tickers){\n  getSymbols(i,\n             from = \"2017-01-01\",\n             to = \"2023-12-31\")}\n\nx &lt;- list(\n  title = \"date\"\n)\ny &lt;- list(\n  title = \"value\"\n)\n\nstock &lt;- data.frame(UPS$UPS.Adjusted,\n                    UNP$UNP.Adjusted,\n                    JBHT$JBHT.Adjusted,\n                    KEX$KEX.Adjusted\n                    )\n\n\nstock &lt;- data.frame(stock,rownames(stock))\ncolnames(stock) &lt;- append(tickers,'Dates')\n\nstock$date&lt;-as.Date(stock$Dates,\"%Y-%m-%d\")\n(head(stock))\n\n\n                UPS      UNP     JBHT   KEX      Dates       date\n2017-01-03 92.12064 87.95855 90.92937 66.25 2017-01-03 2017-01-03\n2017-01-04 92.14464 88.49049 91.91604 67.90 2017-01-04 2017-01-04\n2017-01-05 92.19269 87.62392 91.32407 68.00 2017-01-05 2017-01-05\n2017-01-06 92.37683 88.53337 91.79388 68.30 2017-01-06 2017-01-06\n2017-01-09 91.87249 87.87274 91.02337 65.45 2017-01-09 2017-01-09\n2017-01-10 91.19206 88.73072 91.82207 64.90 2017-01-10 2017-01-10"
  },
  {
    "objectID": "introduction.html#topic-explanation",
    "href": "introduction.html#topic-explanation",
    "title": "Introduction",
    "section": "",
    "text": "Over the past few years, the freight transportation landscape in the United States has undergone significant changes, driven by various factors such as globalization, rapid technological advancements, and evolving consumer demands. These dynamic shifts have fundamentally altered the fundamentals of the freight transportation industry, making it crucial to conduct a comprehensive exploration through the lens of time series data.\nThis analysis aims to unravel the intricacies of the industry’s evolution by considering the temporal dimensions that contribute to its multifaceted nature. To achieve this, advanced time series analysis techniques will be employed to uncover underlying patterns, trends, and pivotal moments that have shaped its trajectory. This in-depth analysis will provide a detailed understanding of the industry’s historical development and its current state, enabling stakeholders to make informed decisions for the future."
  },
  {
    "objectID": "introduction.html#big-picture",
    "href": "introduction.html#big-picture",
    "title": "Introduction",
    "section": "",
    "text": "This exploration focuses on unraveling the temporal evolution of the freight trasportation industry across multiple sectors, utilizing comprehensive time series data. The first sector analyzes domestic freight movement, considering changes in values and weights of shipments across different transportation modes within the United States. The second sector takes a global perspective, focusing on the temporal dynamics of U.S. international freight trade. The third sector examines the industry’s contribution to the U.S. economy over time, analyzing the long-term trend in the freight industry’s impact on the nation’s GDP and employment dynamics. The fourth sector delves into the stock performance of key industry players during economic downturns, aiming to shed light on the adaptability and resilience of the U.S. freight transportation industry in challenging economic landscapes."
  },
  {
    "objectID": "data_sources.html#world-health-organization-coronavirus-covid-19",
    "href": "data_sources.html#world-health-organization-coronavirus-covid-19",
    "title": "Data Sources",
    "section": "World Health Organization: Coronavirus (COVID-19)",
    "text": "World Health Organization: Coronavirus (COVID-19)\nThe COVID-19 dashboard by the World Health Organization (WHO) offers daily updates on official counts of COVID-19 cases, deaths, and vaccine utilization reported by various countries, territories, and areas. This interactive dashboard serves as a dynamic resource for data visualization, dissemination, and exploration, providing users with regularly updated information. Additionally, it facilitates access to other valuable and informative resources related to the COVID-19 pandemic.\nSource COVID-19 data\nCOVID-19 New Cases and Total Cases in the U.S.\n\n\nCode\ncovid = read.csv(\"./data/clean_data/covid.csv\",header =TRUE, sep = ',')\ncovid$date &lt;- as.Date(covid$date)\ncovid$new_cases_per_million &lt;- as.double(covid$new_cases_per_million)\ncovid$total_cases_per_million &lt;- as.double(covid$total_cases_per_million)\nhead(covid)\n\n\n       location       date total_cases_per_million new_cases_per_million\n1 United States 2020-01-05                      NA                 0.000\n2 United States 2020-01-12                      NA                 0.000\n3 United States 2020-01-19                      NA                 0.000\n4 United States 2020-01-26                   0.021                 0.021\n5 United States 2020-02-02                   0.027                 0.006\n6 United States 2020-02-09                   0.059                 0.033\n\n\n\n\nCode\npar(mfrow = c(2, 1)) \nplot1 = plot(covid$date, covid$new_cases_per_million, col=\"darkblue\", xlab=\"Time\", ylab=\"New Cases(per Million)\")\ntitle(\"Covid New Cases in U.S. Over Time\")\n\nplot2 = plot(covid$date, covid$total_cases_per_million, col=\"lightblue\", xlab=\"Time\", ylab=\"Total Cases(per Million)\")\ntitle(\"Covid Total Cases in U.S. Over Time\")"
  },
  {
    "objectID": "data_sources.html#sector-4-changes-in-the-most-vital-stocks",
    "href": "data_sources.html#sector-4-changes-in-the-most-vital-stocks",
    "title": "Data Sources",
    "section": "Sector 4: Changes in the Most Vital Stocks",
    "text": "Sector 4: Changes in the Most Vital Stocks\nSource:\n\n\nCode\nlibrary(quantmod)\nlibrary(tidyquant)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(ggfortify)\noptions(\"getSymbols.warning4.0\"=FALSE)\noptions(\"getSymbols.yahoo.warning\"=FALSE)\n\ntickers = c(\"UPS\",\"UNP\",\"JBHT\",\"KEX\")\nfor (i in tickers){\n  getSymbols(i,\n             from = \"2017-01-01\",\n             to = \"2023-12-31\")}\n\nx &lt;- list(\n  title = \"date\"\n)\ny &lt;- list(\n  title = \"value\"\n)\n\nstock &lt;- data.frame(UPS$UPS.Adjusted,\n                    UNP$UNP.Adjusted,\n                    JBHT$JBHT.Adjusted,\n                    KEX$KEX.Adjusted\n                    )\n\n\nstock &lt;- data.frame(stock,rownames(stock))\ncolnames(stock) &lt;- append(tickers,'Dates')\n\nstock$date&lt;-as.Date(stock$Dates,\"%Y-%m-%d\")\n(head(stock))\n\n\n                UPS      UNP     JBHT   KEX      Dates       date\n2017-01-03 92.12066 87.95852 90.92941 66.25 2017-01-03 2017-01-03\n2017-01-04 92.14466 88.49048 91.91602 67.90 2017-01-04 2017-01-04\n2017-01-05 92.19267 87.62393 91.32405 68.00 2017-01-05 2017-01-05\n2017-01-06 92.37682 88.53339 91.79388 68.30 2017-01-06 2017-01-06\n2017-01-09 91.87248 87.87273 91.02335 65.45 2017-01-09 2017-01-09\n2017-01-10 91.19209 88.73070 91.82206 64.90 2017-01-10 2017-01-10"
  },
  {
    "objectID": "data_sources.html#sector-1-moving-goods-in-the-united-states",
    "href": "data_sources.html#sector-1-moving-goods-in-the-united-states",
    "title": "Data Sources",
    "section": "",
    "text": "Code\ndf1 &lt;- read.csv(\"data/clean_data/11value_us.csv\")\n#df1$Year &lt;- as.Date(ISOdate(df1$Year, 1, 1))\nhead(df1)\n\n\n                         Mode              Measure.Names Year Trade.Type\n1           Other and Unknown Value (billions of 2017 $) 2017     Import\n2                    Pipeline Value (billions of 2017 $) 2017     Import\n3 Multiple Dms Modes and Mail Value (billions of 2017 $) 2017     Import\n4    Air (includes truck-air) Value (billions of 2017 $) 2017     Import\n5                       Water Value (billions of 2017 $) 2017     Import\n6                        Rail Value (billions of 2017 $) 2017     Import\n  Measure.Values\n1       11.84428\n2       63.44107\n3     1037.25672\n4      571.16543\n5      120.53570\n6      113.05147\n\n\n\n\n\n\n\nCode\ndf2 &lt;- read.csv(\"data/clean_data/12weight_us.csv\")\nhead(df2)\n\n\n  Trade.Type                        Mode Year   Measure.Names Measure.Values\n1   Domestic    Air (includes truck-air) 2021 Tons (millions)       2.062421\n2   Domestic    Air (includes truck-air) 2020 Tons (millions)       2.049576\n3   Domestic    Air (includes truck-air) 2019 Tons (millions)       2.126921\n4   Domestic    Air (includes truck-air) 2018 Tons (millions)       2.162104\n5   Domestic    Air (includes truck-air) 2017 Tons (millions)       2.136208\n6   Domestic Multiple Dms Modes and Mail 2021 Tons (millions)     507.931713\n\n\n\n\n\n\n\nCode\ndf3 &lt;- read.csv(\"data/clean_data/13distance_us.csv\")\nhead(df3)\n\n\n  Year Distance.band..miles.                                  Measure.Names\n1 2017            Over 2,000 % of Total Running Sum of ton-miles (millions)\n2 2017         1,500 - 2,000 % of Total Running Sum of ton-miles (millions)\n3 2017         1,000 - 1,499 % of Total Running Sum of ton-miles (millions)\n4 2017             750 - 999 % of Total Running Sum of ton-miles (millions)\n5 2017             500 - 749 % of Total Running Sum of ton-miles (millions)\n6 2017             250 - 499 % of Total Running Sum of ton-miles (millions)\n  Measure.Values\n1      1.0000000\n2      0.8880109\n3      0.8020772\n4      0.6103572\n5      0.5091046\n6      0.4247276"
  },
  {
    "objectID": "data_sources.html#sector-2-international-freight",
    "href": "data_sources.html#sector-2-international-freight",
    "title": "Data Sources",
    "section": "",
    "text": "Code\ndf4 &lt;- read.csv(\"data/clean_data/21international_value.csv\")\nhead(df4)\n\n\n  Year             Mode                  Measure  Trade.Type      Value\n1 2017            Water Billions of U.S. Dollars Total trade 1601.74488\n2 2017            Truck Billions of U.S. Dollars Total trade  720.82734\n3 2017 Total, all modes Billions of U.S. Dollars Total trade 3886.78673\n4 2017             Rail Billions of U.S. Dollars Total trade  174.14326\n5 2017         Pipeline Billions of U.S. Dollars Total trade   65.24362\n6 2017    Other/unknown Billions of U.S. Dollars Total trade  256.06434\n\n\n\n\n\n\n\nCode\ndf5 &lt;- read.csv(\"data/clean_data/22international_Region.csv\")\nhead(df5)\n\n\n  Mode Year                                      Measure Region  Value\n1  Air 2022 Value of freight flows (millions of dollars)  Other 105226\n2  Air 2021 Value of freight flows (millions of dollars)  Other  98610\n3  Air 2020 Value of freight flows (millions of dollars)  Other  80459\n4  Air 2019 Value of freight flows (millions of dollars)  Other  93690\n5  Air 2018 Value of freight flows (millions of dollars)  Other  91088\n6  Air 2017 Value of freight flows (millions of dollars)  Other  88959"
  },
  {
    "objectID": "data_sources.html#sector-3-contribution-to-the-u.s.-economy",
    "href": "data_sources.html#sector-3-contribution-to-the-u.s.-economy",
    "title": "Data Sources",
    "section": "",
    "text": "Code\ndf6 &lt;- read.csv(\"data/clean_data/31GDP.csv\")\nhead(df6)\n\n\n  Year                         Mode      Type Current....billions.\n1 2021                    Household Household               411.48\n2 2021                     Pipeline Household                   NA\n3 2021 Transit and ground passenger Household                   NA\n4 2021                        Water Household                   NA\n5 2021                         Rail Household                   NA\n6 2021                          Air Household                   NA\n\n\n\n\n\n\n\nCode\ndf7 &lt;- read.csv(\"data/clean_data/32monthly_employment.csv\")\nhead(df7)\n\n\n                    Date Transportation.Employment...Pipeline.Transportation\n1 01/01/2005 12:00:00 AM                                               38100\n2 02/01/2005 12:00:00 AM                                               37700\n3 03/01/2005 12:00:00 AM                                               37600\n4 04/01/2005 12:00:00 AM                                               37800\n5 05/01/2005 12:00:00 AM                                               37500\n6 06/01/2005 12:00:00 AM                                               37800\n  Transportation.Employment...Water.Transportation\n1                                            55500\n2                                            55100\n3                                            56700\n4                                            59400\n5                                            61100\n6                                            62600\n  Transportation.Employment...Rail.Transportation\n1                                          191000\n2                                          191400\n3                                          191900\n4                                          193300\n5                                          193900\n6                                          193900\n  Transportation.Employment...Air.Transportation\n1                                         505200\n2                                         503400\n3                                         504200\n4                                         507300\n5                                         507800\n6                                         508300\n  Transportation.Employment...Transit.and.ground.passenger.transportation\n1                                                                  407900\n2                                                                  407700\n3                                                                  409200\n4                                                                  413700\n5                                                                  415300\n6                                                                  383900\n  Transportation.Employment...Truck.Transportation\n1                                          1348500\n2                                          1349000\n3                                          1359900\n4                                          1377300\n5                                          1391700\n6                                          1418900\n\n\n\n\n\n\n\nCode\ndf8 &lt;- read.csv(\"data/clean_data/33revenue.csv\")\nhead(df8)\n\n\n                                       Measure                  Mode Year\n1 Freight revenue per ton-mile (current cents) Air carrier, domestic 2021\n2 Freight revenue per ton-mile (current cents) Air carrier, domestic 2020\n3 Freight revenue per ton-mile (current cents) Air carrier, domestic 2019\n4 Freight revenue per ton-mile (current cents) Air carrier, domestic 2018\n5 Freight revenue per ton-mile (current cents) Air carrier, domestic 2017\n6 Freight revenue per ton-mile (current cents) Air carrier, domestic 2016\n     Value\n1  97.8600\n2 122.9800\n3 137.6700\n4 137.4876\n5 125.1505\n6 119.8993\n\n\n\n\n\n\n\nCode\ndf9 &lt;- read.csv(\"data/clean_data/34monthly_fuel_prices.csv\")\nhead(df9)\n\n\n  Month.of.Date  Diesel Jet.Fuel\n1  January 2000 $135.60   $78.10\n2 February 2000 $146.10   $78.00\n3    March 2000 $147.90   $77.10\n4    April 2000 $142.20   $71.90\n5      May 2000 $142.00   $76.20\n6     June 2000 $142.10   $78.50\n\n\n\n\n\n\n\nCode\ndf10 &lt;- read.csv(\"data/clean_data/35monthly_TSI.csv\")\nhead(df10)\n\n\n                    Date Transportation.Services.Index...Freight\n1 01/01/2000 12:00:00 AM                                   105.1\n2 02/01/2000 12:00:00 AM                                   103.3\n3 03/01/2000 12:00:00 AM                                    99.7\n4 04/01/2000 12:00:00 AM                                    97.9\n5 05/01/2000 12:00:00 AM                                    98.8\n6 06/01/2000 12:00:00 AM                                    99.7"
  },
  {
    "objectID": "data_visualization.html#moving-goods-in-the-united-states",
    "href": "data_visualization.html#moving-goods-in-the-united-states",
    "title": "Data Visualization",
    "section": "Moving Goods in the United States",
    "text": "Moving Goods in the United States\n\nU.S. Domestic Freight Transport Values by ModeU.S. Domestic Freight Transport Weights by Mode\n\n\n\n\nCode\n# Select the Domestic values\ndf &lt;- read.csv(\"data/clean_data/11value_us.csv\")\ndf &lt;- df[df$Trade.Type=='Domestic',]\n\nfig &lt;- plot_ly(df, x = ~Year, y = ~Measure.Values, name = ~Mode, type = 'scatter', mode = 'lines+markers',color = ~Mode) %&gt;%\nlayout(yaxis = list(title = \"Values(billions of 2017 $)\"),\n         title = \"U.S. Domestic Freight Transport Values by Mode\")\n \nfig \n\n\n\n\n\n\nThis plot illustrates the U.S. domestic freight transport values by mode from 2017 to 2021. Across all modes, the overall trend appears to be relatively stable over the period. Notably, truck transport accounts for the highest value in U.S. domestic shipments, surpassing 10,000 billion units. Conversely, other modes remain below 20,000 billion units. Additionally, there is a noticeable decline in each mode’s value in 2020, attributable to the COVID-19 pandemic.\n\n\n\n\nCode\n# Select the Domestic weights\ndf &lt;- read.csv(\"data/clean_data/12weight_us.csv\")\ndf &lt;- df[df$Trade.Type=='Domestic',]\n\nfig &lt;- plot_ly(df, x = ~Year, y = ~Measure.Values, name = ~Mode, type = 'scatter', mode = 'lines+markers',color = ~Mode) %&gt;%\nlayout(yaxis = list(title = \"Weights(Tons(millions))\"),\n         title = \"U.S. Domestic Freight Transport Weights by Mode\")\n \nfig \n\n\n\n\n\n\nThis plot visualizes the U.S. domestic freight transport weights by mode from 2017 to 2021. Throughout the period, the overall trend shows relative stability across all modes. Notably, truck transport emerges as the dominant mode, accounting for nearly 12,000 million tons. In contrast, other modes maintain weights below 20,000 million tons, except for pipeline transport, which hovers around 30,000 million tons. Additionally, a discernible decline is observed in each mode’s weight in 2020, attributed to the impact of the COVID-19 pandemic.\n\n\n\n\nU.S. Total freight Moved by Distance\n\n\nCode\nlibrary(plotly)\n\n# Read in the CSV file\ndf &lt;- read.csv(\"data/clean_data/13distance_us.csv\")\n\n# Filter the data for the desired measures\ndf &lt;- df[df$Measure.Names == '% of Total Value (millions of 2017 $)' | df$Measure.Names == '% of Total Tons (thousands)', ]\n\n# Round the Measure.Values to one decimal place and convert to percentages\ndf$Measure.Values &lt;- round(df$Measure.Values * 100, 1)\n\n# Create the plot using plot_ly\nTS3 &lt;- plot_ly(df, x = ~Distance.band..miles., y = ~Measure.Values,  \n               frame = ~Year, type = 'bar', name = ~Measure.Names, color = ~Measure.Names,\n               colors = RColorBrewer::brewer.pal(length(unique(df$Measure.Names)), \"Set2\")) %&gt;%\n  \n  # Specify axis titles and formatting\n  layout(yaxis = list(title = \"% of Total Value\"),\n         xaxis = list(title = \"Distance (miles)\", \n                      tickfont = list(family = 'Arial', color = 'black', size = 10)),\n         title = 'Total freight moved by distance')\n\n# Display the plot\nTS3\n\n\n\n\n\n\nThis plot provides insights into the total freight movement across different distances within the United States from 2017 to 2021. Analysis of the data underscores a significant trend: freight movement within distances below 250 miles dominates the landscape, consistently contributing over 50% to the total values in millions and 70% to the total weights in tons of the freight movement each year.\nConversely, transportation over distances exceeding 500 miles represents a smaller proportion, accounting for under 10% of both the total value and total weight each year. This disparity highlights the prevalence of shorter-distance freight movements compared to longer hauls, suggesting potential implications for logistics planning and infrastructure development."
  },
  {
    "objectID": "data_visualization.html#international-freight",
    "href": "data_visualization.html#international-freight",
    "title": "Data Visualization",
    "section": "International Freight",
    "text": "International Freight\n\nU.S. International Freight Transport Values by ModeU.S. International Freight Transport Weights by Mode\n\n\n\n\nCode\n# Select the international values\ndf &lt;- read.csv(\"data/clean_data/21international_value.csv\")\ndf &lt;- df[df$Trade.Type=='Total trade',]\ndf &lt;- df[df$Measure=='Billions of U.S. Dollars',]\n\nfig &lt;- plot_ly(df, x = ~Year, y = ~Value, name = ~Mode, type = 'scatter', mode = 'lines+markers',color = ~Mode) %&gt;%\nlayout(yaxis = list(title = \"Values(Billions of U.S. Dollars)\"),\n         title = \"U.S. International Freight Transport Values by Mode\")\n \nfig \n\n\n\n\n\n\nThis plot depicts U.S. international freight transport values by mode. The overall trend exhibits an upward trajectory, particularly evident post-2020. However, there is a notable drop in 2020 attributed to the COVID-19 pandemic, followed by a discernible rebound thereafter. Water transport emerges as the dominant mode for international freight, surpassing 2000 billion units by 2022.\n\n\n\n\nCode\n# Select the international weights\ndf &lt;- read.csv(\"data/clean_data/21international_value.csv\")\ndf &lt;- df[df$Trade.Type=='Total trade',]\ndf &lt;- df[df$Measure=='Millions of Short Tons',]\n\nfig &lt;- plot_ly(df, x = ~Year, y = ~Value, name = ~Mode, type = 'scatter', mode = 'lines+markers',color = ~Mode) %&gt;%\nlayout(yaxis = list(title = \"Weights(Millions of Short Tons(2,000 pounds))\"),\n         title = \"U.S. International Freight Transport Weights by Mode\")\nfig\n\n\n\n\n\n\nThis plot illustrates U.S. international freight transport weights by mode. While the overall trend appears relatively flat, there is a slight decline in 2020 attributed to the COVID-19 pandemic, followed by a noticeable rebound thereafter. Notably, water transport emerges as the dominant mode for international freight, surpassing 1500 million short tons. Additionally, there is a decline in 2022 across all modes except for water transport.\n\n\n\n\nU.S. International freight flows by Region and Mode\n\n\nCode\ndf &lt;- read.csv(\"data/clean_data/22International_Region.csv\")\n\n# Create the bar plot\nTS &lt;- plot_ly(df, x = ~Region, y = ~Value, name=~Mode, color=~Mode, frame = ~Year, type = 'bar') %&gt;%\n  \n  # Specify the y-axis range and title\n  layout(yaxis = list(title = \"Value of freight flows (millions of dollars)\"), barmode='stack') %&gt;%\n  layout(xaxis = list(tickfont = list(family = 'Arial', color = 'black', size = 10)),\n         title = 'International freight flows by Region and Mode')\n\n\n# Display the plot\nTS\n\n\n\n\n\n\nThis plot illustrates the dynamic landscape of U.S. international freight flows across various regions and modes of transportation. Overall, there is a notable upward trajectory in the volume of freight being transported.\nAsia emerges as the predominant destination for international freight shipments, boasting the highest values among the regions analyzed. Following closely behind is Europe, which steadily approaches Asia in terms of freight volume. Notably, both Asia and Europe primarily rely on vessel and air transport for their international freight movement. Examining the shift over time, at the outset, vessel transport dominates the freight movement in these regions, comprising over 50% of the total. However, a significant transition occurs as air transport gradually supersedes vessel transport, becoming the primary mode of freight transportation, constituting over 50% of the total volume.\nIn contrast, for neighboring countries such as Canada and Mexico, truck transport emerges as the predominant mode, accounting for over 60% of the freight movement. Particularly in Mexico, truck transportation dominates, handling nearly 70% of all freight shipments at 2022. Furthermore, there is a noteworthy increase in other modes of transportation. For instance, the utilization of pipelines for transporting freight to Canada has seen a remarkable surge, doubling in volume each year since 2020, indicating a shifting trend in transportation preferences and infrastructure development."
  },
  {
    "objectID": "data_visualization.html#contribution-to-the-u.s.-economy",
    "href": "data_visualization.html#contribution-to-the-u.s.-economy",
    "title": "Data Visualization",
    "section": "Contribution to the U.S. Economy",
    "text": "Contribution to the U.S. Economy\n\nGross domestic product (GDP) Attributed by Freight ModeAverage freight revenue per ton-mile by Mode\n\n\n\n\nCode\ndf &lt;- read.csv(\"data/clean_data/31GDP.csv\")\n# Group by Year and Mode, calculate the sum of GDP within each group\ndf1 &lt;- df %&gt;%\n  group_by(Year, Mode) %&gt;%\n  summarize(Value = sum(Current....billions., na.rm = TRUE))\n\np&lt;-ggplot(df1, aes(x = Year, y = Value, color = Mode)) +\n  geom_line() +\n  ggtitle(\"Gross domestic product (GDP) Attributed by Freight Mode\") +\n  labs(y=\"Value(current billions)\")\n\npf&lt;-p + facet_wrap(~Mode, ncol = 4) +\ntheme(axis.text.x = element_text(face = \"bold\", color = \"blue\", size = 7, angle = 45))\n\nggplotly(pf)\n\n\n\n\nNotes: Household transportation covers transportation that households provide for themselves with vehicles. Other transportation includes: pipeline, transit and ground passenger transportation; sightseeing transportation and transportation support; courier and messenger services; and warehousing and storage.\n\n\nThis plot illustrates the contribution of various freight modes to the U.S. GDP from 2012 to 2021. Notably, household, truck, and other modes have experienced significant growth and collectively account for the majority of the GDP in the freight transportation industry, totaling around 70%.\nThe air freight sector saw substantial growth until 2020, after which it experienced a sharp decline, followed by a gradual recovery in 2021. Despite this setback, air transportation remains a significant contributor to the GDP of the freight industry.\nIn contrast, other modes such as pipeline, rail, and water exhibit relatively stable trends, with their combined contribution hovering around 10% of the total GDP throughout the analyzed period.\n\n\n\n\nCode\ndf &lt;- read.csv(\"data/clean_data/33revenue.csv\")\n\np&lt;-ggplot(df, aes(x = Year, y = Value, color = Mode)) +\n  geom_line() +\n  ggtitle(\"Average freight revenue per ton-mile by Mode\") +\n  labs(y=\"Value(per ton-mile (current cents))\")\n\npf&lt;-p + facet_wrap(~Mode, ncol = 5) +\ntheme(axis.text.x = element_text(face = \"bold\", color = \"blue\", size = 7, angle = 45))\n\nggplotly(pf)\n\n\n\n\n\n\nThis plot displays the average freight revenue per ton-mile across different modes of transportation. Notably, domestic air carriers exhibit considerable fluctuations in revenue. Initially, there was a significant increase until 2019, followed by a notable drop since 2020. Despite these fluctuations, the average revenue remains over ten times higher than that of other modes. In 2019, it peaked at 137 current cents per ton-mile, whereas in 2021, it decreased to 97 cents.\nIn contrast, other modes such as rail, oil pipeline, and water transportation maintain relatively lower average revenues, consistently below 10 cents per ton-mile. The trucking industry shows a sharp upward trend in revenue, although it still remains below 20 cents per ton-mile."
  },
  {
    "objectID": "data_visualization.html#stock-prices-for-the-best-known-transportation-companies-from-2017-2023",
    "href": "data_visualization.html#stock-prices-for-the-best-known-transportation-companies-from-2017-2023",
    "title": "Data Visualization",
    "section": "",
    "text": "Code\noptions(\"getSymbols.warning4.0\"=FALSE)\noptions(\"getSymbols.yahoo.warning\"=FALSE)\n\ntickers = c(\"UPS\",\"UNP\",\"JBHT\",\"KEX\")\nfor (i in tickers){\n  getSymbols(i,\n             from = \"2017-01-01\",\n             to = \"2023-12-31\")}\n\nx &lt;- list(\n  title = \"date\"\n)\ny &lt;- list(\n  title = \"value\"\n)\n\nstock &lt;- data.frame(UPS$UPS.Adjusted,\n                    UNP$UNP.Adjusted,\n                    JBHT$JBHT.Adjusted,\n                    KEX$KEX.Adjusted\n                    )\n\n\nstock &lt;- data.frame(stock,rownames(stock))\ncolnames(stock) &lt;- append(tickers,'Dates')\n\nstock$date&lt;-as.Date(stock$Dates,\"%Y-%m-%d\")\n(head(stock))\n\n\n                UPS      UNP     JBHT   KEX      Dates       date\n2017-01-03 92.12064 87.95854 90.74683 66.25 2017-01-03 2017-01-03\n2017-01-04 92.14466 88.49049 91.73149 67.90 2017-01-04 2017-01-04\n2017-01-05 92.19270 87.62395 91.14070 68.00 2017-01-05 2017-01-05\n2017-01-06 92.37681 88.53340 91.60957 68.30 2017-01-06 2017-01-06\n2017-01-09 91.87250 87.87275 90.84063 65.45 2017-01-09 2017-01-09\n2017-01-10 91.19209 88.73072 91.63771 64.90 2017-01-10 2017-01-10\n\n\nCode\n################################################\n\nggplot(stock, aes(x=date)) +\n  geom_line(aes(y=UPS, colour=\"UPS\"))+\n  geom_line(aes(y=UNP, colour=\"UNP\"))+\n  geom_line(aes(y=JBHT, colour=\"JBHT\"))+\n  geom_line(aes(y=KEX, colour=\"KEX\"))+\n   labs(\n    title = \"Stock Prices for the Best-Known Transportation Companies\",\n    subtitle = \"From 2017-2023\",\n    x = \"Date\",\n    y = \"Adjusted Closing Prices\")+\n    theme(panel.background = element_rect(fill = \"white\", colour = \"grey50\"))+\n    guides(colour=guide_legend(title=\"Transportation Companies\")) \n\n\n\n\n\nAmong the best-known transportation companies are the following:\nUnited Parcel Service (UPS 0.32%): An industry leader in package delivery, UPS ships billions of packages and documents every year by land, sea, and air. UPS also maintains a network of stores, customer centers, and drop boxes. Union Pacific (UNP 0.19%): This industrial railroad has an extensive network of tracks in the western two-thirds of the U.S., with several different routes between the Mississippi River and the Pacific Ocean. Union Pacific ships everything from coal and chemicals to crops and cars. J.B. Hunt Transport Services (JBHT 1.07%): With a massive coverage network, this trucking company serves the U.S., Canada, and Mexico. J.B. Hunt’s partner network also offers modes of transportation other than trucking, which ensures that customers can transport things in the most efficient way possible. Kirby (KEX 0.4%): This U.S. tank barge operator uses the entire Mississippi River watershed as a conduit for moving goods through the U.S. heartland. Kirby delivers bulk liquids to customers on the west, east, and Gulf of Mexico coasts, as well as Alaska and Hawaii."
  },
  {
    "objectID": "data_visualization.html#stock-prices-for-the-best-known-transportation-companies",
    "href": "data_visualization.html#stock-prices-for-the-best-known-transportation-companies",
    "title": "Data Visualization",
    "section": "Stock Prices for the Best-Known Transportation Companies",
    "text": "Stock Prices for the Best-Known Transportation Companies\n\n\nCode\noptions(\"getSymbols.warning4.0\"=FALSE)\noptions(\"getSymbols.yahoo.warning\"=FALSE)\n\ntickers = c(\"UPS\",\"UNP\",\"JBHT\",\"KEX\")\nfor (i in tickers){\n  getSymbols(i,\n             from = \"2017-01-01\",\n             to = \"2023-12-31\")}\n\nx &lt;- list(\n  title = \"date\"\n)\ny &lt;- list(\n  title = \"value\"\n)\n\nstock &lt;- data.frame(UPS$UPS.Adjusted,\n                    UNP$UNP.Adjusted,\n                    JBHT$JBHT.Adjusted,\n                    KEX$KEX.Adjusted\n                    )\n\n\nstock &lt;- data.frame(stock,rownames(stock))\ncolnames(stock) &lt;- append(tickers,'Dates')\n\nstock$date&lt;-as.Date(stock$Dates,\"%Y-%m-%d\")\n#(head(stock))\n################################################\n\nggplot(stock, aes(x=date)) +\n  geom_line(aes(y=UPS, colour=\"UPS\"))+\n  geom_line(aes(y=UNP, colour=\"UNP\"))+\n  geom_line(aes(y=JBHT, colour=\"JBHT\"))+\n  geom_line(aes(y=KEX, colour=\"KEX\"))+\n   labs(\n    title = \"Stock Prices for the Best-Known Transportation Companies\",\n    subtitle = \"From 2017-2023\",\n    x = \"Date\",\n    y = \"Adjusted Closing Prices\")+\n    theme(panel.background = element_rect(fill = \"white\", colour = \"grey50\"))+\n    guides(colour=guide_legend(title=\"Transportation Companies\")) \n\n\n\n\n\nThis plot illustrates the stock price performance of some of the most renowned transportation companies spanning the years 2017 to 2023. Among these companies are:\nUnited Parcel Service (UPS): A global leader in package delivery, UPS handles billions of packages and documents annually via land, sea, and air routes. Additionally, UPS operates a widespread network of stores, customer centers, and drop boxes.\nUnion Pacific (UNP): As a prominent industrial railroad, Union Pacific boasts an extensive track network covering the western two-thirds of the United States. The company facilitates the transportation of diverse cargo ranging from coal and chemicals to agricultural produce and automobiles.\nJ.B. Hunt Transport Services (JBHT): With its vast coverage network, J.B. Hunt provides trucking services across the United States, Canada, and Mexico. Moreover, J.B. Hunt collaborates with partner networks to offer various transportation modes, ensuring optimal efficiency in cargo transportation.\nKirby (KEX): As a significant U.S. tank barge operator, Kirby utilizes the entire Mississippi River watershed to transport goods across the heartland of the United States. The company delivers bulk liquids to customers along the west, east, and Gulf of Mexico coasts, as well as serving Alaska and Hawaii.\nThe plot visually depicts the fluctuations in the stock prices of these transportation giants over the specified timeframe, providing insights into their respective financial performances and market dynamics."
  },
  {
    "objectID": "eda.html#time-series-visualization",
    "href": "eda.html#time-series-visualization",
    "title": "Exploratory Data Analysis",
    "section": "Time Series Visualization",
    "text": "Time Series Visualization\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexU.S. Domestic Air Carrier Average Freight RevenueUPS Stock Price\n\n\n\n\nCode\ncanada &lt;- read.csv(\"data/clean_data/24monthly_canada_freight.csv\")\ncanada &lt;- canada[,c(\"Date\",\"Value\")]\ncanada_ts &lt;- ts(canada$Value, start = decimal_date(as.Date(\"2006-01-01\", format = \"%Y-%m-%d\")), end = decimal_date(as.Date(\"2023-01-01\", format = \"%Y-%m-%d\")), frequency = 12)\n\nca &lt;- autoplot(canada_ts, xlab= \"Date\", ylab = \"Billions\", colour = \"blue\")+\nggtitle('U.S.-Canada Freight Value Over Time')\n\nggplotly(ca)\n\n\n\n\n\n\nThis plot reveals an overall upward trend with notable fluctuations in 2009 and 2020, corresponding to economic downturns. Additionally, recurring seasonality is evident each year. The gradual nature of the upward trend suggests an additive series rather than a drastic surge.\n\n\n\n\nCode\nemployment &lt;- read.csv(\"data/clean_data/32monthly_employment.csv\")\nemployment &lt;- employment[,c(\"Date\",\"Transportation.Employment...Air.Transportation\")]\nemployment_ts &lt;- ts(employment$Transportation.Employment...Air.Transportation, start = decimal_date(as.Date(\"2005-01-01\", format = \"%Y-%m-%d\")), end = decimal_date(as.Date(\"2024-01-01\", format = \"%Y-%m-%d\")), frequency = 12)\n\nem &lt;- autoplot(employment_ts, xlab= \"Date\", ylab = \"Employment\", colour = \"blue\")+\nggtitle('U.S. Air Transportation Employment Over Time')\n\nggplotly(em)\n\n\n\n\n\n\nThis plot showcases a slight overall upward trend amidst significant fluctuations. A notable downward trend is observed from 2008 until a rebound in 2014, followed by a sharp drop in 2020 attributed to the COVID-19 pandemic. Despite these fluctuations, recurring seasonal patterns are discernible each year. The gradual nature of the trend suggests an additive series rather than a dramatic surge.\n\n\n\n\nCode\ntsi &lt;- read.csv(\"data/clean_data/35monthly_TSI.csv\")\ntsi_ts &lt;- ts(tsi$Transportation.Services.Index...Freight, start = decimal_date(as.Date(\"2000-01-01\", format = \"%Y-%m-%d\")), end = decimal_date(as.Date(\"2023-01-01\", format = \"%Y-%m-%d\")), frequency = 12)\n\nt &lt;- autoplot(tsi_ts, xlab= \"Date\", ylab = \"Transportation Services Index\", colour = \"blue\")+\nggtitle('U.S. Freight Transportation Services Index Over Time')\n\nggplotly(t)\n\n\n\n\n\n\nThis plot illustrates an overall upward trend with two noticeable fluctuations in 2009 and 2020 attributed to economic downturns. Additionally, there are discernible seasonal patterns observed each year. The upward trend appears gradual, indicative of an additive series rather than a rapid ascent.\n\n\n\n\nCode\nair &lt;- read.csv(\"data/clean_data/33revenue.csv\")\nair &lt;- air[air$Mode==\"Air carrier, domestic\",c(\"Year\",\"Value\")]\nair &lt;- air[order(air$Year), ]\nair_ts &lt;- ts(air$Value, start = decimal_date(as.Date(\"2000-01-01\", format = \"%Y-%m-%d\")), end = decimal_date(as.Date(\"2021-01-01\", format = \"%Y-%m-%d\")), frequency = 1)\n\na &lt;- autoplot(air_ts, xlab= \"Year\", ylab = \"Freight revenue per ton-mile (current cents)\", colour = \"blue\")+\nggtitle('U.S. Domestic Air Carrier Average Freight Revenue Over Time')\n\nggplotly(a)\n\n\n\n\n\n\nThis plot depicts an overall upward trend punctuated by significant fluctuations, notably in 2001 and 2020, attributed to economic downturns, with a rapid rebound observed in 2010. Additional minor fluctuations are evident in 2009 and 2016. Since the data is recorded annually, there is no discernible seasonality. The gradual nature of the upward trend suggests an additive series rather than a sharp incline.\n\n\n\n\nCode\nups &lt;- getSymbols(\"UPS\",auto.assign = FALSE, from = \"2017-01-01\", to = \"2024-01-01\",src=\"yahoo\") \nups=data.frame(ups)\nups &lt;- data.frame(ups,rownames(ups))\ncolnames(ups)[7] = \"date\"\nups$date&lt;-as.Date(ups$date,\"%Y-%m-%d\")\nups_ts &lt;- ts(ups$UPS.Adjusted, start = decimal_date(as.Date(\"2017-01-03\", format = \"%Y-%m-%d\")), frequency = 365.25)\n\nu &lt;- autoplot(ups_ts, xlab= \"Date\", ylab = \"Stock Price\", colour = \"blue\")+\nggtitle('UPS Stock Price Over Time')\n\nggplotly(u)\n\n\n\n\n\n\nThis plot illustrates an overall upward trend, with two significant increases observed in 2019 attributed to the surge in delivery demand during the COVID-19 pandemic. Additionally, recurring seasonal patterns are evident each year. The gradual nature of the upward trend suggests an additive series rather than a sharp incline."
  },
  {
    "objectID": "eda.html#component-analysis",
    "href": "eda.html#component-analysis",
    "title": "Exploratory Data Analysis",
    "section": "Component Analysis",
    "text": "Component Analysis\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexU.S. Domestic Air Carrier Average Freight RevenueUPS Stock Price\n\n\n\n\nCode\ndecomposed &lt;- decompose(canada_ts, \"additive\")\nautoplot(decomposed, colour = \"#5a3196\", main = \"Decomposition Plot For UPS Stock Price Data\")+theme_bw()\n\n\n\n\n\nThe decomposition of the time series data aligns with the initial observations made during data exploration. The trend component indicates a consistent upward trend over time, corroborating our earlier findings. Furthermore, the presence of seasonality in the dataset is confirmed, reinforcing our understanding of recurring patterns within the data.\n\n\n\n\nCode\ndecomposed &lt;- decompose(employment_ts, \"additive\")\nautoplot(decomposed, colour = \"#5a3196\", main = \"Decomposition Plot For U.S. Air Transportation Employment Data\")+theme_bw()\n\n\n\n\n\nThe decomposition of the time series validates our initial observations from data exploration. Specifically, the trend component illustrates a consistent upward trend with a notable fluctuation in 2020, aligning with our earlier findings. Additionally, the presence of seasonality in the dataset is confirmed, further reinforcing our understanding of recurring patterns within the data.\n\n\n\n\nCode\ndecomposed &lt;- decompose(tsi_ts, \"additive\")\nautoplot(decomposed, colour = \"#5a3196\", main = \"Decomposition Plot For U.S. Freight Transportation Services Index Data\")+theme_bw()\n\n\n\n\n\nThe decomposition of the time series data aligns with the initial observations made during data exploration. The trend component indicates a consistent upward trend over time, corroborating our earlier findings. Furthermore, the presence of seasonality in the dataset is confirmed, reinforcing our understanding of recurring patterns within the data.\n\n\nDecomposition was not able to be ran on this dataset because there was not enough seasonality.\n\n\n\n\nCode\ndecomposed &lt;- decompose(ups_ts, \"additive\")\nautoplot(decomposed, colour = \"#5a3196\", main = \"Decomposition Plot For UPS Stock Price Data\")+theme_bw()\n\n\n\n\n\nThe decomposition of the time series validates our initial observations from the data exploration phase. Specifically, the trend component indicates a consistent upward trend with a significant increase observed from 2019 to 2020, aligning with our earlier findings. Additionally, the presence of seasonality in the dataset is confirmed, further reinforcing our understanding of recurring patterns within the data."
  },
  {
    "objectID": "eda.html#lag-plot-analysis",
    "href": "eda.html#lag-plot-analysis",
    "title": "Exploratory Data Analysis",
    "section": "Lag Plot Analysis",
    "text": "Lag Plot Analysis\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexU.S. Domestic Air Carrier Average Freight RevenueUPS Stock Price\n\n\n\n\nCode\ngglagplot(canada_ts, do.lines=FALSE) +xlab(\"Lags\")+ylab(\"Value(billions)\")+ggtitle(\"Lag Plot for U.S.-Canada Freight Value\")+theme(axis.text.x=element_text(angle=45, hjust=1))+ theme_bw()\n\n\n\n\n\nInitially, there is a strong positive autocorrelation observed in the first two lags, indicating a significant correlation between adjacent time points. However, as we move further along the lag sequence, the autocorrelation gradually weakens, suggesting a diminishing correlation between more distant observations. By lags 13-16, the autocorrelation becomes very weak, indicating minimal correlation between observations separated by larger time intervals.\n\n\n\n\nCode\ngglagplot(employment_ts, do.lines=FALSE) +xlab(\"Lags\")+ylab(\"Value\")+ggtitle(\"Lag Plot for U.S. Air Transportation Employment\")+theme(axis.text.x=element_text(angle=45, hjust=1))+ theme_bw()\n\n\n\n\n\nInitially, there is a notable positive autocorrelation observed in the first three lags, indicating a strong correlation between adjacent time points. However, as we progress along the lag sequence, the autocorrelation gradually diminishes, suggesting a weakening correlation between observations further apart in time. By lags 13-16, the autocorrelation becomes very weak, indicating minimal correlation between observations separated by larger time intervals.\n\n\n\n\nCode\ngglagplot(tsi_ts, do.lines=FALSE) +xlab(\"Lags\")+ylab(\"TSI\")+ggtitle(\"Lag Plot for U.S. Freight Transportation Services Index\")+theme(axis.text.x=element_text(angle=45, hjust=1))+ theme_bw()\n\n\n\n\n\nInitially, there is a strong positive autocorrelation observed for the first three lags, indicating a robust correlation between adjacent time points. As we progress along the lag sequence, the autocorrelation gradually weakens but remains relatively strong until lag 12. However, beyond lag 12, the autocorrelation diminishes further, indicating a decline in the strength of correlation between observations separated by larger time intervals.\n\n\n\n\nCode\ngglagplot(air_ts, do.lines=FALSE) +xlab(\"Lags\")+ylab(\"Value(per ton-mile (current cents))\")+ggtitle(\"Lag Plot for U.S. Domestic Air Carrier Average Freight Revenue\")+theme(axis.text.x=element_text(angle=45, hjust=1))+ theme_bw()\n\n\n\n\n\nThere is a stronger positive autocorrelation observed in the first lag, indicating a notable correlation between adjacent time points. However, beyond the first lag, there is either no discernible autocorrelation or very weak positive autocorrelation observed.\n\n\n\n\nCode\ngglagplot(ups_ts, do.lines=FALSE) +xlab(\"Lags\")+ylab(\"Value\")+ggtitle(\"Lag Plot for UPS Stock Price\")+theme(axis.text.x=element_text(angle=45, hjust=1))+ theme_bw()\n\n\n\n\n\nInitially, there is a strong positive autocorrelation observed for the first four lags, indicating a robust correlation between adjacent time points. As we progress along the lag sequence, the autocorrelation gradually weakens but remains relatively strong until lag 16. This sustained strength in autocorrelation suggests that there is still a notable correlation between observations even as we move further along the lag sequence."
  },
  {
    "objectID": "eda.html#acf-pacf-plots",
    "href": "eda.html#acf-pacf-plots",
    "title": "Exploratory Data Analysis",
    "section": "ACF & PACF Plots",
    "text": "ACF & PACF Plots\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexU.S. Domestic Air Carrier Average Freight RevenueUPS Stock Price\n\n\n\n\nCode\nplot1&lt;-ggAcf(canada_ts)+ggtitle(\"U.S.-Canada Freight Value ACF\") + theme_bw()\nplot2&lt;- ggPacf(canada_ts)+theme_bw()+ggtitle(\"U.S.-Canada Freight Value PACF\")\n\ngrid.arrange(plot1, plot2,nrow=2)\n\n\n\n\n\nBased on the ACF and PACF plots, we observe strong correlations at the beginning lags, gradually decreasing but remaining relatively strong until lag 12 in the ACF plot. In contrast, the PACF plot also exhibits strong correlation at lag 1, with moderate correlation extending until lag 13. The presence of significant correlations in both plots suggests that the time series data is non-stationary.\n\n\n\n\nCode\nplot1&lt;-ggAcf(employment_ts)+ggtitle(\"U.S. Air Transportation Employment ACF\") + theme_bw()\nplot2&lt;- ggPacf(employment_ts)+theme_bw()+ggtitle(\"U.S. Air Transportation Employment PACF\")\n\ngrid.arrange(plot1, plot2,nrow=2)\n\n\n\n\n\nBased on the ACF plot, there is strong correlation observed from lag 1 to lag 16, with the correlation gradually decreasing but remaining relatively strong throughout. Similarly, the PACF plot shows strong correlation at lag 1 and lag 2. Given the presence of significant correlations in both plots, we can infer that the series is likely non-stationary.\n\n\n\n\nCode\nplot1&lt;-ggAcf(tsi_ts)+ggtitle(\"U.S. Freight Transportation Services Index ACF\") + theme_bw()\nplot2&lt;- ggPacf(tsi_ts)+theme_bw()+ggtitle(\"U.S. Freight Transportation Services Index PACF\")\n\ngrid.arrange(plot1, plot2,nrow=2)\n\n\n\n\n\nBased on the ACF plot, there is a strong correlation observed at lag 1, with the correlation slightly decreasing but remaining relatively strong until the end of the plot. Similarly, the PACF plot shows strong correlation at lag 1. Given the presence of significant correlations in both plots, we can infer that the series is likely non-stationary.\n\n\n\n\nCode\nplot1&lt;-ggAcf(air_ts)+ggtitle(\"U.S. Domestic Air Carrier Average Freight Revenue ACF\") + theme_bw()\nplot2&lt;- ggPacf(air_ts)+theme_bw()+ggtitle(\"U.S. Domestic Air Carrier Average Freight Revenue PACF\")\n\ngrid.arrange(plot1, plot2,nrow=2)\n\n\n\n\n\nBased on the description provided, the ACF plot demonstrates strong correlation at lag 1 and moderate correlation at lag 2 and lag 3. Additionally, the PACF plot exhibits strong correlation only at lag 1. Given the presence of significant correlations in both plots, particularly at lag 1, and moderate correlation at subsequent lags, we can infer that the series is likely non-stationary.\n\n\n\n\nCode\nplot1&lt;-ggAcf(ups_ts, lag=100)+ggtitle(\"UPS Stock Price ACF\") + theme_bw()\nplot2&lt;- ggPacf(ups_ts, lag=100)+theme_bw()+ggtitle(\"UPS Stock Price PACF\")\n\ngrid.arrange(plot1, plot2,nrow=2)\n\n\n\n\n\nBased on the provided information, it appears that the ACF plot shows strong correlation beginning at lag 1 and then slightly decreasing but remaining strong until the end. Additionally, the PACF plot exhibits strong correlation only at lag 1. Given the presence of significant correlations in both plots, particularly at lag 1, and the sustained autocorrelation observed in the ACF plot, we can infer that the series is likely non-stationary."
  },
  {
    "objectID": "eda.html#adjusted-dickey-fuller-test",
    "href": "eda.html#adjusted-dickey-fuller-test",
    "title": "Exploratory Data Analysis",
    "section": "Adjusted Dickey-Fuller Test",
    "text": "Adjusted Dickey-Fuller Test\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexU.S. Domestic Air Carrier Average Freight RevenueUPS Stock Price\n\n\n\n\nCode\ntseries::adf.test(canada_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  canada_ts\nDickey-Fuller = -3.0511, Lag order = 5, p-value = 0.1356\nalternative hypothesis: stationary\n\n\nWith a p-value higher than 0.05, there is insufficient evidence to reject the null hypothesis at the 5% significance level. Consequently, we can conclude that our series is non-stationary. This conclusion aligns with the earlier analysis, where strong autocorrelation was observed in the ACF and PACF plots, indicating non-stationarity.\n\n\n\n\nCode\ntseries::adf.test(employment_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  employment_ts\nDickey-Fuller = -3.1311, Lag order = 6, p-value = 0.1008\nalternative hypothesis: stationary\n\n\nWith a p-value higher than 0.05, there is insufficient evidence to reject the null hypothesis at the 5% significance level. Consequently, we can conclude that our series is non-stationary. This conclusion aligns with the earlier analysis, where strong autocorrelation was observed in the ACF and PACF plots, indicating non-stationarity.\n\n\n\n\nCode\ntseries::adf.test(tsi_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  tsi_ts\nDickey-Fuller = -2.4166, Lag order = 6, p-value = 0.4005\nalternative hypothesis: stationary\n\n\nWith a p-value higher than 0.05, there is insufficient evidence to reject the null hypothesis at the 5% significance level. Consequently, we can conclude that our series is non-stationary. This conclusion aligns with the earlier analysis, where strong autocorrelation was observed in the ACF and PACF plots, indicating non-stationarity.\n\n\n\n\nCode\ntseries::adf.test(air_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  air_ts\nDickey-Fuller = -0.85187, Lag order = 2, p-value = 0.9424\nalternative hypothesis: stationary\n\n\nWith a p-value higher than 0.05, there is insufficient evidence to reject the null hypothesis at the 5% significance level. Consequently, we can conclude that our series is non-stationary. This conclusion aligns with the earlier analysis, where strong autocorrelation was observed in the ACF and PACF plots, indicating non-stationarity.\n\n\n\n\nCode\ntseries::adf.test(ups_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  ups_ts\nDickey-Fuller = -2.2106, Lag order = 12, p-value = 0.4892\nalternative hypothesis: stationary\n\n\nWith a p-value higher than 0.05, there is insufficient evidence to reject the null hypothesis at the 5% significance level. Consequently, we can conclude that our series is non-stationary. This conclusion aligns with the earlier analysis, where strong autocorrelation was observed in the ACF and PACF plots, indicating non-stationarity."
  },
  {
    "objectID": "eda.html#detrend-differencing",
    "href": "eda.html#detrend-differencing",
    "title": "Exploratory Data Analysis",
    "section": "Detrend & Differencing",
    "text": "Detrend & Differencing\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexU.S. Domestic Air Carrier Average Freight RevenueUPS Stock Price\n\n\n\n\nCode\nrequire(gridExtra)\nfit = lm(canada_ts~time(canada_ts), na.action=NULL)\n\nplot1&lt;-autoplot(resid(fit), main=\"Detrended\") +theme_bw()\nplot2&lt;-autoplot(diff(canada_ts), main=\"First Difference\") +theme_bw()\n\ngrid.arrange(plot1, plot2,nrow=2)\n\n\n\n\n\n\n\nCode\nplot1 &lt;- ggAcf(canada_ts, 48) + ggtitle(\"Original Data\")+theme_bw()\nplot2 &lt;- ggAcf(resid(fit), 48) + ggtitle(\"Detrended Data\")+theme_bw()\nplot3 &lt;- ggAcf(diff(canada_ts), 48) + ggtitle(\"First Difference Data\")+theme_bw()\n\ngrid.arrange(plot1, plot2, plot3,nrow=3)\n\n\n\n\n\nThe differenced data exhibits greater stationarity compared to both the original and detrended data. This improvement is evident in the ACF plot of the differenced data, which shows a significant drop-off, indicating a substantial reduction in autocorrelation beyond those lags. However, despite the improvement, the First Order Difference still shows some seasonality in the plot, suggesting that further differencing may be necessary to fully address the seasonality present in the data.\n\n\nCode\nplot1 &lt;- ggAcf(diff(canada_ts), 48) + ggtitle(\"First Difference Data\")+theme_bw()\nplot2 &lt;- ggAcf(diff(diff(canada_ts)), 48) + ggtitle(\"Second Differenced Data\") + theme_bw()\n\ngrid.arrange(plot1, plot2, nrow=2)\n\n\n\n\n\nThe second differenced ACF plot shows that the data be over differenced.\n\n\n\n\nCode\nrequire(gridExtra)\nfit1 = lm(employment_ts~time(employment_ts), na.action=NULL)\n\nplot1&lt;-autoplot(resid(fit1), main=\"Detrended\") +theme_bw()\nplot2&lt;-autoplot(diff(employment_ts), main=\"First Difference\") +theme_bw()\n\ngrid.arrange(plot1, plot2,nrow=2)\n\n\n\n\n\n\n\nCode\nplot1 &lt;- ggAcf(employment_ts, 48) + ggtitle(\"Original Data\")+theme_bw()\nplot2 &lt;- ggAcf(resid(fit1), 48) + ggtitle(\"Detrended Data\")+theme_bw()\nplot3 &lt;- ggAcf(diff(employment_ts), 48) + ggtitle(\"First Difference Data\")+theme_bw()\n\ngrid.arrange(plot1, plot2, plot3, nrow=3)\n\n\n\n\n\nThe differenced data exhibits greater stationarity compared to both the original and detrended data. This improvement is evident in the ACF plot of the differenced data, which shows a significant drop-off, indicating a substantial reduction in autocorrelation beyond those lags. However, despite the improvement, the First Order Difference still shows some seasonality in the plot, suggesting that further differencing may be necessary to fully address the seasonality present in the data.\n\n\nCode\nplot1 &lt;- ggAcf(diff(employment_ts), 48) + ggtitle(\"First Difference Data\")+theme_bw()\nplot2 &lt;- ggAcf(diff(diff(employment_ts)), 48) + ggtitle(\"Second Differenced Data\") + theme_bw()\n\ngrid.arrange(plot1, plot2, nrow=2)\n\n\n\n\n\nThe plot above clearly demonstrates that Second Order Differencing effectively renders the data stationary, which is a crucial prerequisite for accurate modeling.\n\n\n\n\nCode\nrequire(gridExtra)\nfit2 = lm(tsi_ts~time(tsi_ts), na.action=NULL)\n\nplot1&lt;-autoplot(resid(fit2), main=\"Detrended\") +theme_bw()\nplot2&lt;-autoplot(diff(tsi_ts), main=\"First Difference\") +theme_bw()\n\ngrid.arrange(plot1, plot2,nrow=2)\n\n\n\n\n\n\n\nCode\nplot1 &lt;- ggAcf(tsi_ts, 48) + ggtitle(\"Original Data\")+theme_bw()\nplot2 &lt;- ggAcf(resid(fit2), 48) + ggtitle(\"Detrended Data\")+theme_bw()\nplot3 &lt;- ggAcf(diff(tsi_ts), 48) + ggtitle(\"First Difference Data\")+theme_bw()\n\ngrid.arrange(plot1, plot2, plot3,nrow=3)\n\n\n\n\n\nFrom both the original plots and the ACF plots, it’s evident that the differenced data exhibits greater stationarity compared to the original data and the detrended data. The ACF plot of the differenced data shows a significant drop-off, indicating a lack of autocorrelation beyond those lags, which is characteristic of stationary data. In contrast, the detrended data still retains substantial correlation, resembling the patterns observed in the original data.\n\n\n\n\nCode\nrequire(gridExtra)\nfit3 = lm(air_ts~time(air_ts), na.action=NULL)\n\nplot1&lt;-autoplot(resid(fit3), main=\"Detrended\") +theme_bw()\nplot2&lt;-autoplot(diff(air_ts), main=\"First Difference\") +theme_bw()\n\ngrid.arrange(plot1, plot2,nrow=2)\n\n\n\n\n\n\n\nCode\nplot1 &lt;- ggAcf(air_ts, 48) + ggtitle(\"Original Data\")+theme_bw()\nplot2 &lt;- ggAcf(resid(fit3), 48) + ggtitle(\"Detrended Data\")+theme_bw()\nplot3 &lt;- ggAcf(diff(air_ts), 48) + ggtitle(\"First Difference Data\")+theme_bw()\n\ngrid.arrange(plot1, plot2, plot3,nrow=3)\n\n\n\n\n\nThe detrended and differenced data exhibit greater stationarity compared to the original data. This improvement is evident in the ACF plot of the differenced data and detrended data, both of which show a significant drop-off, indicating a lack of autocorrelation beyond those lags. This drop-off is characteristic of stationary data.\n\n\n\n\nCode\nrequire(gridExtra)\nfit4 = lm(ups_ts~time(ups_ts), na.action=NULL)\n\nplot1&lt;-autoplot(resid(fit4), main=\"Detrended\") +theme_bw()\nplot2&lt;-autoplot(diff(ups_ts), main=\"First Difference\") +theme_bw()\n\ngrid.arrange(plot1, plot2,nrow=2)\n\n\n\n\n\n\n\nCode\nplot1 &lt;- ggAcf(ups_ts, 48) + ggtitle(\"Original Data\")+theme_bw()\nplot2 &lt;- ggAcf(resid(fit4), 48) + ggtitle(\"Detrended Data\")+theme_bw()\nplot3 &lt;- ggAcf(diff(ups_ts), 48) + ggtitle(\"First Difference Data\")+theme_bw()\n\ngrid.arrange(plot1, plot2, plot3,nrow=3)\n\n\n\n\n\nThe differenced data exhibits greater stationarity compared to both the original and detrended data. This improvement is evident in the ACF plot of the differenced data, which shows a significant drop-off, indicating a substantial reduction in autocorrelation beyond those lags. However, despite the improvement, the First Order Difference still shows some seasonality in the plot, suggesting that further differencing may be necessary to fully address the seasonality present in the data.\n\n\nCode\nplot1 &lt;- ggAcf(diff(ups_ts), 48) + ggtitle(\"First Difference Data\")+theme_bw()\nplot2 &lt;- ggAcf(diff(diff(ups_ts)), 48) + ggtitle(\"Second Differenced Data\") + theme_bw()\n\ngrid.arrange(plot1, plot2, nrow=2)\n\n\n\n\n\nThe second differenced ACF plot shows that the data be over differenced."
  },
  {
    "objectID": "eda.html#moving-average-smoothing",
    "href": "eda.html#moving-average-smoothing",
    "title": "Exploratory Data Analysis",
    "section": "Moving Average Smoothing",
    "text": "Moving Average Smoothing\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexU.S. Domestic Air Carrier Average Freight RevenueUPS Stock Price\n\n\n\n\nCode\nma3 &lt;- autoplot(canada_ts, series=\"Data\") +\n  autolayer(ma(canada_ts,3), series=\"3-MA\") +\n  xlab(\"Date\") + ylab(\"Value(billions)\") +\n  ggtitle(\"MSA for U.S.-Canada Freight Value\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"3-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"3-MA\"))\n\nma7 &lt;- autoplot(canada_ts, series=\"Data\") +\n  autolayer(ma(canada_ts,7), series=\"7-MA\") +\n  xlab(\"Date\") + ylab(\"Value(billions)\") +\n  ggtitle(\"MSA for U.S.-Canada Freight Value\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"7-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"7-MA\"))\n\n\nma11 &lt;- autoplot(canada_ts, series=\"Data\") +\n  autolayer(ma(canada_ts,11), series=\"11-MA\") +\n  xlab(\"Date\") + ylab(\"Value(billions)\") +\n  ggtitle(\"MSA for U.S.-Canada Freight Value\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"11-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"11-MA\"))\n\nma25 &lt;- autoplot(canada_ts, series=\"Data\") +\n  autolayer(ma(canada_ts, 25), series=\"25-MA\") +\n  xlab(\"Date\") + ylab(\"Value(billions)\") +\n  ggtitle(\"MSA for U.S.-Canada Freight Value\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"25-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"25-MA\"))\n\ngrid.arrange(ma3, ma7, ma11, ma25, nrow = 2, ncol=2)\n\n\n\n\n\nIn addition to the original data, I incorporated three moving average windows: short-term windows of moving averages of 3, two medium-term moving averages of 7 and 11, and finally, the long-term moving average of 25. After careful analysis, it became evident that the 3-MA window didn’t exhibit sufficient change from the original data, while the 25-MA excessively smoothed the data. The most suitable choice for all the moving averages in this series appears to be the 7-MA window. It strikes a balance between capturing important fluctuations and smoothing the data, making it the optimal choice for this dataset.\n\n\n\n\nCode\nma3 &lt;- autoplot(employment_ts, series=\"Data\") +\n  autolayer(ma(employment_ts,3), series=\"3-MA\") +\n  xlab(\"Date\") + ylab(\"Employment\") +\n  ggtitle(\"MSA for U.S. Air Transportation Employment\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"3-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"3-MA\"))\n\nma7 &lt;- autoplot(employment_ts, series=\"Data\") +\n  autolayer(ma(employment_ts,7), series=\"7-MA\") +\n  xlab(\"Date\") + ylab(\"Employment\") +\n  ggtitle(\"MSA for U.S. Air Transportation Employment\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"7-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"7-MA\"))\n\n\nma11 &lt;- autoplot(employment_ts, series=\"Data\") +\n  autolayer(ma(employment_ts,11), series=\"11-MA\") +\n  xlab(\"Date\") + ylab(\"Employment\") +\n  ggtitle(\"MSA for U.S. Air Transportation Employment\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"11-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"11-MA\"))\n\nma25 &lt;- autoplot(employment_ts, series=\"Data\") +\n  autolayer(ma(employment_ts, 25), series=\"25-MA\") +\n  xlab(\"Date\") + ylab(\"Employment\") +\n  ggtitle(\"MSA for U.S. Air Transportation Employment\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"25-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"25-MA\"))\n\ngrid.arrange(ma3, ma7, ma11, ma25, nrow = 2, ncol=2)\n\n\n\n\n\nIn addition to the original data, I incorporated three moving average windows: short-term windows of moving averages of 3, two medium-term moving averages of 7 and 11, and finally, the long-term moving average of 25. Upon analysis, it was observed that the 3-MA window didn’t exhibit sufficient change from the original data, while the 25-MA excessively smoothed the data. The most suitable choice for all the moving averages in this series appears to be the 11-MA window. It strikes a balance between capturing important fluctuations and smoothing the data, making it the optimal choice for this dataset.\n\n\n\n\nCode\nma3 &lt;- autoplot(tsi_ts, series=\"Data\") +\n  autolayer(ma(tsi_ts,3), series=\"3-MA\") +\n  xlab(\"Date\") + ylab(\"TSI\") +\n  ggtitle(\"MSA for U.S. Freight TSI\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"3-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"3-MA\"))\n\nma7 &lt;- autoplot(tsi_ts, series=\"Data\") +\n  autolayer(ma(tsi_ts,7), series=\"7-MA\") +\n  xlab(\"Date\") + ylab(\"TSI\") +\n  ggtitle(\"MSA for U.S. Freight TSI\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"7-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"7-MA\"))\n\n\nma11 &lt;- autoplot(tsi_ts, series=\"Data\") +\n  autolayer(ma(tsi_ts,11), series=\"11-MA\") +\n  xlab(\"Date\") + ylab(\"TSI\") +\n  ggtitle(\"MSA for U.S. Freight TSI\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"11-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"11-MA\"))\n\nma25 &lt;- autoplot(tsi_ts, series=\"Data\") +\n  autolayer(ma(tsi_ts, 25), series=\"25-MA\") +\n  xlab(\"Date\") + ylab(\"TSI\") +\n  ggtitle(\"MSA for U.S. Freight TSI\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"25-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"25-MA\"))\n\ngrid.arrange(ma3, ma7, ma11, ma25, nrow = 2, ncol=2)\n\n\n\n\n\nIn addition to the original data, I incorporated three moving average windows: short-term windows of moving averages of 3, two medium-term moving averages of 7 and 11, and finally, the long-term moving average of 25. Upon analysis, it was observed that the 3-MA window didn’t exhibit sufficient change from the original data, while the 25-MA excessively smoothed the data. The most suitable choice for all the moving averages in this series appears to be the 7-MA window. It strikes a balance between capturing important fluctuations and smoothing the data, making it the optimal choice for this dataset.\n\n\n\n\nCode\nma3 &lt;- autoplot(air_ts, series=\"Data\") +\n  autolayer(ma(air_ts,3), series=\"3-MA\") +\n  xlab(\"Date\") + ylab(\"per ton-mile (current cents)\") +\n  ggtitle(\"MSA for U.S. Domestic Air Carrier Average Freight Revenue\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"3-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"3-MA\"))\n\nma7 &lt;- autoplot(air_ts, series=\"Data\") +\n  autolayer(ma(air_ts,7), series=\"7-MA\") +\n  xlab(\"Date\") + ylab(\"per ton-mile (current cents)\") +\n  ggtitle(\"MSA for U.S. Domestic Air Carrier Average Freight Revenue\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"7-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"7-MA\"))\n\n\nma11 &lt;- autoplot(air_ts, series=\"Data\") +\n  autolayer(ma(air_ts,11), series=\"11-MA\") +\n  xlab(\"Date\") + ylab(\"per ton-mile (current cents)\") +\n  ggtitle(\"MSA for U.S. Domestic Air Carrier Average Freight Revenue\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"11-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"11-MA\"))\n\nma15 &lt;- autoplot(air_ts, series=\"Data\") +\n  autolayer(ma(air_ts, 15), series=\"15-MA\") +\n  xlab(\"Date\") + ylab(\"per ton-mile (current cents)\") +\n  ggtitle(\"MSA for U.S. Domestic Air Carrier Average Freight Revenue\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"15-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"15-MA\"))\n\ngrid.arrange(ma3, ma7, ma11, ma15, nrow = 2, ncol=2)\n\n\n\n\n\nIn addition to the original data, I incorporated three moving average windows: short-term windows of moving averages of 3, two medium-term moving averages of 7 and 11, and finally, the long-term moving average of 15. Upon analysis, it became apparent that the best choice for all the moving averages in this series is the 3-MA window. The other moving averages tend to excessively smooth the data, whereas the 3-MA effectively balances smoothing while preserving important fluctuations.\n\n\n\n\nCode\nma3 &lt;- autoplot(ups_ts, series=\"Data\") +\n  autolayer(ma(ups_ts,3), series=\"3-MA\") +\n  xlab(\"Date\") + ylab(\"Stock Price\") +\n  ggtitle(\"MSA for UPS Stock Price\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"3-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"3-MA\"))\n\nma11 &lt;- autoplot(ups_ts, series=\"Data\") +\n  autolayer(ma(ups_ts,11), series=\"11-MA\") +\n  xlab(\"Date\") + ylab(\"Stock Price\") +\n  ggtitle(\"MSA for UPS Stock Price\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"11-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"11-MA\"))\n\nma25 &lt;- autoplot(ups_ts, series=\"Data\") +\n  autolayer(ma(ups_ts, 25), series=\"25-MA\") +\n  xlab(\"Date\") + ylab(\"Stock Price\") +\n  ggtitle(\"MSA for UPS Stock Price\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"25-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"25-MA\"))\n\nma37 &lt;- autoplot(ups_ts, series=\"Data\") +\n  autolayer(ma(ups_ts,37), series=\"37-MA\") +\n  xlab(\"Date\") + ylab(\"Stock Price\") +\n  ggtitle(\"MSA for UPS Stock Price\") +\n  scale_colour_manual(values=c(\"Data\"=\"grey50\",\"37-MA\"=\"red\"),\n                      breaks=c(\"Data\",\"37-MA\"))\n\ngrid.arrange(ma3, ma11, ma25, ma37, nrow = 2, ncol=2)\n\n\n\n\n\nIn addition to the original data, I opted to incorporate three moving average windows: short-term windows of moving averages of 3, two medium-term moving averages of 11, and finally, the long-term moving averages of 25 and 37. Upon analysis, it became apparent that the 3-MA window failed to capture significant changes from the original data, while the 37-MA window excessively smoothed the data. Among the options explored, the 25-MA window emerged as the most optimal choice for all moving averages in this series."
  },
  {
    "objectID": "univariate_ts_model.html#acf-pacf-plots",
    "href": "univariate_ts_model.html#acf-pacf-plots",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "ACF & PACF Plots",
    "text": "ACF & PACF Plots\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexU.S. Domestic Air Carrier Average Freight RevenueUPS Stock Price\n\n\n\n\nCode\nplot1&lt;-ggAcf(canada_ts)+ggtitle(\"U.S.-Canada Freight Value ACF\") + theme_bw()\nplot2&lt;- ggPacf(canada_ts)+theme_bw()+ggtitle(\"U.S.-Canada Freight Value PACF\")\n\ngrid.arrange(plot1, plot2,nrow=2)\n\n\n\n\n\nBased on the ACF and PACF plots, we observe strong correlations at the beginning lags, gradually decreasing but remaining relatively strong until lag 12 in the ACF plot. In contrast, the PACF plot also exhibits strong correlation at lag 1, with moderate correlation extending until lag 13. The presence of significant correlations in both plots suggests that the time series data is non-stationary.\n\n\n\n\nCode\nplot1&lt;-ggAcf(employment_ts)+ggtitle(\"U.S. Air Transportation Employment ACF\") + theme_bw()\nplot2&lt;- ggPacf(employment_ts)+theme_bw()+ggtitle(\"U.S. Air Transportation Employment PACF\")\n\ngrid.arrange(plot1, plot2,nrow=2)\n\n\n\n\n\nBased on the ACF plot, there is strong correlation observed from lag 1 to lag 16, with the correlation gradually decreasing but remaining relatively strong throughout. Similarly, the PACF plot shows strong correlation at lag 1 and lag 2. Given the presence of significant correlations in both plots, we can infer that the series is likely non-stationary.\n\n\n\n\nCode\nplot1&lt;-ggAcf(tsi_ts)+ggtitle(\"U.S. Freight Transportation Services Index ACF\") + theme_bw()\nplot2&lt;- ggPacf(tsi_ts)+theme_bw()+ggtitle(\"U.S. Freight Transportation Services Index PACF\")\n\ngrid.arrange(plot1, plot2,nrow=2)\n\n\n\n\n\nBased on the ACF plot, there is a strong correlation observed at lag 1, with the correlation slightly decreasing but remaining relatively strong until the end of the plot. Similarly, the PACF plot shows strong correlation at lag 1. Given the presence of significant correlations in both plots, we can infer that the series is likely non-stationary.\n\n\n\n\nCode\nplot1&lt;-ggAcf(air_ts)+ggtitle(\"U.S. Domestic Air Carrier Average Freight Revenue ACF\") + theme_bw()\nplot2&lt;- ggPacf(air_ts)+theme_bw()+ggtitle(\"U.S. Domestic Air Carrier Average Freight Revenue PACF\")\n\ngrid.arrange(plot1, plot2,nrow=2)\n\n\n\n\n\nBased on the description provided, the ACF plot demonstrates strong correlation at lag 1 and moderate correlation at lag 2 and lag 3. Additionally, the PACF plot exhibits strong correlation only at lag 1. Given the presence of significant correlations in both plots, particularly at lag 1, and moderate correlation at subsequent lags, we can infer that the series is likely non-stationary.\n\n\n\n\nCode\nplot1&lt;-ggAcf(ups_ts, lag=100)+ggtitle(\"UPS Stock Price ACF\") + theme_bw()\nplot2&lt;- ggPacf(ups_ts, lag=100)+theme_bw()+ggtitle(\"UPS Stock Price PACF\")\n\ngrid.arrange(plot1, plot2,nrow=2)\n\n\n\n\n\nBased on the provided information, it appears that the ACF plot shows strong correlation beginning at lag 1 and then slightly decreasing but remaining strong until the end. Additionally, the PACF plot exhibits strong correlation only at lag 1. Given the presence of significant correlations in both plots, particularly at lag 1, and the sustained autocorrelation observed in the ACF plot, we can infer that the series is likely non-stationary."
  },
  {
    "objectID": "univariate_ts_model.html#adjusted-dickey-fuller-test",
    "href": "univariate_ts_model.html#adjusted-dickey-fuller-test",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "Adjusted Dickey-Fuller Test",
    "text": "Adjusted Dickey-Fuller Test\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexU.S. Domestic Air Carrier Average Freight RevenueUPS Stock Price\n\n\n\n\nCode\ntseries::adf.test(canada_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  canada_ts\nDickey-Fuller = -3.0511, Lag order = 5, p-value = 0.1356\nalternative hypothesis: stationary\n\n\nWith a p-value higher than 0.05, there is insufficient evidence to reject the null hypothesis at the 5% significance level. Consequently, we can conclude that our series is non-stationary. This conclusion aligns with the earlier analysis, where strong autocorrelation was observed in the ACF and PACF plots, indicating non-stationarity.\n\n\n\n\nCode\ntseries::adf.test(employment_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  employment_ts\nDickey-Fuller = -3.1311, Lag order = 6, p-value = 0.1008\nalternative hypothesis: stationary\n\n\nWith a p-value higher than 0.05, there is insufficient evidence to reject the null hypothesis at the 5% significance level. Consequently, we can conclude that our series is non-stationary. This conclusion aligns with the earlier analysis, where strong autocorrelation was observed in the ACF and PACF plots, indicating non-stationarity.\n\n\n\n\nCode\ntseries::adf.test(tsi_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  tsi_ts\nDickey-Fuller = -2.4166, Lag order = 6, p-value = 0.4005\nalternative hypothesis: stationary\n\n\nWith a p-value higher than 0.05, there is insufficient evidence to reject the null hypothesis at the 5% significance level. Consequently, we can conclude that our series is non-stationary. This conclusion aligns with the earlier analysis, where strong autocorrelation was observed in the ACF and PACF plots, indicating non-stationarity.\n\n\n\n\nCode\ntseries::adf.test(air_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  air_ts\nDickey-Fuller = -0.85187, Lag order = 2, p-value = 0.9424\nalternative hypothesis: stationary\n\n\nWith a p-value higher than 0.05, there is insufficient evidence to reject the null hypothesis at the 5% significance level. Consequently, we can conclude that our series is non-stationary. This conclusion aligns with the earlier analysis, where strong autocorrelation was observed in the ACF and PACF plots, indicating non-stationarity.\n\n\n\n\nCode\ntseries::adf.test(ups_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  ups_ts\nDickey-Fuller = -2.2106, Lag order = 12, p-value = 0.4892\nalternative hypothesis: stationary\n\n\nWith a p-value higher than 0.05, there is insufficient evidence to reject the null hypothesis at the 5% significance level. Consequently, we can conclude that our series is non-stationary. This conclusion aligns with the earlier analysis, where strong autocorrelation was observed in the ACF and PACF plots, indicating non-stationarity."
  },
  {
    "objectID": "univariate_ts_model.html#differencing",
    "href": "univariate_ts_model.html#differencing",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "Differencing",
    "text": "Differencing\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexU.S. Domestic Air Carrier Average Freight RevenueUPS Stock Price\n\n\n\n\nCode\nrequire(gridExtra)\nfit = lm(canada_ts~time(canada_ts), na.action=NULL)\n\nplot1&lt;-autoplot(diff(canada_ts), main=\"First Difference\") +theme_bw()\nplot2 &lt;- ggAcf(diff(canada_ts), 48) + ggtitle(\"First Difference Data\")+theme_bw()\n\ngrid.arrange(plot1, plot2,nrow=2)\n\n\n\n\n\nCode\ncanada_ts %&gt;% diff() %&gt;% ggtsdisplay()\n\n\n\n\n\nThe differenced data exhibits greater stationarity compared to the originaldata. This improvement is evident in the ACF plot of the differenced data, which shows a significant drop-off, indicating a substantial reduction in autocorrelation beyond those lags. However, despite the improvement, the first order difference still shows some seasonality in the plot, suggesting that further differencing may be necessary to fully address the seasonality present in the data.\n\n\nCode\nplot1 &lt;- ggAcf(diff(canada_ts), 48) + ggtitle(\"First Difference Data\")+theme_bw()\nplot2 &lt;- ggAcf(diff(diff(canada_ts)), 48) + ggtitle(\"Second Differenced Data\") + theme_bw()\n\ngrid.arrange(plot1, plot2, nrow=2)\n\n\n\n\n\nCode\ncanada_ts %&gt;% diff() %&gt;% diff() %&gt;% ggtsdisplay()\n\n\n\n\n\nAfter applying a second-order difference, the ACF plot shows even stronger autocorrelation. The second differenced ACF plot shows that the data be over differenced. Consequently, I have opted to retain the first-order difference data, as it achieves a satisfactory level of stationarity.\n\n\n\n\nCode\nrequire(gridExtra)\nfit1 = lm(employment_ts~time(employment_ts), na.action=NULL)\n\nplot1&lt;-autoplot(diff(employment_ts), main=\"First Difference\") +theme_bw()\nplot2 &lt;- ggAcf(diff(employment_ts), 48) + ggtitle(\"First Difference Data\")+theme_bw()\n\ngrid.arrange(plot1, plot2,nrow=2)\n\n\n\n\n\nCode\nemployment_ts %&gt;% diff() %&gt;% ggtsdisplay()\n\n\n\n\n\nThe differenced data exhibits greater stationarity compared to the original data. This improvement is evident in the ACF plot of the differenced data, which shows a significant drop-off, indicating a substantial reduction in autocorrelation beyond those lags. However, despite the improvement, the first order difference still shows some seasonality in the plot, suggesting that further differencing may be necessary to fully address the seasonality present in the data.\n\n\nCode\nplot1 &lt;- ggAcf(diff(employment_ts), 48) + ggtitle(\"First Difference Data\")+theme_bw()\nplot2 &lt;- ggAcf(diff(diff(employment_ts)), 48) + ggtitle(\"Second Differenced Data\") + theme_bw()\n\ngrid.arrange(plot1, plot2, nrow=2)\n\n\n\n\n\nCode\nemployment_ts %&gt;% diff() %&gt;% diff() %&gt;% ggtsdisplay()\n\n\n\n\n\nThe plot above clearly demonstrates that Second Order Differencing effectively renders the data stationary, which is a crucial prerequisite for accurate modeling.\n\n\n\n\nCode\nrequire(gridExtra)\nfit2 = lm(tsi_ts~time(tsi_ts), na.action=NULL)\n\nplot1&lt;- autoplot(diff(tsi_ts), main=\"First Difference\") +theme_bw()\nplot2 &lt;- ggAcf(diff(tsi_ts), 48) + ggtitle(\"First Difference Data\")+theme_bw()\n\ngrid.arrange(plot1, plot2,nrow=2)\n\n\n\n\n\nCode\ntsi_ts %&gt;% diff() %&gt;% ggtsdisplay()\n\n\n\n\n\nFrom both the original plots and the ACF plots, it’s evident that the differenced data exhibits greater stationarity compared to the original data. The ACF plot of the differenced data shows a significant drop-off, indicating a lack of autocorrelation beyond those lags, which is characteristic of stationary data.\n\n\n\n\nCode\nrequire(gridExtra)\nfit3 = lm(air_ts~time(air_ts), na.action=NULL)\n\nplot1&lt;-autoplot(diff(air_ts), main=\"First Difference\") +theme_bw()\nplot2 &lt;- ggAcf(diff(air_ts), 48) + ggtitle(\"First Difference Data\")+theme_bw()\n\ngrid.arrange(plot1, plot2,nrow=2)\n\n\n\n\n\nCode\nair_ts %&gt;% diff() %&gt;% ggtsdisplay()\n\n\n\n\n\nThe differenced data exhibit greater stationarity compared to the original data. This improvement is evident in the ACF plot of the differenced data, which show a significant drop-off, indicating a lack of autocorrelation beyond those lags. This drop-off is characteristic of stationary data.\n\n\n\n\nCode\nrequire(gridExtra)\nfit4 = lm(ups_ts~time(ups_ts), na.action=NULL)\n\nplot1&lt;-autoplot(diff(ups_ts), main=\"First Difference\") +theme_bw()\nplot2 &lt;- ggAcf(diff(ups_ts), 48) + ggtitle(\"First Difference Data\")+theme_bw()\n\ngrid.arrange(plot1, plot2,nrow=2)\n\n\n\n\n\nCode\nups_ts %&gt;% diff() %&gt;% ggtsdisplay(lag=48)\n\n\n\n\n\nThe differenced data exhibits greater stationarity compared to the original. This improvement is evident in the ACF plot of the differenced data, which shows a significant drop-off, indicating a substantial reduction in autocorrelation beyond those lags. However, despite the improvement, the First Order Difference still shows some seasonality in the plot, suggesting that further differencing may be necessary to fully address the seasonality present in the data.\n\n\nCode\nplot1 &lt;- ggAcf(diff(ups_ts), 48) + ggtitle(\"First Difference Data\")+theme_bw()\nplot2 &lt;- ggAcf(diff(diff(ups_ts)), 48) + ggtitle(\"Second Differenced Data\") + theme_bw()\n\ngrid.arrange(plot1, plot2, nrow=2)\n\n\n\n\n\nCode\nups_ts %&gt;% diff() %&gt;% diff() %&gt;% ggtsdisplay(lag=48)\n\n\n\n\n\nAfter performing a second-order difference, strong negative autocorrelation is observed at lag 1 in the ACF plot. The second differenced ACF plot shows that the data be over differenced. Therefore, I have decided to retain the first-order difference data, as it achieves a satisfactory level of stationarity."
  },
  {
    "objectID": "univariate_ts_model.html#adjusted-dickey-fuller-test-on-original-data",
    "href": "univariate_ts_model.html#adjusted-dickey-fuller-test-on-original-data",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "Adjusted Dickey-Fuller Test On Original Data",
    "text": "Adjusted Dickey-Fuller Test On Original Data\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexU.S. Domestic Air Carrier Average Freight RevenueUPS Stock Price\n\n\n\n\nCode\ntseries::adf.test(canada_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  canada_ts\nDickey-Fuller = -3.0511, Lag order = 5, p-value = 0.1356\nalternative hypothesis: stationary\n\n\nWith a p-value higher than 0.05, there is insufficient evidence to reject the null hypothesis at the 5% significance level. Consequently, we can conclude that our series is non-stationary. This conclusion aligns with the earlier analysis, where strong autocorrelation was observed in the ACF and PACF plots, indicating non-stationarity.\n\n\n\n\nCode\ntseries::adf.test(employment_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  employment_ts\nDickey-Fuller = -3.1311, Lag order = 6, p-value = 0.1008\nalternative hypothesis: stationary\n\n\nWith a p-value higher than 0.05, there is insufficient evidence to reject the null hypothesis at the 5% significance level. Consequently, we can conclude that our series is non-stationary. This conclusion aligns with the earlier analysis, where strong autocorrelation was observed in the ACF and PACF plots, indicating non-stationarity.\n\n\n\n\nCode\ntseries::adf.test(tsi_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  tsi_ts\nDickey-Fuller = -2.4166, Lag order = 6, p-value = 0.4005\nalternative hypothesis: stationary\n\n\nWith a p-value higher than 0.05, there is insufficient evidence to reject the null hypothesis at the 5% significance level. Consequently, we can conclude that our series is non-stationary. This conclusion aligns with the earlier analysis, where strong autocorrelation was observed in the ACF and PACF plots, indicating non-stationarity.\n\n\n\n\nCode\ntseries::adf.test(air_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  air_ts\nDickey-Fuller = -0.85187, Lag order = 2, p-value = 0.9424\nalternative hypothesis: stationary\n\n\nWith a p-value higher than 0.05, there is insufficient evidence to reject the null hypothesis at the 5% significance level. Consequently, we can conclude that our series is non-stationary. This conclusion aligns with the earlier analysis, where strong autocorrelation was observed in the ACF and PACF plots, indicating non-stationarity.\n\n\n\n\nCode\ntseries::adf.test(ups_ts)\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  ups_ts\nDickey-Fuller = -2.2106, Lag order = 12, p-value = 0.4892\nalternative hypothesis: stationary\n\n\nWith a p-value higher than 0.05, there is insufficient evidence to reject the null hypothesis at the 5% significance level. Consequently, we can conclude that our series is non-stationary. This conclusion aligns with the earlier analysis, where strong autocorrelation was observed in the ACF and PACF plots, indicating non-stationarity."
  },
  {
    "objectID": "univariate_ts_model.html#adjusted-dickey-fuller-test-on-differencing-data",
    "href": "univariate_ts_model.html#adjusted-dickey-fuller-test-on-differencing-data",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "Adjusted Dickey-Fuller Test On Differencing Data",
    "text": "Adjusted Dickey-Fuller Test On Differencing Data\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexU.S. Domestic Air Carrier Average Freight RevenueUPS Stock Price\n\n\n\n\nCode\ntseries::adf.test(diff(canada_ts))\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  diff(canada_ts)\nDickey-Fuller = -6.549, Lag order = 5, p-value = 0.01\nalternative hypothesis: stationary\n\n\nWith a p-value smaller than 0.05, there is sufficient evidence to reject the null hypothesis at the 5% significance level. Consequently, we can conclude that our series is stationary. This conclusion aligns with the earlier analysis, where strong autocorrelation was observed in the ACF and PACF plots, indicating stationarity.\n\n\n\n\nCode\ntseries::adf.test(diff(diff(employment_ts)))\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  diff(diff(employment_ts))\nDickey-Fuller = -9.6886, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\nWith a p-value smaller than 0.05, there is sufficient evidence to reject the null hypothesis at the 5% significance level. Consequently, we can conclude that our series is stationary. This conclusion aligns with the earlier analysis, where strong autocorrelation was observed in the ACF and PACF plots, indicating stationarity.\n\n\n\n\nCode\ntseries::adf.test(diff(tsi_ts))\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  diff(tsi_ts)\nDickey-Fuller = -5.025, Lag order = 6, p-value = 0.01\nalternative hypothesis: stationary\n\n\nWith a p-value smaller than 0.05, there is sufficient evidence to reject the null hypothesis at the 5% significance level. Consequently, we can conclude that our series is stationary. This conclusion aligns with the earlier analysis, where strong autocorrelation was observed in the ACF and PACF plots, indicating stationarity.\n\n\n\n\nCode\ntseries::adf.test(diff(air_ts))\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  diff(air_ts)\nDickey-Fuller = -2.1674, Lag order = 2, p-value = 0.5086\nalternative hypothesis: stationary\n\n\nWith a p-value higher than 0.05, there is insufficient evidence to reject the null hypothesis at the 5% significance level. Consequently, we can conclude that our series is non-stationary. This conclusion againest with the earlier analysis, where lack of autocorrelation was observed in the ACF and PACF plots, indicating the data almost stationary.\n\n\n\n\nCode\ntseries::adf.test(diff(ups_ts))\n\n\n\n    Augmented Dickey-Fuller Test\n\ndata:  diff(ups_ts)\nDickey-Fuller = -11.498, Lag order = 12, p-value = 0.01\nalternative hypothesis: stationary\n\n\nWith a p-value smaller than 0.05, there is sufficient evidence to reject the null hypothesis at the 5% significance level. Consequently, we can conclude that our series is stationary. This conclusion aligns with the earlier analysis, where strong autocorrelation was observed in the ACF and PACF plots, indicating stationarity."
  },
  {
    "objectID": "univariate_ts_model.html#arimapdq",
    "href": "univariate_ts_model.html#arimapdq",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "ARIMA(p,d,q)",
    "text": "ARIMA(p,d,q)\nIn this section, we will identify potential values for the parameters p and q based on the significant lags observed in the PACF and ACF plots of the original data, respectively. Specifically, we will consider the most significant lags from the PACF plot for the value of p, and from the ACF plot for the value of q.\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexU.S. Domestic Air Carrier Average Freight RevenueUPS Stock Price\n\n\np = 0,1,2 d = 0,1,2, q = 0,1,2,3\n\n\nCode\n## empty list to store model fits\n\nARMA_res &lt;- list()\n\n## set counter\ncc &lt;-1\n\n## loop over AR\nfor(p in 0:2){\n  ## loop over MA\n  for(q in 0:3){\n    ## loop over I\n    for(d in 0:2){\n      ARMA_res[[cc]]&lt;-Arima(y=canada_ts,order = c(p,d,q), include.drift = TRUE)\n      cc&lt;- cc+1\n    }\n  }\n}\n\n## get AIC values for model evaluation\nARMA_AIC&lt;-sapply(ARMA_res,function(x) x$aic)\nARMA_res[[which(ARMA_AIC == min(ARMA_AIC))]]\n\n\nSeries: canada_ts \nARIMA(2,2,3) \n\nCoefficients:\n          ar1      ar2     ma1      ma2     ma3\n      -1.7310  -0.9992  0.7457  -0.7457  -1.000\ns.e.   0.0025   0.0013  0.0251   0.0242   0.026\n\nsigma^2 = 9.987:  log likelihood = -525.66\nAIC=1063.32   AICc=1063.74   BIC=1083.19\n\n\nCode\n## get BIC values for model evaluation\nARMA_BIC&lt;-sapply(ARMA_res,function(x) x$bic)\nARMA_res[[which(ARMA_BIC == min(ARMA_BIC))]]\n\n\nSeries: canada_ts \nARIMA(2,2,3) \n\nCoefficients:\n          ar1      ar2     ma1      ma2     ma3\n      -1.7310  -0.9992  0.7457  -0.7457  -1.000\ns.e.   0.0025   0.0013  0.0251   0.0242   0.026\n\nsigma^2 = 9.987:  log likelihood = -525.66\nAIC=1063.32   AICc=1063.74   BIC=1083.19\n\n\nThe model with the lowest AIC and BIC is ARIMA(2,2,3).\n\n\np = 0,1,2, d = 0,1,2, q = 0,1,2,3\n\n\nCode\n## empty list to store model fits\n\nARMA_res &lt;- list()\n\n## set counter\ncc &lt;-1\n\n## loop over AR\nfor(p in 0:2){\n  ## loop over MA\n  for(q in 0:3){\n    ## loop over I\n    for(d in 0:2){\n    \n      ARMA_res[[cc]]&lt;-Arima(y=employment_ts,order = c(p,d,q), include.drift = TRUE)\n      cc&lt;- cc+1\n    }\n  }\n}\n\n## get AIC values for model evaluation\nARMA_AIC&lt;-sapply(ARMA_res,function(x) x$aic)\nARMA_res[[which(ARMA_AIC == min(ARMA_AIC))]]\n\n\nSeries: employment_ts \nARIMA(2,2,3) \n\nCoefficients:\n         ar1      ar2      ma1     ma2      ma3\n      0.4253  -0.5218  -0.9902  0.3708  -0.3806\ns.e.  0.1897   0.1252   0.1912  0.1990   0.1703\n\nsigma^2 = 40180919:  log likelihood = -2309.48\nAIC=4630.96   AICc=4631.35   BIC=4651.51\n\n\nCode\n## get BIC values for model evaluation\nARMA_BIC&lt;-sapply(ARMA_res,function(x) x$bic)\nARMA_res[[which(ARMA_BIC == min(ARMA_BIC))]]\n\n\nSeries: employment_ts \nARIMA(2,2,1) \n\nCoefficients:\n         ar1      ar2      ma1\n      0.4688  -0.2364  -1.0000\ns.e.  0.0644   0.0643   0.0143\n\nsigma^2 = 40643462:  log likelihood = -2311.73\nAIC=4631.45   AICc=4631.63   BIC=4645.15\n\n\nCode\n## get AICC values for model evaluation\nARMA_AICC&lt;-sapply(ARMA_res,function(x) x$aicc)\nARMA_res[[which(ARMA_AICC == min(ARMA_AICC))]]\n\n\nSeries: employment_ts \nARIMA(2,2,3) \n\nCoefficients:\n         ar1      ar2      ma1     ma2      ma3\n      0.4253  -0.5218  -0.9902  0.3708  -0.3806\ns.e.  0.1897   0.1252   0.1912  0.1990   0.1703\n\nsigma^2 = 40180919:  log likelihood = -2309.48\nAIC=4630.96   AICc=4631.35   BIC=4651.51\n\n\nThe model with the lowest AIC and BIC is ARIMA(2,2,3).\n\n\np = 0,1, d = 0,1, q = 0,1,2,3\n\n\nCode\n## empty list to store model fits\n\nARMA_res &lt;- list()\n\n## set counter\ncc &lt;-1\n\n## loop over AR\nfor(p in 0:1){\n  ## loop over MA\n  for(q in 0:3){\n    ## loop over I\n    for(d in 0:1){\n    \n      ARMA_res[[cc]]&lt;-Arima(y=tsi_ts,order = c(p,d,q), include.drift = TRUE)\n      cc&lt;- cc+1\n    }\n  }\n}\n\n## get AIC values for model evaluation\nARMA_AIC&lt;-sapply(ARMA_res,function(x) x$aic)\nARMA_res[[which(ARMA_AIC == min(ARMA_AIC))]]\n\n\nSeries: tsi_ts \nARIMA(0,1,3) with drift \n\nCoefficients:\n          ma1      ma2     ma3   drift\n      -0.0700  -0.0927  0.1035  0.1127\ns.e.   0.0608   0.0580  0.0578  0.0837\n\nsigma^2 = 2.217:  log likelihood = -499.51\nAIC=1009.03   AICc=1009.25   BIC=1027.13\n\n\nCode\n## get BIC values for model evaluation\nARMA_BIC&lt;-sapply(ARMA_res,function(x) x$bic)\nARMA_res[[which(ARMA_BIC == min(ARMA_BIC))]]\n\n\nSeries: tsi_ts \nARIMA(0,1,0) with drift \n\nCoefficients:\n       drift\n      0.1141\ns.e.  0.0901\n\nsigma^2 = 2.246:  log likelihood = -502.8\nAIC=1009.61   AICc=1009.65   BIC=1016.85\n\n\nCode\n## get AICC values for model evaluation\nARMA_AICC&lt;-sapply(ARMA_res,function(x) x$aicc)\nARMA_res[[which(ARMA_AICC == min(ARMA_AICC))]]\n\n\nSeries: tsi_ts \nARIMA(0,1,3) with drift \n\nCoefficients:\n          ma1      ma2     ma3   drift\n      -0.0700  -0.0927  0.1035  0.1127\ns.e.   0.0608   0.0580  0.0578  0.0837\n\nsigma^2 = 2.217:  log likelihood = -499.51\nAIC=1009.03   AICc=1009.25   BIC=1027.13\n\n\nThe model with the lowest AIC and BIC is ARIMA(0,1,3).\n\n\np = 0,1, d = 0,1, q = 0,1,2\n\n\nCode\n## empty list to store model fits\n\nARMA_res &lt;- list()\n\n## set counter\ncc &lt;-1\n\n## loop over AR\nfor(p in 0:1){\n  ## loop over MA\n  for(q in 0:2){\n    ## loop over I\n    for(d in 0:1){\n    \n      ARMA_res[[cc]]&lt;-Arima(y=air_ts,order = c(p,d,q), include.drift = TRUE)\n      cc&lt;- cc+1\n    }\n  }\n}\n\n## get AIC values for model evaluation\nARMA_AIC&lt;-sapply(ARMA_res,function(x) x$aic)\nARMA_res[[which(ARMA_AIC == min(ARMA_AIC))]]\n\n\nSeries: air_ts \nARIMA(0,1,1) with drift \n\nCoefficients:\n         ma1    drift\n      1.0000  -0.1510\ns.e.  0.2724   5.1467\n\nsigma^2 = 161:  log likelihood = -83.65\nAIC=173.3   AICc=174.71   BIC=176.43\n\n\nCode\n## get BIC values for model evaluation\nARMA_BIC&lt;-sapply(ARMA_res,function(x) x$bic)\nARMA_res[[which(ARMA_BIC == min(ARMA_BIC))]]\n\n\nSeries: air_ts \nARIMA(0,1,1) with drift \n\nCoefficients:\n         ma1    drift\n      1.0000  -0.1510\ns.e.  0.2724   5.1467\n\nsigma^2 = 161:  log likelihood = -83.65\nAIC=173.3   AICc=174.71   BIC=176.43\n\n\nThe model with the lowest AIC and BIC is ARIMA(0,1,1).\n\n\np = 0,1, d = 0,1,2, q = 0,1,2\n\n\nCode\n## empty list to store model fits\n\nARMA_res &lt;- list()\n\n## set counter\ncc &lt;-1\n\n## loop over AR\nfor(p in 0:1){\n  ## loop over MA\n  for(q in 0:2){\n    ## loop over I\n    for(d in 0:2){\n    \n      ARMA_res[[cc]]&lt;-Arima(y=ups_ts,order = c(p,d,q), include.drift = TRUE)\n      cc&lt;- cc+1\n    }\n  }\n}\n\n## get AIC values for model evaluation\nARMA_AIC&lt;-sapply(ARMA_res,function(x) x$aic)\nARMA_res[[which(ARMA_AIC == min(ARMA_AIC))]]\n\n\nSeries: ups_ts \nARIMA(0,1,0) with drift \n\nCoefficients:\n       drift\n      0.0366\ns.e.  0.0557\n\nsigma^2 = 5.465:  log likelihood = -3989.16\nAIC=7982.32   AICc=7982.33   BIC=7993.26\n\n\nCode\n## get BIC values for model evaluation\nARMA_BIC&lt;-sapply(ARMA_res,function(x) x$bic)\nARMA_res[[which(ARMA_BIC == min(ARMA_BIC))]]\n\n\nSeries: ups_ts \nARIMA(0,1,0) with drift \n\nCoefficients:\n       drift\n      0.0366\ns.e.  0.0557\n\nsigma^2 = 5.465:  log likelihood = -3989.16\nAIC=7982.32   AICc=7982.33   BIC=7993.26\n\n\nThe model with the lowest AIC and BIC is ARIMA(0,1,0)."
  },
  {
    "objectID": "univariate_ts_model.html#fit-best-arimapdq-diagnostics",
    "href": "univariate_ts_model.html#fit-best-arimapdq-diagnostics",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "Fit Best ARIMA(p,d,q) & Diagnostics",
    "text": "Fit Best ARIMA(p,d,q) & Diagnostics\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexU.S. Domestic Air Carrier Average Freight RevenueUPS Stock Price\n\n\n\n\nCode\nARMA_res_canada&lt;-Arima(y=canada_ts,order = c(2,2,3), include.drift = TRUE)\nsummary(ARMA_res_canada)\n\n\nSeries: canada_ts \nARIMA(2,2,3) \n\nCoefficients:\n          ar1      ar2     ma1      ma2     ma3\n      -1.7310  -0.9992  0.7457  -0.7457  -1.000\ns.e.   0.0025   0.0013  0.0251   0.0242   0.026\n\nsigma^2 = 9.987:  log likelihood = -525.66\nAIC=1063.32   AICc=1063.74   BIC=1083.19\n\nTraining set error measures:\n                      ME     RMSE      MAE        MPE     MAPE      MASE\nTraining set -0.02179075 3.105814 2.276102 -0.2721476 4.798624 0.3998011\n                    ACF1\nTraining set -0.01487147\n\n\nEquation: \\(x_t= 0.269*x_{t-1} +3.4612*x_{t-2} +0.2674*x_{t-3} +0.9992*x_{t-4}+w_t +0.7457*w_{t-1} -0.7457*w_{t-2} -w_{t-3}\\)\n\n\nCode\noutput &lt;- capture.output(sarima(canada_ts,2,2,3))\n\n\n\n\n\nCode\ncat(output[120:131], output[length(output)], sep = \"\\n\") \n\n\nCoefficients: \n    Estimate     SE   t.value p.value\nar1  -1.7310 0.0025 -701.3924       0\nar2  -0.9992 0.0013 -759.3772       0\nma1   0.7457 0.0251   29.6534       0\nma2  -0.7457 0.0242  -30.8026       0\nma3  -1.0000 0.0260  -38.3988       0\n\nsigma^2 estimated as 9.741094 on 198 degrees of freedom \n \nAIC = 5.238006  AICc = 5.239506  BIC = 5.335933 \n \n \n\n\nUpon inspection of the time plot of the standardized residuals above, no discernible patterns are evident. However, the ACF plot of the standardized residuals indicates some remaining correlation. The normal Q-Q plot of the residuals suggests that the assumption of normality is reasonable, with the exception of potential outliers. The results of the Ljung-Box test reveal values below the 0.05 (5% significance) threshold, indicating the presence of some significant correlation remaining. Despite these findings, it appears that the model has been improved.\n\n\n\n\nCode\nARMA_res_employment&lt;-Arima(y=employment_ts,order = c(2,2,3), include.drift = TRUE)\nsummary(ARMA_res_employment)\n\n\nSeries: employment_ts \nARIMA(2,2,3) \n\nCoefficients:\n         ar1      ar2      ma1     ma2      ma3\n      0.4253  -0.5218  -0.9902  0.3708  -0.3806\ns.e.  0.1897   0.1252   0.1912  0.1990   0.1703\n\nsigma^2 = 40180919:  log likelihood = -2309.48\nAIC=4630.96   AICc=4631.35   BIC=4651.51\n\nTraining set error measures:\n                   ME     RMSE      MAE        MPE      MAPE      MASE\nTraining set 263.3125 6241.208 2809.261 0.05105339 0.6005098 0.1456793\n                    ACF1\nTraining set 0.009897766\n\n\nEquation: \\(x_t= 2.8506*x_{t-1} -2.3724*x_{t-2} -0.6183*x_{t-3} -0.5218*x_{t-4} +w_t -0.9902*w_{t-1} +0.3708*w_{t-2} -0.3806*w_{t-3}\\)\n\n\nCode\noutput &lt;- capture.output(sarima(employment_ts,2,2,3))\n\n\n\n\n\nCode\ncat(output[55:66], output[length(output)], sep = \"\\n\") \n\n\nCoefficients: \n    Estimate     SE t.value p.value\nar1   0.4253 0.1897  2.2413  0.0260\nar2  -0.5218 0.1252 -4.1690  0.0000\nma1  -0.9902 0.1912 -5.1783  0.0000\nma2   0.3708 0.1990  1.8633  0.0637\nma3  -0.3806 0.1703 -2.2346  0.0264\n\nsigma^2 estimated as 39293604 on 222 degrees of freedom \n \nAIC = 20.40072  AICc = 20.40192  BIC = 20.49125 \n \n \n\n\nUpon examining the time plot of the standardized residuals, no discernible patterns are evident. Additionally, the ACF plot of the standardized residuals reveals no significant departures from the model assumptions, as no significant lags are observed. The normal Q-Q plot of the residuals indicates that the assumption of normality is reasonable, with the exception of possible outliers. Furthermore, the Ljung-Box test yields favorable values exceeding 0.05, suggesting the absence of significant correlation and indicating a well-fitted model. Overall, these observations suggest that the model fits the data well.\n\n\n\n\nCode\nARMA_res_tsi&lt;-Arima(y=tsi_ts,order = c(0,1,3), include.drift = TRUE)\nsummary(ARMA_res_tsi)\n\n\nSeries: tsi_ts \nARIMA(0,1,3) with drift \n\nCoefficients:\n          ma1      ma2     ma3   drift\n      -0.0700  -0.0927  0.1035  0.1127\ns.e.   0.0608   0.0580  0.0578  0.0837\n\nsigma^2 = 2.217:  log likelihood = -499.51\nAIC=1009.03   AICc=1009.25   BIC=1027.13\n\nTraining set error measures:\n                       ME     RMSE      MAE         MPE      MAPE      MASE\nTraining set 0.0007283871 1.475506 1.068367 -0.01205377 0.9267941 0.2634875\n                    ACF1\nTraining set 0.004977272\n\n\nEquation: \\(x_t= x_{t-1} +w_t -0.07*w_{t-1} -0.0927*w_{t-2} +0.1035*w_{t-3} +0.1127\\)\n\n\nCode\noutput &lt;- capture.output(sarima(tsi_ts,0,1,3))\n\n\n\n\n\nCode\ncat(output[21:31], output[length(output)], sep = \"\\n\") \n\n\nCoefficients: \n         Estimate     SE t.value p.value\nma1       -0.0700 0.0608 -1.1505  0.2509\nma2       -0.0927 0.0580 -1.6003  0.1107\nma3        0.1035 0.0578  1.7915  0.0743\nconstant   0.1127 0.0837  1.3458  0.1795\n\nsigma^2 estimated as 2.184965 on 272 degrees of freedom \n \nAIC = 3.655896  AICc = 3.656431  BIC = 3.721483 \n \n \n\n\nUpon examining the time plot of the standardized residuals, no discernible patterns are evident. Additionally, the ACF plot of the standardized residuals reveals no significant departures from the model assumptions, as no significant lags are observed. The normal Q-Q plot of the residuals indicates that the assumption of normality is reasonable, with the exception of possible outliers. Furthermore, the Ljung-Box test yields favorable values exceeding 0.05, suggesting the absence of significant correlation and indicating a well-fitted model. Overall, these observations suggest that the model fits the data well.\n\n\n\n\nCode\nARMA_res_air&lt;-Arima(y=air_ts,order = c(0,1,1), include.drift = TRUE)\nsummary(ARMA_res_air)\n\n\nSeries: air_ts \nARIMA(0,1,1) with drift \n\nCoefficients:\n         ma1    drift\n      1.0000  -0.1510\ns.e.  0.2724   5.1467\n\nsigma^2 = 161:  log likelihood = -83.65\nAIC=173.3   AICc=174.71   BIC=176.43\n\nTraining set error measures:\n                    ME     RMSE      MAE       MPE     MAPE      MASE      ACF1\nTraining set 0.2965719 11.79289 8.992931 0.1888945 9.662775 0.8915005 -0.264417\n\n\nEquation: \\(x_t= x_{t-1} +w_t +w_{t-1} -0.151\\)\n\n\nCode\noutput &lt;- capture.output(sarima(air_ts,0,1,1))\n\n\n\n\n\nCode\ncat(output[30:38], output[length(output)], sep = \"\\n\") \n\n\nCoefficients: \n         Estimate     SE t.value p.value\nma1         1.000 0.2724  3.6708  0.0016\nconstant   -0.151 5.1467 -0.0293  0.9769\n\nsigma^2 estimated as 145.6943 on 19 degrees of freedom \n \nAIC = 8.252253  AICc = 8.283999  BIC = 8.40147 \n \n \n\n\nUpon examining the time plot of the standardized residuals, no discernible patterns are evident. Additionally, the ACF plot of the standardized residuals reveals no significant departures from the model assumptions, as no significant lags are observed. The normal Q-Q plot of the residuals indicates that the assumption of normality is reasonable, with the exception of possible outliers. Furthermore, the Ljung-Box test yields favorable values exceeding 0.05, suggesting the absence of significant correlation and indicating a well-fitted model. Overall, these observations suggest that the model fits the data well.\n\n\n\n\nCode\nARMA_res_ups&lt;-Arima(y=ups_ts,order = c(0,1,0), include.drift = TRUE)\nsummary(ARMA_res_ups)\n\n\nSeries: ups_ts \nARIMA(0,1,0) with drift \n\nCoefficients:\n       drift\n      0.0366\ns.e.  0.0557\n\nsigma^2 = 5.465:  log likelihood = -3989.16\nAIC=7982.32   AICc=7982.33   BIC=7993.26\n\nTraining set error measures:\n                       ME     RMSE      MAE         MPE     MAPE       MASE\nTraining set 5.173999e-05 2.336454 1.513771 -0.01543306 1.161839 0.04821099\n                   ACF1\nTraining set 0.03201837\n\n\nEquation: \\(x_t= x_{t-1} + w_t +0.0366\\)\n\n\nCode\noutput &lt;- capture.output(sarima(ups_ts,0,1,0))\n\n\n\n\n\nCode\ncat(output[11:18], output[length(output)], sep = \"\\n\") \n\n\nCoefficients: \n         Estimate     SE t.value p.value\nconstant   0.0366 0.0557  0.6569  0.5113\n\nsigma^2 estimated as 5.462114 on 1758 degrees of freedom \n \nAIC = 4.537987  AICc = 4.537988  BIC = 4.544209 \n \n \n\n\nUpon examining the time plot of the standardized residuals, no discernible patterns are evident. Additionally, the ACF plot of the standardized residuals reveals no significant departures from the model assumptions, as no significant lags are observed. The normal Q-Q plot of the residuals indicates that the assumption of normality is reasonable, with the exception of possible outliers. Furthermore, the Ljung-Box test yields favorable values exceeding 0.05, suggesting the absence of significant correlation and indicating a well-fitted model. Overall, these observations suggest that the model fits the data well."
  },
  {
    "objectID": "univariate_ts_model.html#auto-arima",
    "href": "univariate_ts_model.html#auto-arima",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "Auto ARIMA",
    "text": "Auto ARIMA\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexU.S. Domestic Air Carrier Average Freight RevenueUPS Stock Price\n\n\n\n\nCode\nauto.arima(canada_ts)\n\n\nSeries: canada_ts \nARIMA(2,1,5)(1,0,0)[12] \n\nCoefficients:\n          ar1      ar2     ma1     ma2     ma3      ma4     ma5    sar1\n      -0.1410  -0.4216  0.1452  0.4440  0.0703  -0.3019  0.2020  0.5636\ns.e.   0.1988   0.2128  0.1977  0.2187  0.0836   0.0907  0.1092  0.0718\n\nsigma^2 = 8.695:  log likelihood = -508.85\nAIC=1035.71   AICc=1036.63   BIC=1065.57\n\n\nThe best model provided by Auto ARIMA differs from the best model identified in the previous step. This discrepancy suggests that the Auto ARIMA model may offer a better fit compared to the previously chosen model, which was not optimal. It is plausible that this dataset exhibits strong seasonality, which ARIMA alone may struggle to capture adequately. Therefore, considering SARIMA models might be necessary to effectively model the seasonality present in the data.\n\n\n\n\nCode\nauto.arima(employment_ts)\n\n\nSeries: employment_ts \nARIMA(0,1,1) \n\nCoefficients:\n         ma1\n      0.4204\ns.e.  0.0536\n\nsigma^2 = 41251784:  log likelihood = -2322.12\nAIC=4648.25   AICc=4648.3   BIC=4655.11\n\n\nThe discrepancy between the best model provided by Auto ARIMA and the best model identified in the previous step raises concerns about its reliability. Auto ARIMA solely relies on minimizing AIC/BIC values without considering lag instances of high correlation as reflected in the ACF/PACF plots. This approach may result in overfitting and may not capture the underlying patterns in the data accurately.\n\n\n\n\nCode\nauto.arima(tsi_ts)\n\n\nSeries: tsi_ts \nARIMA(3,1,0)(0,0,2)[12] with drift \n\nCoefficients:\n          ar1      ar2     ar3     sma1     sma2   drift\n      -0.0787  -0.0820  0.0791  -0.1773  -0.1487  0.1261\ns.e.   0.0605   0.0614  0.0623   0.0634   0.0655  0.0560\n\nsigma^2 = 2.129:  log likelihood = -493.41\nAIC=1000.82   AICc=1001.24   BIC=1026.16\n\n\nThe best model provided by Auto ARIMA differs from the best model identified in the previous step. This discrepancy suggests that the Auto ARIMA model may offer a better fit compared to the previously chosen model, which was not optimal. It is plausible that this dataset exhibits strong seasonality, which ARIMA alone may struggle to capture adequately. Therefore, considering SARIMA models might be necessary to effectively model the seasonality present in the data.\n\n\n\n\nCode\nauto.arima(air_ts)\n\n\nSeries: air_ts \nARIMA(0,1,0) \n\nsigma^2 = 213.5:  log likelihood = -86.12\nAIC=174.23   AICc=174.44   BIC=175.28\n\n\nThe discrepancy between the best model provided by Auto ARIMA and the best model identified in the previous step raises concerns about its reliability. Auto ARIMA solely relies on minimizing AIC/BIC values without considering lag instances of high correlation as reflected in the ACF/PACF plots. This approach may result in overfitting and may not capture the underlying patterns in the data accurately.\n\n\n\n\nCode\nauto.arima(ups_ts)\n\n\nSeries: ups_ts \nARIMA(0,1,0) \n\nsigma^2 = 5.463:  log likelihood = -3989.38\nAIC=7980.75   AICc=7980.75   BIC=7986.22\n\n\nThe best model Auto ARIMA provide is the same with the best model from the step above."
  },
  {
    "objectID": "univariate_ts_model.html#forecasting",
    "href": "univariate_ts_model.html#forecasting",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "Forecasting",
    "text": "Forecasting\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexU.S. Domestic Air Carrier Average Freight RevenueUPS Stock Price\n\n\n\n\nCode\npred_canada &lt;- forecast(ARMA_res_canada, 12)\nautoplot(pred_canada, xlab = \"Date\", ylab = \"Billions\", colour = \"blue\")+ggtitle('U.S.-Canada Freight Value Forecast') +theme_bw()\n\n\n\n\n\nThe blue line represents the forecast, while the two shades of purple depict the confidence intervals, with the darker shade representing the 95% interval and the lighter shade representing the 5% interval. As the confidence interval widens, indicating greater uncertainty in the forecast, the shaded region becomes wider.\nExamining the forecast plot, there is an initial surge in the monthly U.S.-Canada freight value, followed by a subsequent decline and another increase. Comparing the observed increasing seasonal fluctuations post-2020 to the forecasted fluctuations, it appears that the model accurately predicted the anticipated pattern.\n\n\n\n\nCode\npred_employment &lt;- forecast(ARMA_res_employment, 12)\nautoplot(pred_employment, xlab = \"Date\", ylab = \"Employment\", colour = \"blue\")+ggtitle('U.S. Air Transportation Employment Forecast') +theme_bw()\n\n\n\n\n\nThe forecast plot illustrates a subtle decreasing trend in air transportation employment over the next 12 months. The colored bands depict the 95% confidence interval. However, the forecast appears overly smooth and lacks fluctuations. This suggests that the model may not adequately capture the inherent variability or fluctuations in the data.\n\n\n\n\nCode\npred_tsi &lt;- forecast(ARMA_res_tsi, 12)\nautoplot(pred_tsi, xlab = \"Date\", ylab = \"Transportation Services Index\", colour = \"blue\")+ggtitle('U.S. Freight Transportation Services Index Forecast') +theme_bw()\n\n\n\n\n\nThe forecast plot indicates an ascending trend in the U.S. freight TSI over the ensuing 12 months. The colored bands delineate the 95% confidence interval. Nonetheless, the forecast appears excessively smooth, lacking the expected fluctuations. This suggests that the model might not adequately capture the inherent variability or fluctuations in the data.\n\n\n\n\nCode\npred_air &lt;- forecast(ARMA_res_air, 5)\nautoplot(pred_air, xlab = \"Date\", ylab = \"Freight revenue per ton-mile (current cents)\", colour = \"blue\")+ggtitle('U.S. Domestic Air Carrier Average Freight Revenue Forecast') +theme_bw()\n\n\n\n\n\nThe forecast plot depicts a stagnant trend in the U.S. domestic air carrier average freight revenue over the upcoming five years. The colored bands represent the 95% confidence interval. However, the forecast appears excessively smooth, lacking any noticeable fluctuations. This suggests that the model might not adequately capture the inherent variability or fluctuations in the data.\n\n\n\n\nCode\npred_ups &lt;- forecast(ARMA_res_ups, 50)\nautoplot(pred_ups, xlab = \"Date\", ylab = \"Stock Price\", colour = \"blue\")+ggtitle('UPS Stock Price Forecast') +theme_bw()\n\n\n\n\n\nThe forecast plot illustrates a rising trend in the UPS stock price over the forthcoming 50 days. The colored bands represent the 95% confidence interval. However, the forecast appears overly smooth, lacking noticeable fluctuations. This suggests that the model may not adequately capture the inherent variability or fluctuations in the stock price data."
  },
  {
    "objectID": "univariate_ts_model.html#arima-vs.-benchmark-methods",
    "href": "univariate_ts_model.html#arima-vs.-benchmark-methods",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "ARIMA vs. Benchmark Methods",
    "text": "ARIMA vs. Benchmark Methods\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexU.S. Domestic Air Carrier Average Freight RevenueUPS Stock Price\n\n\n\n\nCode\nautoplot(canada_ts, xlab = \"Date\", ylab = \"Billions\") +\n  autolayer(meanf(canada_ts, h=12),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(canada_ts, h=12),\n            series=\"Naïve\", PI=FALSE)+\n  autolayer(rwf(canada_ts, h=12, drift=TRUE),\n            series=\"Drift\", PI=FALSE)+\n   autolayer(pred_canada, \n            series=\"ARIMA\",PI=FALSE) + ggtitle(\"U.S.-Canada Freight Value ARIMA vs. Benchmarks\")+\n  guides(colour=guide_legend(title=\"Forecast\")) +theme_bw()\n\n\n\n\n\nWe observe that the ARIMA model best captures the trend, closely aligning with the observed data. The drift methods exhibit a comparable trajectory for the forecast. In contrast, the Mean and Naive benchmark models notably underperform, failing to accurately capture the underlying trend.\n\n\nCode\n# Compute accuracy\noutput1 &lt;- accuracy(pred_canada)\noutput2 &lt;- accuracy(meanf(canada_ts, h=12))\noutput3 &lt;- accuracy(naive(canada_ts, h=12))\noutput4 &lt;- accuracy(rwf(canada_ts, drift=TRUE, h=12))\n\noutput_list &lt;- list(output1, output2, output3, output4)\n\n# Put into df\noutput_df &lt;- do.call(rbind, output_list)\n\n# Set row names for the dataframe\nrow.names(output_df) &lt;- c(\"ARIMA\", \"Meanf\", \"Naive\", \"Drift\")\n\noutput_df\n\n\n                 ME     RMSE      MAE        MPE      MAPE      MASE\nARIMA -2.179075e-02 3.105814 2.276102 -0.2721476  4.798624 0.3998011\nMeanf -1.819683e-15 7.158385 5.209884 -2.1984228 11.014570 0.9151249\nNaive  8.439239e-02 3.747662 2.676507 -0.1592665  5.543406 0.4701329\nDrift -2.088947e-15 3.746711 2.677095 -0.3338399  5.547840 0.4702363\n             ACF1\nARIMA -0.01487147\nMeanf  0.85587296\nNaive -0.27042733\nDrift -0.27042733\n\n\nUpon examining the accuracy metrics, it’s evident that the ARIMA model achieved the lowest RMSE, MAE, and MAPE values, followed by the Drift model. This suggests that the ARIMA model outperforms the benchmark models in terms of accuracy.\n\n\n\n\nCode\nautoplot(employment_ts, xlab = \"Date\", ylab = \"Employment\") +\n  autolayer(meanf(employment_ts, h=12),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(employment_ts, h=12),\n            series=\"Naïve\", PI=FALSE)+\n  autolayer(rwf(employment_ts, h=12, drift=TRUE),\n            series=\"Drift\", PI=FALSE)+\n   autolayer(pred_employment, \n            series=\"ARIMA\",PI=FALSE) + ggtitle(\"U.S. Air Transportation Employment ARIMA vs. Benchmarks\")+\n  guides(colour=guide_legend(title=\"Forecast\")) +theme_bw()\n\n\n\n\n\nWe observe that the ARIMA, drift and Naive models exhibit a comparable trajectory for the forecast and best captures the trend, closely aligning with the observed data. In contrast, the Mean benchmark model notably underperform, failing to accurately capture the underlying trend.\n\n\nCode\n# Compute accuracy\noutput1 &lt;- accuracy(pred_employment)\noutput2 &lt;- accuracy(meanf(employment_ts, h=12))\noutput3 &lt;- accuracy(naive(employment_ts, h=12))\noutput4 &lt;- accuracy(rwf(employment_ts, drift=TRUE, h=12))\n\noutput_list &lt;- list(output1, output2, output3, output4)\n\n# Put into df\noutput_df &lt;- do.call(rbind, output_list)\n\n# Set row names for the dataframe\nrow.names(output_df) &lt;- c(\"ARIMA\", \"Meanf\", \"Naive\", \"Drift\")\n\noutput_df\n\n\n                 ME      RMSE       MAE         MPE      MAPE      MASE\nARIMA  2.633125e+02  6241.208  2809.261  0.05105339 0.6005098 0.1456793\nMeanf -2.235212e-11 25101.751 21628.241 -0.28679049 4.5989461 1.1215716\nNaive -8.421053e+01  7028.726  3175.439 -0.02909029 0.6871776 0.1646681\nDrift -4.059817e-12  7028.221  3184.303 -0.01132370 0.6889589 0.1651278\n             ACF1\nARIMA 0.009897766\nMeanf 0.957521645\nNaive 0.376333238\nDrift 0.376333238\n\n\nUpon examining the accuracy metrics, it’s evident that the ARIMA model achieved the lowest RMSE, MAE, and MAPE values, followed by the Drift model. This suggests that the ARIMA model outperforms the benchmark models in terms of accuracy.\n\n\n\n\nCode\nautoplot(tsi_ts, xlab = \"Date\", ylab = \"Transportation Services Index\") +\n  autolayer(meanf(tsi_ts, h=12),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(tsi_ts, h=12),\n            series=\"Naïve\", PI=FALSE)+\n  autolayer(rwf(tsi_ts, h=12, drift=TRUE),\n            series=\"Drift\", PI=FALSE)+\n   autolayer(pred_tsi, \n            series=\"ARIMA\",PI=FALSE) + ggtitle(\"U.S. Freight Transportation Services Index ARIMA vs. Benchmarks\")+\n  guides(colour=guide_legend(title=\"Forecast\")) +theme_bw()\n\n\n\n\n\nWe observe that the ARIMA model best captures the trend, closely aligning with the observed data. The drift methods exhibit a comparable trajectory for the forecast. In contrast, the Mean and Naive benchmark models notably underperform, failing to accurately capture the underlying trend.\n\n\nCode\n# Compute accuracy\noutput1 &lt;- accuracy(pred_tsi)\noutput2 &lt;- accuracy(meanf(tsi_ts, h=12))\noutput3 &lt;- accuracy(naive(tsi_ts, h=12))\noutput4 &lt;- accuracy(rwf(tsi_ts, drift=TRUE, h=12))\n\noutput_list &lt;- list(output1, output2, output3, output4)\n\n# Put into df\noutput_df &lt;- do.call(rbind, output_list)\n\n# Set row names for the dataframe\nrow.names(output_df) &lt;- c(\"ARIMA\", \"Meanf\", \"Naive\", \"Drift\")\n\noutput_df\n\n\n                 ME      RMSE       MAE         MPE      MAPE      MASE\nARIMA  7.283871e-04  1.475506  1.068367 -0.01205377 0.9267941 0.2634875\nMeanf -1.056836e-14 13.009848 11.112711 -1.22065210 9.5135777 2.7406872\nNaive  1.141304e-01  1.500374  1.096014  0.08659501 0.9496963 0.2703060\nDrift  2.500415e-15  1.496027  1.087839 -0.01244364 0.9430018 0.2682897\n              ACF1\nARIMA  0.004977272\nMeanf  0.987698495\nNaive -0.064131500\nDrift -0.064131500\n\n\nUpon examining the accuracy metrics, it’s evident that the ARIMA model achieved the lowest RMSE, MAE, and MAPE values, followed by the Drift model. This suggests that the ARIMA model outperforms the benchmark models in terms of accuracy.\n\n\n\n\nCode\nautoplot(air_ts, xlab = \"Date\", ylab = \"Freight revenue per ton-mile (current cents)\") +\n  autolayer(meanf(air_ts, h=5),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(air_ts, h=5),\n            series=\"Naïve\", PI=FALSE)+\n  autolayer(rwf(air_ts, h=5, drift=TRUE),\n            series=\"Drift\", PI=FALSE)+\n   autolayer(pred_air, \n            series=\"ARIMA\",PI=FALSE) + ggtitle(\"U.S. Domestic Air Carrier Average Freight Revenue ARIMA vs. Benchmarks\")+\n  guides(colour=guide_legend(title=\"Forecast\")) +theme_bw()\n\n\n\n\n\nWe observe that the ARIMA model seems underperform, failing to accurately capture the underlying trend.\n\n\nCode\n# Compute accuracy\noutput1 &lt;- accuracy(pred_air)\noutput2 &lt;- accuracy(meanf(air_ts, h=12))\noutput3 &lt;- accuracy(naive(air_ts, h=12))\noutput4 &lt;- accuracy(rwf(air_ts, drift=TRUE, h=12))\n\noutput_list &lt;- list(output1, output2, output3, output4)\n\n# Put into df\noutput_df &lt;- do.call(rbind, output_list)\n\n# Set row names for the dataframe\nrow.names(output_df) &lt;- c(\"ARIMA\", \"Meanf\", \"Naive\", \"Drift\")\n\noutput_df\n\n\n                 ME     RMSE       MAE          MPE      MAPE      MASE\nARIMA  2.965719e-01 11.79289  8.992931   0.18889448  9.662775 0.8915005\nMeanf -2.306236e-15 31.95599 29.965043 -12.98493762 35.854642 2.9705387\nNaive  9.865931e-01 14.61164 10.087410  -0.04930048 11.202702 1.0000000\nDrift -3.383537e-15 14.57830  9.911415  -1.18896301 10.999729 0.9825529\n            ACF1\nARIMA -0.2644170\nMeanf  0.8911918\nNaive  0.2602701\nDrift  0.2602701\n\n\nUpon examining the accuracy metrics, it’s evident that the ARIMA model achieved the lowest RMSE, MAE, and MAPE values, followed by the Drift model. This suggests that the ARIMA model outperforms the benchmark models in terms of accuracy.\n\n\n\n\nCode\nautoplot(ups_ts, xlab = \"Date\", ylab = \"Stock Price\") +\n  autolayer(meanf(ups_ts, h=50),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(ups_ts, h=50),\n            series=\"Naïve\", PI=FALSE)+\n  autolayer(rwf(ups_ts, h=50, drift=TRUE),\n            series=\"Drift\", PI=FALSE)+\n   autolayer(pred_ups, \n            series=\"ARIMA\",PI=FALSE) + ggtitle(\"UPS Stock Price ARIMA vs. Benchmarks\")+\n  guides(colour=guide_legend(title=\"Forecast\")) +theme_bw()\n\n\n\n\n\nWe observe that the ARIMA, drift and Naive models exhibit a comparable trajectory for the forecast and best captures the trend, closely aligning with the observed data. In contrast, the Mean benchmark model notably underperform, failing to accurately capture the underlying trend.\n\n\nCode\n# Compute accuracy\noutput1 &lt;- accuracy(pred_ups)\noutput2 &lt;- accuracy(meanf(ups_ts, h=12))\noutput3 &lt;- accuracy(naive(ups_ts, h=12))\noutput4 &lt;- accuracy(rwf(ups_ts, drift=TRUE, h=12))\n\noutput_list &lt;- list(output1, output2, output3, output4)\n\n# Put into df\noutput_df &lt;- do.call(rbind, output_list)\n\n# Set row names for the dataframe\nrow.names(output_df) &lt;- c(\"ARIMA\", \"Meanf\", \"Naive\", \"Drift\")\n\noutput_df\n\n\n                ME      RMSE       MAE          MPE      MAPE       MASE\nARIMA 5.173999e-05  2.336454  1.513771  -0.01543306  1.161839 0.04821099\nMeanf 1.080126e-12 40.426672 38.180110 -10.12057135 31.863701 1.21597050\nNaive 3.660449e-02  2.337403  1.515062   0.01546450  1.162754 0.04825209\nDrift 5.107578e-15  2.337117  1.514580  -0.01549867  1.162442 0.04823675\n            ACF1\nARIMA 0.03201837\nMeanf 0.99795274\nNaive 0.03201852\nDrift 0.03201852\n\n\nUpon examining the accuracy metrics, it’s evident that the ARIMA model achieved the lowest RMSE, MAE, and MAPE values, followed by the Drift model. This suggests that the ARIMA model outperforms the benchmark models in terms of accuracy."
  },
  {
    "objectID": "univariate_ts_model.html#sarima",
    "href": "univariate_ts_model.html#sarima",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "SARIMA",
    "text": "SARIMA\n\nACF & PACF Plots\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexUPS Stock Price\n\n\n\n\nCode\ncanada_ts %&gt;% diff(lag=12) %&gt;% ggtsdisplay()\n\n\n\n\n\nCode\ncanada_ts %&gt;% diff(lag=24) %&gt;% ggtsdisplay()\n\n\n\n\n\nYou can observe significant changes in the seasonal differenced dataset, as depicted in the time series plot. While the seasonal cycles remain visible in the plots for seasonal lags 1 and 2, there is a noticeable decrease in correlation in both the ACF and PACF plots. This reduction in correlation indicates a potential improvement in stationarity and suggests that the seasonal differencing has helped alleviate the seasonality present in the original data.\n\nP: 1 D: 1, 2 Q: 1, 2, 3, 4\n\n\n\n\n\nCode\nemployment_ts %&gt;% diff(lag=12) %&gt;% ggtsdisplay()\n\n\n\n\n\nCode\nemployment_ts %&gt;% diff(lag=24) %&gt;% ggtsdisplay()\n\n\n\n\n\nYou can observe significant changes in the seasonal differenced dataset, as depicted in the time series plot. While the seasonal cycles remain visible in the plots for seasonal lags 1 and 2, there is a noticeable decrease in correlation in both the ACF and PACF plots. This reduction in correlation indicates a potential improvement in stationarity and suggests that the seasonal differencing has helped alleviate the seasonality present in the original data.\n\nP: 1,2,3 D: 1, 2 Q: 1, 2, 3, 4\n\n\n\n\n\nCode\ntsi_ts %&gt;% diff(lag=12) %&gt;% ggtsdisplay()\n\n\n\n\n\nCode\ntsi_ts %&gt;% diff(lag=24) %&gt;% ggtsdisplay()\n\n\n\n\n\nYou can observe significant changes in the seasonal differenced dataset, as depicted in the time series plot. While the seasonal cycles remain visible in the plots for seasonal lags 1 and 2, there is a noticeable decrease in correlation in both the ACF and PACF plots. This reduction in correlation indicates a potential improvement in stationarity and suggests that the seasonal differencing has helped alleviate the seasonality present in the original data.\n\nP: 1 D: 1, 2 Q: 1, 2, 3, 4\n\n\n\n\n\nCode\nups_ts %&gt;% diff(lag=12) %&gt;% ggtsdisplay()\n\n\n\n\n\nCode\nups_ts %&gt;% diff(lag=24) %&gt;% ggtsdisplay()\n\n\n\n\n\nYou can observe significant changes in the seasonal differenced dataset, as depicted in the time series plot. While the seasonal cycles remain visible in the plots for seasonal lags 1 and 2, there is a noticeable decrease in correlation in both the ACF and PACF plots. This reduction in correlation indicates a potential improvement in stationarity and suggests that the seasonal differencing has helped alleviate the seasonality present in the original data.\n\nP: 1 D: 1, 2 Q: 1, 2, 3, 4\n\n\n\n\n\n\nFinding Model Parameters For Selected Models\nIn this section, we will identify potential values for the parameters p and q based on the significant lags observed in the PACF and ACF plots of the original data, respectively. Specifically, we will consider the most significant lags from the PACF plot for the value of p, and from the ACF plot for the value of q.\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexUPS Stock Price\n\n\np = 0,1,2, d = 0,1,2, q = 0,1,2,3,4, P: 1, D: 1, 2, Q: 1, 2, 3, 4\n\n\nCode\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,d1,d2,D1,D2,data){\n  \n  temp=c()\n  d=2\n  D=2\n  s=12\n  \n  i=1\n  temp= data.frame()\n  ls=matrix(rep(NA,9*150),nrow=150)\n  \n  \n  for (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P1)\n      {\n        for(Q in Q1:Q1)\n        {\n          for(d in d1:d2)\n            {\n              for(D in D1:D2)\n        {\n          if(p+d+q+P+D+Q&lt;=10)\n          {\n            \n            model&lt;- Arima(data,order=c(p,d,q),seasonal=c(P,D,Q))\n            ls[i,]= c(p,d,q,P,D,Q,model$aic,model$bic,model$aicc)\n            i=i+1\n            #print(i)\n            \n          }\n          \n        }\n      }\n    }\n    \n  }\n  }\n  }\n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  \n  temp\n  \n}\n\n\noutput=SARIMA.c(p1=0,p2=2,q1=0,q2=4,P1=0,P2=1,Q1=0,Q2=4,d1=0,d2=2,D1=0,D2=2,data=canada_ts)\n#output\n\noutput[which.min(output$AIC),] \n\n\n    p d q P D Q     AIC      BIC     AICc\n131 2 1 4 0 1 0 1003.03 1025.832 1003.639\n\n\nCode\noutput[which.min(output$BIC),] \n\n\n  p d q P D Q      AIC     BIC     AICc\n5 0 1 0 0 1 0 1012.312 1015.57 1012.333\n\n\nCode\noutput[which.min(output$AICc),] \n\n\n    p d q P D Q     AIC      BIC     AICc\n131 2 1 4 0 1 0 1003.03 1025.832 1003.639\n\n\nThe model with the lowest AIC and BIC is ARIMA(2,1,4)X(0,1,0)12.\n\n\np = 0,1,2, d = 0,1,2, q = 0,1,2,3,4, P: 1,2,3, D: 1, 2, Q: 1, 2, 3, 4\n\n\nCode\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,d1,d2,D1,D2,data){\n  \n  temp=c()\n  d=2\n  D=2\n  s=12\n  \n  i=1\n  temp= data.frame()\n  ls=matrix(rep(NA,9*150),nrow=150)\n  \n  \n  for (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P1)\n      {\n        for(Q in Q1:Q1)\n        {\n          for(d in d1:d2)\n            {\n              for(D in D1:D2)\n        {\n          if(p+d+q+P+D+Q&lt;=10)\n          {\n            \n            model&lt;- Arima(data,order=c(p,d,q),seasonal=c(P,D,Q))\n            ls[i,]= c(p,d,q,P,D,Q,model$aic,model$bic,model$aicc)\n            i=i+1\n            #print(i)\n            \n          }\n          \n        }\n      }\n    }\n    \n  }\n  }\n  }\n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  \n  temp\n  \n}\n\n\noutput=SARIMA.c(p1=0,p2=2,q1=0,q2=4,P1=0,P2=3,Q1=0,Q2=4,d1=0,d2=2,D1=0,D2=2,data=employment_ts)\n#output\n\noutput[which.min(output$AIC),] \n\n\n    p d q P D Q      AIC      BIC     AICc\n135 2 2 4 0 2 0 4473.083 4496.276 4473.658\n\n\nCode\noutput[which.min(output$BIC),] \n\n\n    p d q P D Q      AIC      BIC     AICc\n135 2 2 4 0 2 0 4473.083 4496.276 4473.658\n\n\nCode\noutput[which.min(output$AICc),] \n\n\n    p d q P D Q      AIC      BIC     AICc\n135 2 2 4 0 2 0 4473.083 4496.276 4473.658\n\n\nThe model with the lowest AIC and BIC is ARIMA(2,2,4)X(0,2,0)24.\n\n\np = 0,1, d = 0,1, q = 0,1,2,3,4, P: 1, D: 1, 2, Q: 1, 2, 3, 4\n\n\nCode\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,d1,d2,D1,D2,data){\n  \n  temp=c()\n  d=2\n  D=2\n  s=12\n  \n  i=1\n  temp= data.frame()\n  ls=matrix(rep(NA,9*150),nrow=150)\n  \n  \n  for (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P1)\n      {\n        for(Q in Q1:Q1)\n        {\n          for(d in d1:d2)\n            {\n              for(D in D1:D2)\n        {\n          if(p+d+q+P+D+Q&lt;=10)\n          {\n            \n            model&lt;- Arima(data,order=c(p,d,q),seasonal=c(P,D,Q))\n            ls[i,]= c(p,d,q,P,D,Q,model$aic,model$bic,model$aicc)\n            i=i+1\n            #print(i)\n            \n          }\n          \n        }\n      }\n    }\n    \n  }\n  }\n  }\n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  \n  temp\n  \n}\n\n\noutput=SARIMA.c(p1=0,p2=1,q1=0,q2=4,P1=0,P2=1,Q1=0,Q2=4,d1=0,d2=1,D1=0,D2=2,data=tsi_ts)\n#output\n\noutput[which.min(output$AIC),] \n\n\n   p d q P D Q      AIC      BIC    AICc\n52 1 1 3 0 0 0 1008.547 1026.649 1008.77\n\n\nCode\noutput[which.min(output$BIC),] \n\n\n  p d q P D Q      AIC      BIC     AICc\n4 0 1 0 0 0 0 1009.209 1012.829 1009.223\n\n\nCode\noutput[which.min(output$AICc),] \n\n\n   p d q P D Q      AIC      BIC    AICc\n52 1 1 3 0 0 0 1008.547 1026.649 1008.77\n\n\nThe model with the lowest AIC and BIC is ARIMA(1,1,3)X(0,0,0).\n\n\np = 0,1, d = 0,1,2, q = 0,1,2,3, P: 1, D: 1, 2, Q: 1, 2, 3, 4\n\n\nCode\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,d1,d2,D1,D2,data){\n  \n  temp=c()\n  d=2\n  D=2\n  s=12\n  \n  i=1\n  temp= data.frame()\n  ls=matrix(rep(NA,9*150),nrow=150)\n  \n  \n  for (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P1)\n      {\n        for(Q in Q1:Q1)\n        {\n          for(d in d1:d2)\n            {\n              for(D in D1:D2)\n        {\n          if(p+d+q+P+D+Q&lt;=10)\n          {\n            \n            model&lt;- Arima(data,order=c(p,d,q),seasonal=c(P,D,Q))\n            ls[i,]= c(p,d,q,P,D,Q,model$aic,model$bic,model$aicc)\n            i=i+1\n            #print(i)\n            \n          }\n          \n        }\n      }\n    }\n    \n  }\n  }\n  }\n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  \n  temp\n  \n}\n\n\n#output=SARIMA.c(p1=0,p2=1,q1=0,q2=1,P1=0,P2=1,Q1=0,Q2=2,d1=0,d2=1,D1=0,D2=2,data=ups_ts)\n#output\n\n#output[which.min(output$AIC),] \n\n#output[which.min(output$BIC),] \n\n#output[which.min(output$AICc),] \n\n\nThe model with the lowest AIC and BIC is ARIMA(2,2,3)X(0,1,0).\n\n\n\n\n\nFit Best SARIMA(P,D,Q) & Diagnostics\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexUPS Stock Price\n\n\n\n\nCode\nset.seed(99)\noutput &lt;- capture.output(sarima(canada_ts,2,1,4,0,1,0,12))\n\n\n\n\n\nCode\ncat(output[61:72], output[length(output)], sep = \"\\n\") \n\n\nCoefficients: \n    Estimate     SE t.value p.value\nar1  -0.0808 0.0879 -0.9196  0.3590\nar2  -0.6642 0.1566 -4.2420  0.0000\nma1   0.1757 0.1088  1.6144  0.1081\nma2   0.7722 0.1802  4.2854  0.0000\nma3   0.0630 0.0935  0.6737  0.5013\nma4  -0.1880 0.1174 -1.6022  0.1108\n\nsigma^2 estimated as 9.998351 on 186 degrees of freedom \n \nAIC = 5.224114  AICc = 5.226479  BIC = 5.342877 \n \n\n\nUpon inspection of the time plot of the standardized residuals above, no discernible patterns are evident. However, the ACF plot of the standardized residuals indicates some remaining correlation. The normal Q-Q plot of the residuals suggests that the assumption of normality is reasonable, with the exception of potential outliers. The results of the Ljung-Box test reveal values below the 0.05 (5% significance) threshold, indicating the presence of some significant correlation remaining. Despite these findings, it appears that the model has been improved.\n\n\n\n\nCode\nset.seed(99)\noutput &lt;- capture.output(sarima(employment_ts,2,2,4,0,2,0,12))\n\n\n\n\n\nCode\ncat(output[72:83], output[length(output)], sep = \"\\n\") \n\n\nCoefficients: \n    Estimate     SE  t.value p.value\nar1   0.3027 0.0454   6.6701   0e+00\nar2  -0.8468 0.0424 -19.9902   0e+00\nma1  -0.7547 0.0875  -8.6201   0e+00\nma2   0.7374 0.0959   7.6871   0e+00\nma3  -0.6817 0.0943  -7.2296   0e+00\nma4  -0.3008 0.0852  -3.5297   5e-04\n\nsigma^2 estimated as 189158079 on 197 degrees of freedom \n \nAIC = 22.03489  AICc = 22.03701  BIC = 22.14914 \n \n\n\nUpon examining the time plot of the standardized residuals, no discernible patterns are evident. Additionally, the ACF plot of the standardized residuals reveals no significant departures from the model assumptions, as no significant lags are observed. The normal Q-Q plot of the residuals indicates that the assumption of normality is reasonable, with the exception of possible outliers. Furthermore, the Ljung-Box test yields favorable values exceeding 0.05, suggesting the absence of significant correlation and indicating a well-fitted model. Overall, these observations suggest that the model fits the data well.\n\n\n\n\nCode\nset.seed(99)\noutput &lt;- capture.output(sarima(tsi_ts,1,1,3,0,0,0,12))\n\n\n\n\n\nCode\ncat(output[45:55], output[length(output)], sep = \"\\n\") \n\n\nCoefficients: \n         Estimate     SE t.value p.value\nar1        0.5867 0.2181  2.6905  0.0076\nma1       -0.6583 0.2206 -2.9849  0.0031\nma2       -0.0582 0.0737 -0.7888  0.4309\nma3        0.1708 0.0650  2.6269  0.0091\nconstant   0.1053 0.0975  1.0795  0.2813\n\nsigma^2 estimated as 2.172189 on 271 degrees of freedom \n \nAIC = 3.657447  AICc = 3.658252  BIC = 3.736151 \n \n\n\nUpon examining the time plot of the standardized residuals, no discernible patterns are evident. Additionally, the ACF plot of the standardized residuals reveals no significant departures from the model assumptions, as no significant lags are observed. The normal Q-Q plot of the residuals indicates that the assumption of normality is reasonable, with the exception of possible outliers. Furthermore, the Ljung-Box test yields favorable values exceeding 0.05, suggesting the absence of significant correlation and indicating a well-fitted model. Overall, these observations suggest that the model fits the data well.\n\n\n\n\nCode\nset.seed(99)\n#output &lt;- capture.output(sarima(ups_ts,0,1,0))\n#cat(output[11:18], output[length(output)], sep = \"\\n\") \n\n\nUpon examining the time plot of the standardized residuals, no discernible patterns are evident. Additionally, the ACF plot of the standardized residuals reveals no significant departures from the model assumptions, as no significant lags are observed. The normal Q-Q plot of the residuals indicates that the assumption of normality is reasonable, with the exception of possible outliers. Furthermore, the Ljung-Box test yields favorable values exceeding 0.05, suggesting the absence of significant correlation and indicating a well-fitted model. Overall, these observations suggest that the model fits the data well.\n\n\n\n\n\nAuto ARIMA\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexUPS Stock Price\n\n\n\n\nCode\nauto.arima(canada_ts)\n\n\nSeries: canada_ts \nARIMA(2,1,5)(1,0,0)[12] \n\nCoefficients:\n          ar1      ar2     ma1     ma2     ma3      ma4     ma5    sar1\n      -0.1410  -0.4216  0.1452  0.4440  0.0703  -0.3019  0.2020  0.5636\ns.e.   0.1988   0.2128  0.1977  0.2187  0.0836   0.0907  0.1092  0.0718\n\nsigma^2 = 8.695:  log likelihood = -508.85\nAIC=1035.71   AICc=1036.63   BIC=1065.57\n\n\nThe best model provided by Auto ARIMA differs from the best model identified in the previous step. This discrepancy suggests that the Auto ARIMA model may offer a better fit compared to the previously chosen model, which was not optimal. It is plausible that this dataset exhibits strong seasonality, which ARIMA alone may struggle to capture adequately.\n\n\n\n\nCode\nauto.arima(employment_ts)\n\n\nSeries: employment_ts \nARIMA(0,1,1) \n\nCoefficients:\n         ma1\n      0.4204\ns.e.  0.0536\n\nsigma^2 = 41251784:  log likelihood = -2322.12\nAIC=4648.25   AICc=4648.3   BIC=4655.11\n\n\nThe discrepancy between the best model provided by Auto ARIMA and the best model identified in the previous step raises concerns about its reliability. Auto ARIMA solely relies on minimizing AIC/BIC values without considering lag instances of high correlation as reflected in the ACF/PACF plots. This approach may result in overfitting and may not capture the underlying patterns in the data accurately.\n\n\n\n\nCode\nauto.arima(tsi_ts)\n\n\nSeries: tsi_ts \nARIMA(3,1,0)(0,0,2)[12] with drift \n\nCoefficients:\n          ar1      ar2     ar3     sma1     sma2   drift\n      -0.0787  -0.0820  0.0791  -0.1773  -0.1487  0.1261\ns.e.   0.0605   0.0614  0.0623   0.0634   0.0655  0.0560\n\nsigma^2 = 2.129:  log likelihood = -493.41\nAIC=1000.82   AICc=1001.24   BIC=1026.16\n\n\nThe best model provided by Auto ARIMA differs from the best model identified in the previous step. This discrepancy suggests that the Auto ARIMA model may offer a better fit compared to the previously chosen model, which was not optimal. It is plausible that this dataset exhibits strong seasonality, which ARIMA alone may struggle to capture adequately.\n\n\n\n\nCode\n#auto.arima(ups_ts)\n\n\nThe best model Auto ARIMA provide is the same with the best model from the step above.\n\n\n\n\n\nForecasting\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexUPS Stock Price\n\n\n\n\nCode\nfit_canada &lt;- Arima(canada_ts, order=c(2,1,4), seasonal=c(0,1,0))\n\n# forecast next three years\nfit_canada %&gt;% forecast(h=12) %&gt;% autoplot(xlab = \"Date\", ylab = \"Billions\", colour = \"blue\")+ggtitle('U.S.-Canada Freight Value Forecast')+theme_bw() \n\n\n\n\n\nThe blue line represents the forecast, while the two shades of purple depict the confidence intervals, with the darker shade representing the 95% interval and the lighter shade representing the 5% interval. As the confidence interval widens, indicating greater uncertainty in the forecast, the shaded region becomes wider.\nExamining the forecast plot, there is an initial surge in the monthly U.S.-Canada freight value, followed by a subsequent decline and another increase. Comparing the observed increasing seasonal fluctuations post-2020 to the forecasted fluctuations, it appears that the model accurately predicted the anticipated pattern.\n\n\n\n\nCode\nfit_employment &lt;- Arima(employment_ts, order=c(2,2,4), seasonal=c(0,2,0))\n\n# forecast next three years\nfit_employment %&gt;% forecast(h=12) %&gt;% autoplot(xlab = \"Date\", ylab = \"Employment\", colour = \"blue\")+ggtitle('U.S. Air Transportation Employment Forecast') +theme_bw() \n\n\n\n\n\nThe forecast plot illustrates a subtle decreasing trend in air transportation employment over the next 12 months. The colored bands depict the 95% confidence interval. However, the forecast appears overly smooth and lacks fluctuations. This suggests that the model may not adequately capture the inherent variability or fluctuations in the data.\n\n\n\n\nCode\nfit_tsi &lt;- Arima(tsi_ts, order=c(1,1,3), seasonal=c(0,0,0))\n\n# forecast next three years\nfit_tsi %&gt;% forecast(h=12) %&gt;% autoplot( xlab = \"Date\", ylab = \"Transportation Services Index\", colour = \"blue\")+ggtitle('U.S. Freight Transportation Services Index Forecast') +theme_bw()\n\n\n\n\n\nThe forecast plot indicates an ascending trend in the U.S. freight TSI over the ensuing 12 months. The colored bands delineate the 95% confidence interval. Nonetheless, the forecast appears excessively smooth, lacking the expected fluctuations. This suggests that the model might not adequately capture the inherent variability or fluctuations in the data.\n\n\n\n\nCode\n#fit_ups &lt;- Arima(ups_ts, order=c(2,2,4), seasonal=c(0,2,0))\n\n# forecast next three years\n#fit_ups %&gt;% forecast(h=12) %&gt;% autoplot( xlab = \"Date\", ylab = \"Stock Price\", colour = \"blue\")+ggtitle('UPS Stock Price Forecast') +theme_bw()\n\n\nThe forecast plot illustrates a rising trend in the UPS stock price over the forthcoming 50 days. The colored bands represent the 95% confidence interval. However, the forecast appears overly smooth, lacking noticeable fluctuations. This suggests that the model may not adequately capture the inherent variability or fluctuations in the stock price data.\n\n\n\n\n\nSARIMA vs. Benchmark Methods\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexUPS Stock Price\n\n\n\n\nCode\nautoplot(canada_ts, xlab = \"Date\", ylab = \"Billions\") +\n  autolayer(meanf(canada_ts, h=12),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(canada_ts, h=12),\n            series=\"Naïve\", PI=FALSE)+\n  autolayer(snaive(canada_ts, h=12),\n            series=\"SNaïve\", PI=FALSE)+\n  autolayer(rwf(canada_ts, h=12, drift=TRUE),\n            series=\"Drift\", PI=FALSE)+\n   autolayer(forecast(fit_canada,12), \n            series=\"ARIMA\",PI=FALSE) + ggtitle(\"U.S.-Canada Freight Value ARIMA vs. Benchmarks\")+\n  guides(colour=guide_legend(title=\"Forecast\")) +theme_bw()\n\n\n\n\n\nWe observe that the ARIMA model best captures the trend, closely aligning with the observed data. The drift methods exhibit a comparable trajectory for the forecast. In contrast, the Mean and Naive benchmark models notably underperform, failing to accurately capture the underlying trend.\n\n\nCode\n# Compute accuracy\noutput1 &lt;- accuracy(forecast(fit_canada,12))\noutput2 &lt;- accuracy(meanf(canada_ts, h=12))\noutput3 &lt;- accuracy(naive(canada_ts, h=12))\noutput4 &lt;- accuracy(snaive(canada_ts, h=12))\noutput5 &lt;- accuracy(rwf(canada_ts, drift=TRUE, h=12))\n\noutput_list &lt;- list(output1, output2, output3, output4, output5)\n\n# Put into df\noutput_df &lt;- do.call(rbind, output_list)\n\n# Set row names for the dataframe\nrow.names(output_df) &lt;- c(\"ARIMA\", \"Meanf\", \"Naive\", \"SNaive\", \"Drift\")\n\noutput_df\n\n\n                  ME     RMSE      MAE         MPE      MAPE      MASE\nARIMA   2.676392e-02 3.060137 2.205928 -0.03405288  4.626277 0.3874751\nMeanf  -1.819683e-15 7.158385 5.209884 -2.19842282 11.014570 0.9151249\nNaive   8.439239e-02 3.747662 2.676507 -0.15926651  5.543406 0.4701329\nSNaive  1.362544e+00 7.718869 5.693085  1.00899209 12.230962 1.0000000\nDrift  -2.088947e-15 3.746711 2.677095 -0.33383993  5.547840 0.4702363\n               ACF1\nARIMA  -0.006402906\nMeanf   0.855872956\nNaive  -0.270427328\nSNaive  0.902091441\nDrift  -0.270427328\n\n\nUpon examining the accuracy metrics, it’s evident that the ARIMA model achieved the lowest RMSE, MAE, and MAPE values, followed by the Drift model. This suggests that the ARIMA model outperforms the benchmark models in terms of accuracy.\n\n\n\n\nCode\nautoplot(employment_ts, xlab = \"Date\", ylab = \"Employment\") +\n  autolayer(meanf(employment_ts, h=12),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(employment_ts, h=12),\n            series=\"Naïve\", PI=FALSE)+\n  autolayer(snaive(employment_ts, h=12),\n            series=\"SNaïve\", PI=FALSE)+\n  autolayer(rwf(employment_ts, h=12, drift=TRUE),\n            series=\"Drift\", PI=FALSE)+\n   autolayer(forecast(fit_employment,12), \n            series=\"ARIMA\",PI=FALSE) + ggtitle(\"U.S. Air Transportation Employment ARIMA vs. Benchmarks\")+\n  guides(colour=guide_legend(title=\"Forecast\")) +theme_bw()\n\n\n\n\n\nWe observe that the ARIMA, drift and Naive models exhibit a comparable trajectory for the forecast and best captures the trend, closely aligning with the observed data. In contrast, the Mean benchmark model notably underperform, failing to accurately capture the underlying trend.\n\n\nCode\n# Compute accuracy\noutput1 &lt;- accuracy(forecast(fit_employment,12))\noutput2 &lt;- accuracy(meanf(employment_ts, h=12))\noutput3 &lt;- accuracy(naive(employment_ts, h=12))\noutput4 &lt;- accuracy(snaive(employment_ts, h=12))\noutput5 &lt;- accuracy(rwf(employment_ts, drift=TRUE, h=12))\n\noutput_list &lt;- list(output1, output2, output3, output4, output5)\n\n# Put into df\noutput_df &lt;- do.call(rbind, output_list)\n\n# Set row names for the dataframe\nrow.names(output_df) &lt;- c(\"ARIMA\", \"Meanf\", \"Naive\", \"SNaive\", \"Drift\")\n\noutput_df\n\n\n                  ME      RMSE       MAE          MPE      MAPE      MASE\nARIMA  -4.237444e+00 12949.666  5958.044  0.009721147 1.2697220 0.3089651\nMeanf  -2.235212e-11 25101.751 21628.241 -0.286790486 4.5989461 1.1215716\nNaive  -8.421053e+01  7028.726  3175.439 -0.029090287 0.6871776 0.1646681\nSNaive  0.000000e+00 28713.604 19283.871 -0.196309220 4.1647999 1.0000000\nDrift  -4.059817e-12  7028.221  3184.303 -0.011323704 0.6889589 0.1651278\n              ACF1\nARIMA  -0.01985451\nMeanf   0.95752164\nNaive   0.37633324\nSNaive  0.93334964\nDrift   0.37633324\n\n\nUpon examining the accuracy metrics, it’s evident that the ARIMA model achieved the lowest RMSE, MAE, and MAPE values, followed by the Drift model. This suggests that the ARIMA model outperforms the benchmark models in terms of accuracy.\n\n\n\n\nCode\nautoplot(tsi_ts, xlab = \"Date\", ylab = \"Transportation Services Index\") +\n  autolayer(meanf(tsi_ts, h=12),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(tsi_ts, h=12),\n            series=\"Naïve\", PI=FALSE)+\n  autolayer(snaive(tsi_ts, h=12),\n            series=\"SNaïve\", PI=FALSE)+\n  autolayer(rwf(tsi_ts, h=12, drift=TRUE),\n            series=\"Drift\", PI=FALSE)+\n   autolayer(forecast(fit_tsi,12), \n            series=\"ARIMA\",PI=FALSE) + ggtitle(\"U.S. Freight Transportation Services Index ARIMA vs. Benchmarks\")+\n  guides(colour=guide_legend(title=\"Forecast\")) +theme_bw()\n\n\n\n\n\nWe observe that the ARIMA model best captures the trend, closely aligning with the observed data. The drift methods exhibit a comparable trajectory for the forecast. In contrast, the Mean and Naive benchmark models notably underperform, failing to accurately capture the underlying trend.\n\n\nCode\n# Compute accuracy\noutput1 &lt;- accuracy(forecast(fit_tsi,12))\noutput2 &lt;- accuracy(meanf(tsi_ts, h=12))\noutput3 &lt;- accuracy(naive(tsi_ts, h=12))\noutput4 &lt;- accuracy(snaive(tsi_ts, h=12))\noutput5 &lt;- accuracy(rwf(tsi_ts, drift=TRUE, h=12))\n\noutput_list &lt;- list(output1, output2, output3, output4, output5)\n\n# Put into df\noutput_df &lt;- do.call(rbind, output_list)\n\n# Set row names for the dataframe\nrow.names(output_df) &lt;- c(\"ARIMA\", \"Meanf\", \"Naive\", \"SNaive\", \"Drift\")\n\noutput_df\n\n\n                  ME      RMSE       MAE         MPE      MAPE      MASE\nARIMA   9.533649e-02  1.474058  1.070741  0.07317726 0.9278111 0.2640729\nMeanf  -1.056836e-14 13.009848 11.112711 -1.22065210 9.5135777 2.7406872\nNaive   1.141304e-01  1.500374  1.096014  0.08659501 0.9496963 0.2703060\nSNaive  1.778491e+00  5.242155  4.054717  1.39387516 3.5019130 1.0000000\nDrift   2.500415e-15  1.496027  1.087839 -0.01244364 0.9430018 0.2682897\n               ACF1\nARIMA  -0.002323126\nMeanf   0.987698495\nNaive  -0.064131500\nSNaive  0.889680535\nDrift  -0.064131500\n\n\nUpon examining the accuracy metrics, it’s evident that the ARIMA model achieved the lowest RMSE, MAE, and MAPE values, followed by the Drift model. This suggests that the ARIMA model outperforms the benchmark models in terms of accuracy.\n\n\n\n\nCode\nautoplot(ups_ts, xlab = \"Date\", ylab = \"Stock Price\") +\n  autolayer(meanf(ups_ts, h=50),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(ups_ts, h=50),\n            series=\"Naïve\", PI=FALSE)+\n  autolayer(rwf(ups_ts, h=50, drift=TRUE),\n            series=\"Drift\", PI=FALSE)+\n   autolayer(pred_ups, \n            series=\"ARIMA\",PI=FALSE) + ggtitle(\"UPS Stock Price ARIMA vs. Benchmarks\")+\n  guides(colour=guide_legend(title=\"Forecast\")) +theme_bw()\n\n\n\n\n\nWe observe that the ARIMA, drift and Naive models exhibit a comparable trajectory for the forecast and best captures the trend, closely aligning with the observed data. In contrast, the Mean benchmark model notably underperform, failing to accurately capture the underlying trend.\n\n\nCode\n# Compute accuracy\noutput1 &lt;- accuracy(pred_ups)\noutput2 &lt;- accuracy(meanf(ups_ts, h=12))\noutput3 &lt;- accuracy(naive(ups_ts, h=12))\noutput4 &lt;- accuracy(rwf(ups_ts, drift=TRUE, h=12))\n\noutput_list &lt;- list(output1, output2, output3, output4)\n\n# Put into df\noutput_df &lt;- do.call(rbind, output_list)\n\n# Set row names for the dataframe\nrow.names(output_df) &lt;- c(\"ARIMA\", \"Meanf\", \"Naive\", \"Drift\")\n\noutput_df\n\n\n                 ME      RMSE       MAE          MPE      MAPE       MASE\nARIMA  5.174000e-05  2.336453  1.513770  -0.01543306  1.161838 0.04821097\nMeanf  1.080126e-12 40.426672 38.180111 -10.12057166 31.863702 1.21597048\nNaive  3.660448e-02  2.337403  1.515061   0.01546450  1.162754 0.04825207\nDrift -4.281767e-15  2.337116  1.514579  -0.01549866  1.162442 0.04823673\n            ACF1\nARIMA 0.03201877\nMeanf 0.99795274\nNaive 0.03201892\nDrift 0.03201892\n\n\nUpon examining the accuracy metrics, it’s evident that the ARIMA model achieved the lowest RMSE, MAE, and MAPE values, followed by the Drift model. This suggests that the ARIMA model outperforms the benchmark models in terms of accuracy.\n\n\n\n\n\nCross Validation\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexUPS Stock Price\n\n\n\n\nCode\ns &lt;- 12 \n\n# The length of the time series\nlen &lt;- length(canada_ts)\nst &lt;- tsp(canada_ts)[1]+(s-1)/s\n\n# Preallocate vectors to store forecasts and actual values\none_step_forecasts &lt;- vector(\"numeric\", len-s)\ns_step_forecasts &lt;- vector(\"numeric\", len-s)\nactuals &lt;- vector(\"numeric\", len-s)\n\n# Loop over the time series\nfor (i in 1:(len - s)) {\n  # Fit the model on the data up to the current point\n  model &lt;- auto.arima(window(canada_ts, end=st + i +s-1))\n  \n  # Forecast 1 step ahead\n  one_step_forecasts[i] &lt;- forecast(model, h=1)$mean\n  \n  # Forecast s steps ahead\n  s_step_forecasts[i] &lt;- forecast(model, h=s)$mean[s]\n  \n  # Store the actual value for the current point\n  actuals[i] &lt;- canada_ts[i+s]\n}\n\n# Calculate errors for 1-step forecasts\none_step_errors &lt;- actuals - one_step_forecasts\none_step_mae &lt;- mean(abs(one_step_errors))\none_step_rmse &lt;- sqrt(mean(one_step_errors^2))\n\n# Calculate errors for s-step forecasts\ns_step_errors &lt;- actuals - s_step_forecasts\ns_step_mae &lt;- mean(abs(s_step_errors))\ns_step_rmse &lt;- sqrt(mean(s_step_errors^2))\n\n# Print the error metrics\ncat(\"1-Step Forecast MAE:\", one_step_mae, \"\\n\")\n\n\n1-Step Forecast MAE: 11.34933 \n\n\nCode\ncat(\"1-Step Forecast RMSE:\", one_step_rmse, \"\\n\")\n\n\n1-Step Forecast RMSE: 12.80245 \n\n\nCode\ncat(\"s-Step Forecast MAE:\", s_step_mae, \"\\n\")\n\n\ns-Step Forecast MAE: 13.68438 \n\n\nCode\ncat(\"s-Step Forecast RMSE:\", s_step_rmse, \"\\n\")\n\n\ns-Step Forecast RMSE: 15.03506 \n\n\nThe best model provided by Auto ARIMA differs from the best model identified in the previous step. This discrepancy suggests that the Auto ARIMA model may offer a better fit compared to the previously chosen model, which was not optimal. It is plausible that this dataset exhibits strong seasonality, which ARIMA alone may struggle to capture adequately. Therefore, considering SARIMA models might be necessary to effectively model the seasonality present in the data.\n\n\n\n\nCode\ns &lt;- 12 \n\n# The length of the time series\nlen &lt;- length(employment_ts)\nst &lt;- tsp(employment_ts)[1]+(s-1)/s\n\n# Preallocate vectors to store forecasts and actual values\none_step_forecasts &lt;- vector(\"numeric\", len-s)\ns_step_forecasts &lt;- vector(\"numeric\", len-s)\nactuals &lt;- vector(\"numeric\", len-s)\n\n# Loop over the time series\nfor (i in 1:(len - s)) {\n  # Fit the model on the data up to the current point\n  model &lt;- auto.arima(window(employment_ts, end=st + i +s-1))\n  \n  # Forecast 1 step ahead\n  one_step_forecasts[i] &lt;- forecast(model, h=1)$mean\n  \n  # Forecast s steps ahead\n  s_step_forecasts[i] &lt;- forecast(model, h=s)$mean[s]\n  \n  # Store the actual value for the current point\n  actuals[i] &lt;- employment_ts[i+s]\n}\n\n# Calculate errors for 1-step forecasts\none_step_errors &lt;- actuals - one_step_forecasts\none_step_mae &lt;- mean(abs(one_step_errors))\none_step_rmse &lt;- sqrt(mean(one_step_errors^2))\n\n# Calculate errors for s-step forecasts\ns_step_errors &lt;- actuals - s_step_forecasts\ns_step_mae &lt;- mean(abs(s_step_errors))\ns_step_rmse &lt;- sqrt(mean(s_step_errors^2))\n\n# Print the error metrics\ncat(\"1-Step Forecast MAE:\", one_step_mae, \"\\n\")\n\n\n1-Step Forecast MAE: 23288.4 \n\n\nCode\ncat(\"1-Step Forecast RMSE:\", one_step_rmse, \"\\n\")\n\n\n1-Step Forecast RMSE: 28393.02 \n\n\nCode\ncat(\"s-Step Forecast MAE:\", s_step_mae, \"\\n\")\n\n\ns-Step Forecast MAE: 23429.42 \n\n\nCode\ncat(\"s-Step Forecast RMSE:\", s_step_rmse, \"\\n\")\n\n\ns-Step Forecast RMSE: 28524.71 \n\n\nThe discrepancy between the best model provided by Auto ARIMA and the best model identified in the previous step raises concerns about its reliability. Auto ARIMA solely relies on minimizing AIC/BIC values without considering lag instances of high correlation as reflected in the ACF/PACF plots. This approach may result in overfitting and may not capture the underlying patterns in the data accurately.\n\n\n\n\nCode\ns &lt;- 12 \n\n# The length of the time series\nlen &lt;- length(tsi_ts)\nst &lt;- tsp(tsi_ts)[1]+(s-1)/s\n\n# Preallocate vectors to store forecasts and actual values\none_step_forecasts &lt;- vector(\"numeric\", len-s)\ns_step_forecasts &lt;- vector(\"numeric\", len-s)\nactuals &lt;- vector(\"numeric\", len-s)\n\n# Loop over the time series\nfor (i in 1:(len - s)) {\n  # Fit the model on the data up to the current point\n  model &lt;- auto.arima(window(tsi_ts, end=st + i +s-1))\n  \n  # Forecast 1 step ahead\n  one_step_forecasts[i] &lt;- forecast(model, h=1)$mean\n  \n  # Forecast s steps ahead\n  s_step_forecasts[i] &lt;- forecast(model, h=s)$mean[s]\n  \n  # Store the actual value for the current point\n  actuals[i] &lt;- tsi_ts[i+s]\n}\n\n# Calculate errors for 1-step forecasts\none_step_errors &lt;- actuals - one_step_forecasts\none_step_mae &lt;- mean(abs(one_step_errors))\none_step_rmse &lt;- sqrt(mean(one_step_errors^2))\n\n# Calculate errors for s-step forecasts\ns_step_errors &lt;- actuals - s_step_forecasts\ns_step_mae &lt;- mean(abs(s_step_errors))\ns_step_rmse &lt;- sqrt(mean(s_step_errors^2))\n\n# Print the error metrics\ncat(\"1-Step Forecast MAE:\", one_step_mae, \"\\n\")\n\n\n1-Step Forecast MAE: 19.67232 \n\n\nCode\ncat(\"1-Step Forecast RMSE:\", one_step_rmse, \"\\n\")\n\n\n1-Step Forecast RMSE: 23.02626 \n\n\nCode\ncat(\"s-Step Forecast MAE:\", s_step_mae, \"\\n\")\n\n\ns-Step Forecast MAE: 20.92412 \n\n\nCode\ncat(\"s-Step Forecast RMSE:\", s_step_rmse, \"\\n\")\n\n\ns-Step Forecast RMSE: 24.25802 \n\n\nThe best model provided by Auto ARIMA differs from the best model identified in the previous step. This discrepancy suggests that the Auto ARIMA model may offer a better fit compared to the previously chosen model, which was not optimal. It is plausible that this dataset exhibits strong seasonality, which ARIMA alone may struggle to capture adequately. Therefore, considering SARIMA models might be necessary to effectively model the seasonality present in the data.\n\n\n\n\nCode\nups_ts\n\n\nTime Series:\nStart = 2017.00547945205 \nEnd = 2021.82135898662 \nFrequency = 365.25 \n   [1]  91.09904  91.12279  91.17028  91.35236  90.85363  90.18077  90.38659\n   [8]  90.17284  90.43410  90.29953  91.00403  90.45784  91.00403  90.60823\n  [15]  91.86694  92.61102  92.56354  93.48179  92.64268  86.38895  83.39662\n  [22]  83.19872  84.66320  83.95866  83.66581  84.03783  84.27532  84.97194\n  [29]  85.89020  86.27810  86.30186  85.52811  85.27284  85.92695  84.25180\n  [36]  83.82903  84.69849  85.13722  84.36347  85.24890  84.51504  84.49908\n  [43]  84.63470  84.26774  84.33954  84.47515  85.13722  85.74349  85.21700\n  [50]  85.94289  85.99076  86.26994  85.44835  84.96174  84.96969  84.27572\n  [57]  83.79712  83.58174  84.70647  84.57884  85.08139  85.59193  84.87400\n  [64]  85.05748  85.14519  85.08938  83.74924  84.88995  84.35548  83.14302\n  [71]  82.75214  83.65353  83.03931  83.32648  84.17999  84.37147  85.32867\n  [78]  85.63976  85.84717  86.81237  85.71954  84.98566  85.28879  85.63177\n  [85]  85.39249  85.69561  85.76740  84.96174  83.83699  83.74052  83.72443\n  [92]  84.65711  84.02192  82.71136  82.96862  83.15356  83.44302  83.78072\n  [99]  84.19882  85.17973  85.12347  85.87927  85.20384  86.56269  86.57073\n [106]  86.79585  86.37777  85.77474  85.83099  86.05614  87.59187  88.32352\n [113]  87.95365  88.65318  88.91852  89.14367  88.13055  87.79285  87.69638\n [120]  88.66122  89.25621  88.17881  88.50845  88.26726  88.91852  88.93460\n [127]  88.86222  87.83305  88.73360  88.61301  88.50042  88.90245  89.37681\n [134]  90.38187  90.07631  89.91553  90.84821  90.51855  90.59896  90.17282\n [141]  91.03314  90.28539  86.66722  88.17076  88.67729  88.58082  89.45724\n [148]  89.66627  90.09241  89.93966  89.96378  90.38187  89.84725  90.26847\n [155]  92.09100  92.48792  92.95775  91.46728  91.80747  92.20441  92.82811\n [162]  91.97761  91.81560  91.85609  92.17201  93.06303  93.12782  92.63370\n [169]  92.65803  92.27731  92.18819  92.88482  93.19263  94.12415  94.89369\n [176]  94.82078  95.07996  95.50119  95.25009  94.74787  95.44449  94.98277\n [183]  95.31489  95.76040  96.32742  96.08440  96.88632  97.27512  97.84212\n [190]  96.96730  96.39223  95.74418  95.33919  94.89369  95.67940  96.32742\n [197]  96.85390  95.87380  95.85760  95.32297  95.70369  96.73241  97.00782\n [204]  96.94301  96.95922  96.02769  96.65950  97.80975  95.65509  95.20147\n [211]  95.14478  94.66687  93.52474  92.27731  92.30160  91.63739  91.16759\n [218]  92.39980  93.68913  93.08529  92.12237  92.78334  92.16315  92.37531\n [225]  92.96288  92.84046  92.32636  93.46880  93.99923  97.14099  99.10760\n [232]  98.17734 100.96001  98.22630  96.52895  97.70404  97.56532  96.33311\n [239]  96.42286  96.61872  95.34571  96.29230  96.95329  97.10832  96.56158\n [246]  96.76559  96.81457  96.50446  97.17362  97.14914  97.23074 100.91923\n [253] 103.15517 103.82431 104.14256 105.40742 105.35847 105.91336 108.90823\n [260] 109.42232 108.43491 109.35704 109.01433 108.59814 108.41859 107.77396\n [267] 107.46384 107.13742 108.30436 106.60699 104.54243 103.89777  97.52450\n [274]  95.04376  92.45691  91.97548  91.32263  89.17645  86.81810  86.75282\n [281]  87.77288  86.98950  88.38490  87.56195  86.17115  86.16293  86.47565\n [288]  86.91183  88.93628  86.97766  85.92429  87.58665  86.71432  87.07642\n [295]  90.35999  89.87446  89.53705  90.83728  89.62756  89.97319  89.50413\n [302]  90.29415  91.27345  89.25723  88.90337  88.59065  85.95719  83.66120\n [309]  85.33998  84.08088  84.50058  86.13004  85.45521  86.85422  87.57020\n [316]  88.20387  86.68140  86.08063  87.24923  87.30685  88.04751  88.26144\n [323]  89.90734  90.12956  91.26523  90.26123  89.33131  89.79214  89.05971\n [330]  89.42182  93.22385  93.80814  93.40491  92.54081  91.47097  90.36822\n [337]  91.60264  92.26923  91.56973  91.67670  93.80814  95.00966  95.74208\n [344]  95.14134  95.72563  95.94781  95.69898  97.10903  95.68240  95.61605\n [351]  95.90633  95.79023  94.41339  96.78555  96.31276  97.25003  97.01776\n [358]  96.88506  97.05925  96.37082  96.71087  96.91824  98.15409  97.31638\n [365]  97.20024  96.85191  96.85191  95.23450  94.26411  94.07331  94.30555\n [372]  91.40258  90.88004  89.89301  87.81948  88.10978  87.81948  87.71992\n [379]  88.15952  87.94388  90.06720  90.00085  89.02214  90.01743  90.38239\n [386]  91.77582  92.12418  93.02827  93.59224  92.95358  93.48444  93.26048\n [393]  99.69681  98.59368  98.41950  98.46098  99.43971  99.00008  98.36973\n [400]  98.82592  99.14939  99.53923 100.01201 100.25255  98.92545  98.00479\n [407]  98.68494  99.57240 100.45158 101.78872 102.41551 102.79993 101.84723\n [414] 101.71350 102.57428 103.50191 102.58264 103.18435 102.66621 102.69128\n [421] 103.91142 104.17883 103.37656 102.78320 103.91142 102.85007 103.04227\n [428] 100.03374 100.61039  99.52395  98.81362  98.82198  99.54903  99.02254\n [435]  98.05313  97.15894  97.52663  97.55172  97.56843  98.16176  97.76897\n [442]  98.42919  98.03642  97.97791  99.26489  98.54619  97.48484  95.06966\n [449]  96.64079  96.74942  98.17848  98.62141  95.88029  97.35114  96.64079\n [456]  95.47081  90.19751  90.10558  88.00795  87.85754  89.47879  89.03587\n [463]  89.85486  88.57623  89.26987  90.79920  92.87176  93.18098  91.51791\n [470]  90.02201  91.42599  91.50955  92.30347  92.76693  93.77811  91.43556\n [477]  91.65465  91.58723  93.23040  93.96349  95.68249  95.43813  97.14870\n [484]  97.13184  89.96935  91.03951  88.74753  87.97231  87.28132  85.28425\n [491]  84.92190  83.13550  81.62714  81.97263  79.47841  79.15820  78.78743\n [498]  75.74549  81.40806  82.39396  81.34064  82.18330  81.91367  79.58794\n [505]  82.36028  82.08218  82.09061  82.51192  83.34616  82.50350  83.53996\n [512]  82.20858  81.72825  83.91072  85.61286  86.52292  85.03988  84.01183\n [519]  84.96404  84.54269  85.36008  85.26738  88.81492  89.39636  89.80927\n [526]  90.71932  91.69678  90.95525  91.09007  91.78944  93.24725  94.38483\n [533]  94.20788  93.42420  93.33994  93.59274  94.17414  92.99445  94.23553\n [540]  94.38853  94.46503  93.67449  95.31506  93.91248  93.47898  92.52692\n [547]  90.83536  90.68233  92.50994  92.66296  94.23553  94.25253  93.09647\n [554]  94.09101  93.80201  91.73638  93.33448  91.25187  90.86935  92.15292\n [561]  92.63743  93.75950  94.98354  97.27015  96.63264  97.20216  96.87914\n [568]  97.18515  96.87914  95.97810  96.12260  96.47112  97.29568  96.59862\n [575]  96.85362  97.32116  97.03214  96.58163  96.56462  97.27015  89.36476\n [582]  88.36173  89.11826  90.29131  88.93125  89.68779  90.65685  88.93125\n [589]  86.78064  86.57664  85.64162  85.53961  84.45153  84.80006  86.31315\n [596]  86.11764  85.30236  84.54717  85.31094  83.67183  82.53046  82.25585\n [603]  80.72832  81.32901  82.17002  79.74141  80.77979  83.80914  84.28113\n [610]  84.10093  84.29831  85.89449  85.82584  86.16052  87.55076  87.20751\n [617]  87.01870  87.66233  87.15602  88.73505  87.67950  85.57698  83.35431\n [624]  85.79152  87.27617  88.62347  88.36602  87.53362  88.56342  87.89404\n [631]  87.46494  87.30190  87.20751  88.67500  90.88907  90.78607  90.63160\n [638]  87.73098  88.22015  88.65781  89.25854  90.33984  98.16637 101.47891\n [645] 103.47848 101.90801 102.81767 102.52588 100.38905 100.57785  98.56115\n [652]  98.68986  99.04171 100.87820  99.33349  98.59544  99.40214  97.86602\n [659]  97.74586  99.78835 101.07791  99.56334 100.33363  99.71913  96.30919\n [666]  98.97482  98.77577 100.67981 102.44536 102.69635 101.54527 103.39735\n [673] 104.89461 103.92531 105.29273 105.93319 106.32264 106.07166 106.16687\n [680] 106.08032 105.92453 104.75616 103.09446 104.46188 103.03387 102.11648\n [687] 103.03387 102.51459 102.94732 103.70028 100.22975  99.73644 100.30765\n [694] 101.68372 100.02206  97.57276  98.54211  99.77107 100.41150 100.28170\n [701] 100.80961 101.69241 102.46265 101.56258 102.57519 100.48074  99.65855\n [708]  98.67192 100.15187 100.61055 101.18179 101.15582  99.67586 103.43199\n [715] 106.46978 105.05907 105.54372 106.87654 107.57758 106.57363 106.46111\n [722] 106.46978 107.38717 107.91922 107.08189 105.13685 103.80237 104.24719\n [729] 104.07275 104.92751 105.71251 104.55247 104.43037 103.11333 101.98816\n [736] 101.58694 100.31351 102.51149 103.04354 103.39243 101.86606 102.00560\n [743] 103.46220 103.89832 104.91879 102.87781 103.40986 102.39812 103.74131\n [750] 103.20926 103.82853 103.74131 101.56077 102.10155 101.86606 101.80498\n [757] 101.35143 101.17699 101.75267 101.98816 101.06361 101.83116 102.28471\n [764] 102.86038 103.45348 103.44476 102.38938 102.27599 101.98816 101.75267\n [771] 100.23499 100.62751 100.96766  94.19927  90.29176  88.99213  90.16962\n [778]  92.48974  92.89967  89.94287  89.89925  91.46925  92.05362  91.79197\n [785]  92.41123  92.82117  93.11772  92.87350  89.78585  86.75571  82.71257\n [792]  82.56283  79.48862  79.70885  81.69958  80.42235  84.40380  81.91098\n [799]  82.80067  76.79321  81.76125  77.50670  75.90353  83.00324  76.68750\n [806]  85.25826  87.43396  84.78258  82.32500  80.95085  83.91054  83.24108\n [813]  87.89201  85.90127  86.18315  82.28976  79.62074  81.95502  79.27722\n [820]  84.28050  81.84053  87.01997  86.93187  86.69405  89.31901  88.01533\n [827]  90.04131  90.50818  89.14284  88.63194  85.98055  87.60133  88.24436\n [834]  90.33199  84.94112  84.65926  83.38203  80.95085  79.66480  81.66435\n [841]  81.85813  81.77007  83.53177  82.72138  81.78765  79.92906  80.76588\n [848]  80.18449  84.65045  84.94112  85.60178  85.71629  86.09014  86.40166\n [855]  88.67142  88.76041  88.75153  88.36878  90.05106  92.25852  91.85796\n [862]  94.92879  98.31115  95.97911  94.91100  89.42801  90.32700  94.02979\n [869]  94.19891  95.23143  95.75658  95.92570  95.15132  98.45359  97.46557\n [876]  98.37348  95.52517  97.44776  98.96093 101.84484 101.79144 102.68153\n [883] 101.87154 101.88934 101.87154 102.42339 101.25737 102.65482 106.10842\n [890] 106.58018 105.52094 105.34293 105.95708 105.67226 105.15598 105.34293\n [897] 107.71059 106.47334 110.08714 125.91306 127.07017 126.55392 128.81477\n [904] 129.13521 129.48235 139.65614 142.05051 138.72157 140.44832 141.78348\n [911] 143.07413 142.68246 142.40654 142.71809 142.01489 142.45381 143.63622\n [918] 142.46277 142.33740 143.51082 145.43674 146.56538 145.69650 148.50026\n [925] 141.54913 144.02142 140.14278 143.14357 141.43260 142.31050 143.44814\n [932] 144.69325 143.20627 143.09877 143.01817 144.27225 145.01572 144.71117\n [939] 143.68997 148.80481 151.29501 150.93677 149.26166 150.17535 149.55725\n [946] 151.52794 151.69814 156.75029 156.05157 156.48154 158.13870 157.05481\n [953] 156.20386 155.89929 156.25757 154.16151 156.65172 154.72583 154.95874\n [960] 153.98235 150.48885 153.03284 139.54259 144.54099 140.73396 142.91962\n [967] 146.43999 145.63380 146.51164 150.20218 146.20709 147.55968 149.27061\n [974] 146.99950 147.50418 151.80307 152.19962 151.81206 150.03665 147.58531\n [981] 150.14484 155.63332 153.65961 152.20862 154.17331 151.37047 152.15454\n [988] 151.25331 150.73062 150.92889 149.95555 152.46999 148.01791 151.76700\n [995] 150.16283 150.65851 153.32614 157.25549 157.87737 155.54317 157.31862\n[1002] 155.58824 155.18269 154.43465 152.33478 149.81136 151.76700 147.62135\n[1009] 145.56656 145.13396 143.29544 142.74571 145.87300 147.72050 146.99950\n[1016] 147.32396 143.20535 140.84410 144.05251 144.28683 143.28645 145.77383\n[1023] 145.48544 142.07881 141.73634 139.69055 140.82611 144.45802 143.93533\n[1030] 146.23347 148.14407 147.30591 150.43317 149.29764 146.33258 147.25185\n[1037] 145.77383 145.09793 146.10728 145.59940 146.56076 145.84427 145.17316\n[1044] 142.85139 143.14162 146.44287 146.35219 145.49965 144.61084 149.10017\n[1051] 145.89868 148.07533 149.85294 151.67589 152.08400 147.50398 147.66721\n[1058] 145.69917 145.29106 144.46574 146.07100 144.98271 145.02806 148.05721\n[1065] 152.34702 152.49213 152.94557 154.16995 155.33990 155.94754 156.87262\n[1072] 155.94754 156.91795 159.56624 161.96054 162.72235 159.81111 162.92189\n[1079] 162.98538 161.48892 162.96721 161.95146 160.99011 162.30516 159.44830\n[1086] 176.06337 179.90877 184.76086 184.88785 192.45169 194.36534 194.55579\n[1093] 194.79158 197.25845 196.01598 194.38347 191.09129 195.59874 196.24268\n[1100] 196.16104 194.07510 194.40164 194.02977 193.07292 194.49448 192.72662\n[1107] 194.84079 193.92041 195.56071 194.36694 193.10936 193.17316 191.94293\n[1114] 194.02977 191.15013 183.22200 185.17210 185.17210 183.24934 184.38841\n[1121] 182.63879 180.47903 180.22386 185.28149 187.17691 185.91937 187.81485\n[1128] 187.36832 187.02203 189.19089 189.51892 191.56927 192.76309 192.54440\n[1135] 195.25090 193.25522 194.94104 194.40338 192.52615 192.76309 193.97508\n[1142] 191.88824 192.65375 193.61058 193.60147 194.31227 192.86331 191.24126\n[1149] 177.87277 175.00221 174.79265 174.38257 174.91109 176.92503 173.86316\n[1156] 173.52597 175.51254 174.03629 173.69911 175.33031 176.46028 176.77010\n[1163] 179.58598 180.21475 177.51735 176.84302 177.02626 176.80638 177.05370\n[1170] 176.68730 176.22008 177.08122 177.73163 179.21571 179.92110 181.56094\n[1177] 180.78223 179.15158 178.24467 173.15115 177.04457 178.07976 174.98335\n[1184] 177.12704 176.77890 174.08554 173.49927 173.81075 169.75246 171.11740\n[1191] 172.24422 171.16324 171.08992 169.23943 166.82095 166.26215 163.44971\n[1198] 164.59482 165.53841 166.36290 168.09431 166.49115 166.72018 168.61650\n[1205] 175.35895 177.49345 177.16365 177.53009 178.88593 182.70604 186.70937\n[1212] 186.79182 199.77290 194.40456 195.95276 195.55885 193.20448 191.59215\n[1219] 194.89012 193.03960 190.74936 191.73872 192.34335 193.88239 195.39395\n[1226] 195.30235 193.77248 194.09309 190.41040 190.06226 191.92194 194.14066\n[1233] 194.99681 191.92194 189.00356 188.39597 182.62366 178.73863 184.03221\n[1240] 184.79633 186.02077 189.08641 188.46960 190.14513 192.51114 189.93338\n[1247] 187.56741 189.43626 191.46162 190.19115 186.36137 190.66069 191.89432\n[1254] 195.34666 198.03485 197.63899 197.56535 196.92091 197.32599 196.55267\n[1261] 200.04182 197.52850 199.44341 200.84276 194.92317 194.49965 194.45364\n[1268] 193.76318 190.14513 189.27052 187.58582 186.23248 185.91949 187.92644\n[1275] 185.91026 183.20364 179.36465 182.51317 186.15886 212.37813 213.68541\n[1282] 210.53691 206.94649 207.19505 207.32394 207.20425 203.16269 196.54347\n[1289] 197.00374 200.01421 198.21899 193.98413 194.14177 193.78009 189.61647\n[1296] 192.12950 194.68890 195.12471 190.63652 196.08911 196.98860 195.09689\n[1303] 186.55637 188.62427 191.74931 192.12021 189.07864 189.44958 195.22670\n[1310] 202.06100 206.15973 203.80434 202.67302 202.54320 198.98235 199.05652\n[1317] 199.69638 203.59108 206.28029 204.19383 198.87108 191.61948 190.29344\n[1324] 182.87495 180.25990 178.69276 177.08853 176.96799 174.23242 175.14117\n[1331] 174.35297 173.55550 176.82890 176.58777 175.07625 173.54619 175.85521\n[1338] 169.74423 172.85072 176.33742 166.89738 165.59915 165.17256 170.43971\n[1345] 166.72119 166.84175 168.24199 168.77980 164.56058 165.66405 166.51514\n[1352] 168.13319 171.28502 161.08124 156.55455 159.96826 163.10141 162.83954\n[1359] 162.60573 166.83313 170.71452 170.45262 168.56339 172.15483 173.48293\n[1366] 174.99803 173.50159 167.82454 165.12160 161.84816 161.53954 162.88632\n[1373] 164.49498 161.04384 159.99635 163.20428 164.74748 167.06697 171.43466\n[1380] 170.04111 168.27347 169.40514 170.72386 173.01527 172.67857 173.18361\n[1387] 174.13759 173.39871 172.68793 167.75906 166.40294 166.73961 170.77063\n[1394] 168.42311 173.78217 174.75487 174.90450 175.81171 175.74625 169.77924\n[1401] 171.99580 176.05490 182.27441 182.69528 181.00246 180.89955 181.92839\n[1408] 184.02336 183.39674 183.92050 189.27023 191.19688 193.06258 193.99545\n[1415] 194.43831 193.14737 196.04019 196.39822 194.48543 193.42065 191.31937\n[1422] 193.16624 187.44664 185.88246 183.79060 183.28178 185.26054 184.73288\n[1429] 184.64809 184.95901 184.80826 187.22050 188.61507 181.58568 179.93671\n[1436] 174.32076 166.50931 169.63766 165.53876 163.79553 158.17017 154.84395\n[1443] 152.41289 155.25854 157.47287 155.77681 152.21500 153.67552 159.14073\n[1450] 158.23613 156.04065 149.95352 150.51892 150.20796 150.27391 154.21263\n[1457] 152.34691 155.21143 157.35039 156.21965 151.68732 155.99353 157.87805\n[1464] 157.35982 159.23495 156.87926 157.52000 158.08537 157.73672 155.07950\n[1471] 154.54240 156.12544 159.36687 159.04648 154.54240 163.89162 169.47452\n[1478] 169.09406 172.59410 168.39977 167.44868 170.21637 171.77615 173.80197\n[1485] 173.89706 173.59271 171.11038 175.84680 180.45007 180.88759 180.12669\n[1492] 172.29924 166.53566 166.12669 170.84409 168.95142 173.60223 174.85767\n[1499] 175.29518 172.34682 169.48402 169.70276 165.13756 168.03836 167.02071\n[1506] 168.35223 168.27612 165.11852 167.15385 165.33727 166.70683 168.44731\n[1513] 165.33727 170.19733 172.80331 170.02615 173.31689 174.00169 173.24080\n[1520] 170.24490 168.07640 167.53429 169.41745 171.65250 171.18646 168.78023\n[1527] 170.91066 173.18376 168.31419 176.17017 175.93242 181.93379 182.28566\n[1534] 179.52750 179.08049 177.24490 175.71365 176.16066 178.24355 177.63487\n[1541] 177.70143 176.47453 175.78372 171.22627 169.45123 172.64627 172.84775\n[1548] 174.84341 175.09290 175.65897 177.19412 178.15359 178.94995 175.84129\n[1555] 176.82953 175.46710 174.18141 174.84341 177.55872 176.88708 180.30280\n[1562] 179.21858 176.05237 179.21858 178.01927 177.77939 178.52779 179.72713\n[1569] 180.12050 183.70891 183.34430 186.12674 185.86768 182.88376 181.72279\n[1576] 180.93604 182.54793 184.64917 182.15457 183.25795 185.05214 185.45512\n[1583] 186.25150 188.08408 187.07661 187.29732 187.91138 169.14421 165.57501\n[1590] 170.55463 172.52153 174.81465 170.63138 168.70285 166.26582 168.61652\n[1597] 167.32121 165.99716 164.61554 163.32985 163.22330 163.56235 161.39249\n[1604] 165.99373 165.68373 165.57718 166.13902 164.47289 162.46773 165.86780\n[1611] 166.19716 164.44382 161.77026 162.57428 164.81194 162.59364 162.34177\n[1618] 166.12935 166.10995 165.15097 166.12935 167.47581 169.40350 173.39447\n[1625] 172.98764 171.71866 168.19266 166.01311 163.98856 167.34019 169.20009\n[1632] 170.15907 170.53687 173.63666 178.01511 174.33411 173.66570 174.13066\n[1639] 175.65150 179.43907 180.64993 179.55530 179.45844 177.01736 178.79005\n[1646] 180.19464 181.08583 181.43456 182.44200 178.90628 178.61568 180.67899\n[1653] 182.00609 181.26988 179.69093 177.60825 175.81619 175.27373 176.44583\n[1660] 174.89594 173.75288 174.73126 172.63950 171.55450 169.35522 166.89201\n[1667] 166.89201 167.38075 164.69272 163.09946 165.07394 163.23630 165.06415\n[1674] 165.03484 167.87924 168.13338 165.58220 164.21376 160.27458 158.65199\n[1681] 158.58359 157.41061 157.26401 153.04138 154.28275 157.10760 156.87303\n[1688] 154.86923 154.44890 154.08725 151.92705 150.31424 150.83229 148.47661\n[1695] 148.97511 151.99547 152.35713 151.58495 150.28491 150.25560 149.92326\n[1702] 150.79320 150.86160 152.04436 151.79999 151.87819 151.58495 153.11955\n[1709] 153.63760 150.35335 148.63300 148.53526 144.82091 145.95477 143.61862\n[1716] 135.09514 131.79132 135.65230 138.06664 136.64931 138.78996 139.64035\n[1723] 139.06364 138.65312 138.75085 136.79593 136.57837 136.63771 141.58226\n[1730] 145.53789 145.28078 146.33891 147.91129 148.10907 149.07820 150.34399\n[1737] 147.93106 149.06831 150.60110 149.92867 153.19206 154.19086 152.45038\n[1744] 153.56784 154.76443 154.56665 154.05241 153.64696 155.50610 160.55945\n[1751] 161.13301 159.77821 159.82764 155.21933 155.41711 156.49503 156.27747\n[1758] 155.10065 155.56544 155.48633\n\n\nThe best model Auto ARIMA provide is the same with the best model from the step above."
  },
  {
    "objectID": "univariate_ts_model.html#acf-pacf-plots-1",
    "href": "univariate_ts_model.html#acf-pacf-plots-1",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "ACF & PACF Plots",
    "text": "ACF & PACF Plots\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexUPS Stock Price\n\n\n\n\nCode\ncanada_ts %&gt;% diff(lag=12) %&gt;% diff() %&gt;% ggtsdisplay()\n\n\n\n\n\nSignificant changes are apparent in the seasonal differenced dataset, evident from the time series plot. Although the seasonal cycles persist in the plots for seasonal lags 1 and 2, there is a discernible decrease in correlation observed in both the ACF and PACF plots. This reduction in correlation signifies a potential enhancement in stationarity, suggesting that the seasonal differencing has effectively mitigated the seasonality inherent in the original data.\n\nP: 1,2 D: 1 Q: 1,2\n\n\n\n\n\nCode\nemployment_ts %&gt;% diff(lag=12) %&gt;% diff() %&gt;% ggtsdisplay()\n\n\n\n\n\nSignificant changes are apparent in the seasonal differenced dataset, evident from the time series plot. Although the seasonal cycles persist in the plots for seasonal lags 1, there is a discernible decrease in correlation observed in both the ACF and PACF plots. This reduction in correlation signifies a potential enhancement in stationarity, suggesting that the seasonal differencing has effectively mitigated the seasonality inherent in the original data.\n\nP: 1,2 D: 1 Q: 1\n\n\n\n\n\nCode\ntsi_ts %&gt;% diff(lag=12) %&gt;% diff() %&gt;% ggtsdisplay()\n\n\n\n\n\nSignificant changes are apparent in the seasonal differenced dataset, evident from the time series plot. Although the seasonal cycles persist in the plots for seasonal lags 1 and 2, there is a discernible decrease in correlation observed in both the ACF and PACF plots. This reduction in correlation signifies a potential enhancement in stationarity, suggesting that the seasonal differencing has effectively mitigated the seasonality inherent in the original data.\n\nP: 1,2 D: 1 Q: 1\n\n\n\n\n\nCode\nups_ts %&gt;% diff(lag=12) %&gt;% diff() %&gt;% ggtsdisplay(lag=40)\n\n\n\n\n\nSignificant changes are apparent in the seasonal differenced dataset, evident from the time series plot. Although the seasonal cycles persist in the plots for seasonal lags 1 and 2, there is a discernible decrease in correlation observed in both the ACF and PACF plots. This reduction in correlation signifies a potential enhancement in stationarity, suggesting that the seasonal differencing has effectively mitigated the seasonality inherent in the original data.\n\nP: 1 D: 1 Q: 1"
  },
  {
    "objectID": "univariate_ts_model.html#finding-model-parameters-for-selected-models",
    "href": "univariate_ts_model.html#finding-model-parameters-for-selected-models",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "Finding Model Parameters For Selected Models",
    "text": "Finding Model Parameters For Selected Models\nIn this section, we will identify potential values for the parameters p, q, P and Q based on the significant lags observed in the PACF and ACF plots of the original data, respectively. Specifically, we will consider the most significant lags from the PACF plot for the value of p,P, and from the ACF plot for the value of q,Q.\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexUPS Stock Price\n\n\np = 0,1,2,3,4 d = 0,1,2 q = 0,1,2,3,4, P: 1,2 D: 1, Q: 1,2\n\n\nCode\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,d1,d2,data){\n  \n  temp=c()\n  D=1\n  s=12\n  \n  i=1\n  temp= data.frame()\n  ls=matrix(rep(NA,9*150),nrow=150)\n  \n  \n  for (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P1)\n      {\n        for(Q in Q1:Q1)\n        {\n          for(d in d1:d2)\n            {\n          if(p+d+q+P+D+Q&lt;=10)\n          {\n            \n            model&lt;- Arima(data,order=c(p,d,q),seasonal=c(P,D,Q))\n            ls[i,]= c(p,d,q,P,D,Q,model$aic,model$bic,model$aicc)\n            i=i+1\n            #print(i)\n            \n          }\n          \n        }\n      }\n    }\n    \n  }\n  }\n  \n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  \n  temp\n  \n}\n\n\noutput=SARIMA.c(p1=0,p2=4,q1=0,q2=2,P1=0,P2=2,Q1=0,Q2=2,d1=0,d2=2,data=canada_ts)\n#output\n\noutput[which.min(output$AIC),] \n\n\n   p d q P D Q      AIC      BIC     AICc\n43 4 0 2 0 1 0 999.1474 1021.986 999.7528\n\n\nCode\noutput[which.min(output$BIC),] \n\n\n  p d q P D Q      AIC     BIC     AICc\n2 0 1 0 0 1 0 1012.312 1015.57 1012.333\n\n\nCode\noutput[which.min(output$AICc),] \n\n\n   p d q P D Q      AIC      BIC     AICc\n43 4 0 2 0 1 0 999.1474 1021.986 999.7528\n\n\nThe model with the lowest AIC and BIC is ARIMA(4,0,2)X(0,1,0)12.\n\n\np = 0,1,2, d = 0,1,2, q = 0,1,2,3, P: 1,2, D: 1, Q: 1,\n\n\nCode\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,d1,d2,data){\n  \n  temp=c()\n  D=1\n  s=12\n  \n  i=1\n  temp= data.frame()\n  ls=matrix(rep(NA,9*150),nrow=150)\n  \n  \n  for (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P1)\n      {\n        for(Q in Q1:Q1)\n        {\n          for(d in d1:d2)\n            {\n          if(p+d+q+P+D+Q&lt;=10)\n          {\n            \n            model&lt;- Arima(data,order=c(p,d,q),seasonal=c(P,D,Q))\n            ls[i,]= c(p,d,q,P,D,Q,model$aic,model$bic,model$aicc)\n            i=i+1\n            #print(i)\n            \n          }\n          \n        }\n      }\n    }\n    \n  }\n  }\n\n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  \n  temp\n  \n}\n\n\noutput=SARIMA.c(p1=0,p2=2,q1=0,q2=3,P1=0,P2=2,Q1=0,Q2=1,d1=0,d2=2,data=employment_ts)\n#output\n\noutput[which.min(output$AIC),] \n\n\n   p d q P D Q      AIC      BIC     AICc\n35 2 1 3 0 1 0 4523.232 4543.484 4523.634\n\n\nCode\noutput[which.min(output$BIC),] \n\n\n   p d q P D Q      AIC      BIC     AICc\n35 2 1 3 0 1 0 4523.232 4543.484 4523.634\n\n\nCode\noutput[which.min(output$AICc),] \n\n\n   p d q P D Q      AIC      BIC     AICc\n35 2 1 3 0 1 0 4523.232 4543.484 4523.634\n\n\nThe model with the lowest AIC and BIC is ARIMA(2,1,3)X(0,1,0)12.\n\n\np = 0,1 d = 0,1, q = 0,1,2,3 P: 1,2 D: 0,1, Q: 1\n\n\nCode\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,d1,d2,data){\n  \n  temp=c()\n  D=0\n  s=12\n  \n  i=1\n  temp= data.frame()\n  ls=matrix(rep(NA,9*150),nrow=150)\n  \n  \n  for (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P1)\n      {\n        for(Q in Q1:Q1)\n        {\n          for(d in d1:d2)\n            {\n          if(p+d+q+P+D+Q&lt;=10)\n          {\n            \n            model&lt;- Arima(data,order=c(p,d,q),seasonal=c(P,D,Q))\n            ls[i,]= c(p,d,q,P,D,Q,model$aic,model$bic,model$aicc)\n            i=i+1\n            #print(i)\n            \n          }\n          \n        }\n      }\n    }\n    \n  }\n  }\n\n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  \n  temp\n  \n}\n\n\noutput=SARIMA.c(p1=0,p2=1,q1=0,q2=3,P1=0,P2=2,Q1=0,Q2=1,d1=0,d2=1,data=tsi_ts)\n#output\n\noutput[which.min(output$AIC),] \n\n\n   p d q P D Q      AIC      BIC    AICc\n16 1 1 3 0 0 0 1008.547 1026.649 1008.77\n\n\nCode\noutput[which.min(output$BIC),] \n\n\n  p d q P D Q      AIC      BIC     AICc\n2 0 1 0 0 0 0 1009.209 1012.829 1009.223\n\n\nCode\noutput[which.min(output$AICc),] \n\n\n   p d q P D Q      AIC      BIC    AICc\n16 1 1 3 0 0 0 1008.547 1026.649 1008.77\n\n\nThe model with the lowest AIC and BIC is ARIMA(1,1,3)X(0,0,0).\n\n\np = 0,1, d = 0,1, q = 0,1, P: 1, D: 1, Q: 1\n\n\nCode\nSARIMA.c=function(p1,p2,q1,q2,P1,P2,Q1,Q2,d1,d2,data){\n  \n  temp=c()\n  D=1\n  s=365\n  \n  i=1\n  temp= data.frame()\n  ls=matrix(rep(NA,9*150),nrow=150)\n  \n  \n  for (p in p1:p2)\n  {\n    for(q in q1:q2)\n    {\n      for(P in P1:P1)\n      {\n        for(Q in Q1:Q1)\n        {\n          for(d in d1:d2)\n            {\n          if(p+d+q+P+D+Q&lt;=10)\n          {\n            \n            model&lt;- Arima(data,order=c(p,d,q),seasonal=c(P,D,Q))\n            ls[i,]= c(p,d,q,P,D,Q,model$aic,model$bic,model$aicc)\n            i=i+1\n            #print(i)\n            \n          }\n          \n        }\n      }\n    }\n    \n  }\n  }\n\n  temp= as.data.frame(ls)\n  names(temp)= c(\"p\",\"d\",\"q\",\"P\",\"D\",\"Q\",\"AIC\",\"BIC\",\"AICc\")\n  \n  temp\n  \n}\n\n\noutput=SARIMA.c(p1=0,p2=1,q1=0,q2=1,P1=0,P2=1,Q1=0,Q2=1,d1=0,d2=1,data=ups_ts)\n#output\n\noutput[which.min(output$AIC),] \n\n\n  p d q P D Q      AIC      BIC     AICc\n2 0 1 0 0 1 0 7409.142 7414.382 7409.145\n\n\nCode\noutput[which.min(output$BIC),] \n\n\n  p d q P D Q      AIC      BIC     AICc\n2 0 1 0 0 1 0 7409.142 7414.382 7409.145\n\n\nCode\noutput[which.min(output$AICc),] \n\n\n  p d q P D Q      AIC      BIC     AICc\n2 0 1 0 0 1 0 7409.142 7414.382 7409.145\n\n\nThe model with the lowest AIC and BIC is ARIMA(0,1,0)X(0,1,0)12."
  },
  {
    "objectID": "univariate_ts_model.html#fit-best-sarimapdq-diagnostics",
    "href": "univariate_ts_model.html#fit-best-sarimapdq-diagnostics",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "Fit Best SARIMA(P,D,Q) & Diagnostics",
    "text": "Fit Best SARIMA(P,D,Q) & Diagnostics\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexUPS Stock Price\n\n\n\n\nCode\nset.seed(99)\noutput &lt;- capture.output(sarima(canada_ts,4,0,2,0,1,0,12))\n\n\n\n\n\nCode\ncat(output[96:108], output[length(output)], sep = \"\\n\") \n\n\nCoefficients: \n         Estimate     SE  t.value p.value\nar1        0.6848 0.0713   9.5986  0.0000\nar2       -0.6141 0.0601 -10.2185  0.0000\nar3        0.8666 0.0611  14.1891  0.0000\nar4       -0.2061 0.0708  -2.9106  0.0040\nma1        0.3393 0.0166  20.4202  0.0000\nma2        1.0000 0.0244  41.0032  0.0000\nconstant   0.1101 0.1546   0.7117  0.4775\n\nsigma^2 estimated as 9.275475 on 186 degrees of freedom \n \nAIC = 5.184752  AICc = 5.187888  BIC = 5.319993 \n \n\n\nEquation: \\(x_t= 0.6848*x_{t-1} -0.6141*x_{t-2} +0.8666*x_{t-3} -0.2061*x_{t-4}-0.6848*x_{t-13} +0.6141*x_{t-14} -0.8666*x_{t-15} +0.2061*x_{t-16} +w_t +0.3393*w_{t-1} +w_{t-2} +0.1101\\)\nUpon inspection of the time plot of the standardized residuals above, no discernible patterns are evident. However, the ACF plot of the standardized residuals indicates some remaining correlation. The normal Q-Q plot of the residuals suggests that the assumption of normality is reasonable, with the exception of potential outliers. The results of the Ljung-Box test reveal values below the 0.05 (5% significance) threshold, indicating the presence of some significant correlation remaining. All the P values are significant. Despite these findings, it appears that the model has been improved.\n\n\n\n\nCode\nset.seed(99)\noutput &lt;- capture.output(sarima(employment_ts,2,1,3,0,1,0,12))\n\n\n\n\n\nCode\ncat(output[48:58], output[length(output)], sep = \"\\n\") \n\n\nCoefficients: \n    Estimate     SE  t.value p.value\nar1   0.1874 0.0457   4.0975   1e-04\nar2  -0.8431 0.0411 -20.5313   0e+00\nma1   0.3593 0.0768   4.6805   0e+00\nma2   0.9952 0.0298  33.4238   0e+00\nma3   0.3723 0.0741   5.0210   0e+00\n\nsigma^2 estimated as 66844570 on 211 degrees of freedom \n \nAIC = 20.94089  AICc = 20.94221  BIC = 21.03465 \n \n\n\n\\(x_t= 1.1874*x_{t-1} -1.0305*x_{t-2} +0.8431*x_{t-3} +x_{t-12}-1.1874*x_{t-13} +1.1874*x_{t-14} -0.8431*x_{t-15} +w_t +0.3593*w_{t-1} +0.9952*w_{t-2} +0.3723*w_{t-3}\\)\nUpon inspection of the time plot of the standardized residuals above, no discernible patterns are evident. However, the ACF plot of the standardized residuals indicates some remaining correlation. The normal Q-Q plot of the residuals suggests that the assumption of normality is reasonable, with the exception of potential outliers. The results of the Ljung-Box test reveal values below the 0.05 (5% significance) threshold, indicating the presence of some significant correlation remaining. All the P values are significant. Despite these findings, it appears that the model has been improved.\n\n\n\n\nCode\nset.seed(99)\noutput &lt;- capture.output(sarima(tsi_ts,1,1,3,0,0,0,12))\n\n\n\n\n\nCode\ncat(output[45:55], output[length(output)], sep = \"\\n\") \n\n\nCoefficients: \n         Estimate     SE t.value p.value\nar1        0.5867 0.2181  2.6905  0.0076\nma1       -0.6583 0.2206 -2.9849  0.0031\nma2       -0.0582 0.0737 -0.7888  0.4309\nma3        0.1708 0.0650  2.6269  0.0091\nconstant   0.1053 0.0975  1.0795  0.2813\n\nsigma^2 estimated as 2.172189 on 271 degrees of freedom \n \nAIC = 3.657447  AICc = 3.658252  BIC = 3.736151 \n \n\n\nEquation: \\(x_t= 1.5867*x_{t-1} -0.5867*x_{t-2} +w_t -0.6583*w_{t-1} -0.0582*w_{t-2} +0.1708*w_{t-3} +0.1053\\)\nUpon examining the time plot of the standardized residuals, no discernible patterns are evident. Additionally, the ACF plot of the standardized residuals reveals no significant departures from the model assumptions, as no significant lags are observed. The normal Q-Q plot of the residuals indicates that the assumption of normality is reasonable, with the exception of possible outliers. Furthermore, the Ljung-Box test yields favorable values exceeding 0.05, suggesting the absence of significant correlation and indicating a well-fitted model. Overall, these observations suggest that the model fits the data well.\n\n\n\n\nCode\nset.seed(99)\noutput &lt;- capture.output(sarima(ups_ts,0,1,0,0,1,0,12))\n\n\n\n\n\nCode\ncat(output, output[length(output)], sep = \"\\n\") \n\n\n&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;&lt;&gt;\n \nCoefficients: \n     Estimate p.value\n\nsigma^2 estimated as 11.05996 on 1747 degrees of freedom \n \nAIC = 5.242353  AICc = 5.242353  BIC = 5.245482 \n \n \n\n\nEquation: \\(x_t= x_{t-1} + x_{t-12} -x_{t-13} +w_t\\)\nUpon examining the time plot of the standardized residuals, no discernible patterns are evident. Additionally, the ACF plot of the standardized residuals reveals just one significant departures from the model assumptions. The normal Q-Q plot of the residuals indicates that the assumption of normality is reasonable, with the exception of possible outliers. The results of the Ljung-Box test reveal values below the 0.05 (5% significance) threshold, indicating the presence of some significant correlation remaining. Despite these findings, it appears that the model has been improved."
  },
  {
    "objectID": "univariate_ts_model.html#auto-arima-1",
    "href": "univariate_ts_model.html#auto-arima-1",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "Auto ARIMA",
    "text": "Auto ARIMA\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexUPS Stock Price\n\n\n\n\nCode\nauto.arima(canada_ts)\n\n\nSeries: canada_ts \nARIMA(2,1,5)(1,0,0)[12] \n\nCoefficients:\n          ar1      ar2     ma1     ma2     ma3      ma4     ma5    sar1\n      -0.1410  -0.4216  0.1452  0.4440  0.0703  -0.3019  0.2020  0.5636\ns.e.   0.1988   0.2128  0.1977  0.2187  0.0836   0.0907  0.1092  0.0718\n\nsigma^2 = 8.695:  log likelihood = -508.85\nAIC=1035.71   AICc=1036.63   BIC=1065.57\n\n\nThe discrepancy between the best model provided by Auto ARIMA and the best model identified in the previous step raises concerns about its reliability. Auto ARIMA solely relies on minimizing AIC/BIC values without considering lag instances of high correlation as reflected in the ACF/PACF plots. This approach may result in overfitting and may not capture the underlying patterns in the data accurately.\n\n\n\n\nCode\nauto.arima(employment_ts)\n\n\nSeries: employment_ts \nARIMA(0,1,1) \n\nCoefficients:\n         ma1\n      0.4204\ns.e.  0.0536\n\nsigma^2 = 41251784:  log likelihood = -2322.12\nAIC=4648.25   AICc=4648.3   BIC=4655.11\n\n\nThe discrepancy between the best model provided by Auto ARIMA and the best model identified in the previous step raises concerns about its reliability. Auto ARIMA solely relies on minimizing AIC/BIC values without considering lag instances of high correlation as reflected in the ACF/PACF plots. This approach may result in overfitting and may not capture the underlying patterns in the data accurately.\n\n\n\n\nCode\nauto.arima(tsi_ts)\n\n\nSeries: tsi_ts \nARIMA(3,1,0)(0,0,2)[12] with drift \n\nCoefficients:\n          ar1      ar2     ar3     sma1     sma2   drift\n      -0.0787  -0.0820  0.0791  -0.1773  -0.1487  0.1261\ns.e.   0.0605   0.0614  0.0623   0.0634   0.0655  0.0560\n\nsigma^2 = 2.129:  log likelihood = -493.41\nAIC=1000.82   AICc=1001.24   BIC=1026.16\n\n\nThe discrepancy between the best model provided by Auto ARIMA and the best model identified in the previous step raises concerns about its reliability. Auto ARIMA solely relies on minimizing AIC/BIC values without considering lag instances of high correlation as reflected in the ACF/PACF plots. This approach may result in overfitting and may not capture the underlying patterns in the data accurately.\n\n\n\n\nCode\nauto.arima(ups_ts)\n\n\nSeries: ups_ts \nARIMA(0,1,0) \n\nsigma^2 = 5.463:  log likelihood = -3989.38\nAIC=7980.75   AICc=7980.75   BIC=7986.22\n\n\nThe discrepancy between the best model provided by Auto ARIMA and the best model identified in the previous step raises concerns about its reliability. Auto ARIMA solely relies on minimizing AIC/BIC values without considering lag instances of high correlation as reflected in the ACF/PACF plots. This approach may result in overfitting and may not capture the underlying patterns in the data accurately."
  },
  {
    "objectID": "univariate_ts_model.html#forecasting-1",
    "href": "univariate_ts_model.html#forecasting-1",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "Forecasting",
    "text": "Forecasting\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexUPS Stock Price\n\n\n\n\nCode\nfit_canada &lt;- Arima(canada_ts, order=c(4,0,2), seasonal=c(0,1,0))\n\n# forecast next three years\nfit_canada %&gt;% forecast(h=12) %&gt;% autoplot(xlab = \"Date\", ylab = \"Billions\", colour = \"blue\")+ggtitle('U.S.-Canada Freight Value Forecast')+theme_bw() \n\n\n\n\n\nThe blue line represents the forecast, while the two shades of purple depict the confidence intervals, with the darker shade representing the 95% interval and the lighter shade representing the 5% interval. As the confidence interval widens, indicating greater uncertainty in the forecast, the shaded region becomes wider.\nExamining the forecast plot, there is an initial surge in the monthly U.S.-Canada freight value, followed by a subsequent decline and another increase. Comparing the observed increasing seasonal fluctuations post-2020 to the forecasted fluctuations, it appears that the model accurately predicted the anticipated pattern.\n\n\n\n\nCode\nfit_employment &lt;- Arima(employment_ts, order=c(2,1,3), seasonal=c(0,1,0))\n\n# forecast next three years\nfit_employment %&gt;% forecast(h=12) %&gt;% autoplot(xlab = \"Date\", ylab = \"Employment\", colour = \"blue\")+ggtitle('U.S. Air Transportation Employment Forecast') +theme_bw() \n\n\n\n\n\nEquation: \\(x_t= 2.8506*x_{t-1} -2.3724*x_{t-2} -0.6183*x_{t-3} -0.5218*x_{t-4} +w_t -0.9902*w_{t-1} +0.3708*w_{t-2} -0.3806*w_{t-3}\\)\nThe forecast plot illustrates a subtle decreasing trend in air transportation employment over the next 12 months. The colored bands depict the 95% confidence interval. However, the forecast appears overly smooth and lacks fluctuations. This suggests that the model may not adequately capture the inherent variability or fluctuations in the data.\n\n\n\n\nCode\nfit_tsi &lt;- Arima(tsi_ts, order=c(1,1,3), seasonal=c(0,0,0))\n\n# forecast next three years\nfit_tsi %&gt;% forecast(h=12) %&gt;% autoplot( xlab = \"Date\", ylab = \"Transportation Services Index\", colour = \"blue\")+ggtitle('U.S. Freight Transportation Services Index Forecast') +theme_bw()\n\n\n\n\n\nThe forecast plot indicates an ascending trend in the U.S. freight TSI over the ensuing 12 months. The colored bands delineate the 95% confidence interval. Nonetheless, the forecast appears excessively smooth, lacking the expected fluctuations. This suggests that the model might not adequately capture the inherent variability or fluctuations in the data.\n\n\n\n\nCode\nfit_ups &lt;- Arima(ups_ts, order=c(0,1,0), seasonal=c(0,1,0))\n\n# forecast next three years\nfit_ups %&gt;% forecast(h=50) %&gt;% autoplot( xlab = \"Date\", ylab = \"Stock Price\", colour = \"blue\")+ggtitle('UPS Stock Price Forecast') +theme_bw()\n\n\n\n\n\nThe forecast plot depicts a rising trend in the UPS stock price over the next 50 days. The colored bands represent the 95% confidence interval. Notably, it closely follows the fluctuation pattern observed in the historical data. This alignment suggests that the model may effectively capture the inherent variability and fluctuations present in the stock price data."
  },
  {
    "objectID": "univariate_ts_model.html#sarima-vs.-benchmark-methods",
    "href": "univariate_ts_model.html#sarima-vs.-benchmark-methods",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "SARIMA vs. Benchmark Methods",
    "text": "SARIMA vs. Benchmark Methods\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexUPS Stock Price\n\n\n\n\nCode\nautoplot(canada_ts, xlab = \"Date\", ylab = \"Billions\") +\n  autolayer(meanf(canada_ts, h=12),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(canada_ts, h=12),\n            series=\"Naïve\", PI=FALSE)+\n  autolayer(snaive(canada_ts, h=12),\n            series=\"SNaïve\", PI=FALSE)+\n  autolayer(rwf(canada_ts, h=12, drift=TRUE),\n            series=\"Drift\", PI=FALSE)+\n   autolayer(forecast(fit_canada,12), \n            series=\"SARIMA\",PI=FALSE) + ggtitle(\"U.S.-Canada Freight Value SARIMA vs. Benchmarks\")+\n  guides(colour=guide_legend(title=\"Forecast\")) +theme_bw()\n\n\n\n\n\nWe observe that the SARIMA model best captures the trend, closely aligning with the observed data. The SNaive methods exhibit a comparable trajectory for the forecast. In contrast, the Mean and Naive benchmark models notably underperform, failing to accurately capture the underlying trend.\n\n\nCode\n# Compute accuracy\noutput1 &lt;- accuracy(forecast(fit_canada,12))\noutput2 &lt;- accuracy(meanf(canada_ts, h=12))\noutput3 &lt;- accuracy(naive(canada_ts, h=12))\noutput4 &lt;- accuracy(snaive(canada_ts, h=12))\noutput5 &lt;- accuracy(rwf(canada_ts, drift=TRUE, h=12))\n\noutput_list &lt;- list(output1, output2, output3, output4, output5)\n\n# Put into df\noutput_df &lt;- do.call(rbind, output_list)\n\n# Set row names for the dataframe\nrow.names(output_df) &lt;- c(\"SARIMA\", \"Meanf\", \"Naive\", \"SNaive\", \"Drift\")\n\noutput_df\n\n\n                  ME     RMSE      MAE         MPE      MAPE      MASE\nSARIMA  1.593321e-01 2.958692 2.117014  0.09347661  4.440010 0.3718570\nMeanf  -1.819683e-15 7.158385 5.209884 -2.19842282 11.014570 0.9151249\nNaive   8.439239e-02 3.747662 2.676507 -0.15926651  5.543406 0.4701329\nSNaive  1.362544e+00 7.718869 5.693085  1.00899209 12.230962 1.0000000\nDrift  -2.088947e-15 3.746711 2.677095 -0.33383993  5.547840 0.4702363\n               ACF1\nSARIMA  0.005197202\nMeanf   0.855872956\nNaive  -0.270427328\nSNaive  0.902091441\nDrift  -0.270427328\n\n\nUpon examining the accuracy metrics, it’s evident that the SARIMA model achieved the lowest RMSE, MAE, and MAPE values, followed by the Drift model. This suggests that the SARIMA model outperforms the benchmark models in terms of accuracy.\n\n\n\n\nCode\nautoplot(employment_ts, xlab = \"Date\", ylab = \"Employment\") +\n  autolayer(meanf(employment_ts, h=12),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(employment_ts, h=12),\n            series=\"Naïve\", PI=FALSE)+\n  autolayer(snaive(employment_ts, h=12),\n            series=\"SNaïve\", PI=FALSE)+\n  autolayer(rwf(employment_ts, h=12, drift=TRUE),\n            series=\"Drift\", PI=FALSE)+\n   autolayer(forecast(fit_employment,12), \n            series=\"SARIMA\",PI=FALSE) + ggtitle(\"U.S. Air Transportation Employment SARIMA vs. Benchmarks\")+\n  guides(colour=guide_legend(title=\"Forecast\")) +theme_bw()\n\n\n\n\n\nWe observe that the SARIMA model best captures the trend, closely aligning with the observed data. The SNaive methods exhibit a comparable trajectory for the forecast. In contrast, the Mean benchmark model notably underperform, failing to accurately capture the underlying trend.\n\n\nCode\n# Compute accuracy\noutput1 &lt;- accuracy(forecast(fit_employment,12))\noutput2 &lt;- accuracy(meanf(employment_ts, h=12))\noutput3 &lt;- accuracy(naive(employment_ts, h=12))\noutput4 &lt;- accuracy(snaive(employment_ts, h=12))\noutput5 &lt;- accuracy(rwf(employment_ts, drift=TRUE, h=12))\n\noutput_list &lt;- list(output1, output2, output3, output4, output5)\n\n# Put into df\noutput_df &lt;- do.call(rbind, output_list)\n\n# Set row names for the dataframe\nrow.names(output_df) &lt;- c(\"SARIMA\", \"Meanf\", \"Naive\", \"SNaive\", \"Drift\")\n\noutput_df\n\n\n                  ME      RMSE       MAE          MPE      MAPE      MASE\nSARIMA -4.505618e+01  7941.374  3598.365 -0.004728991 0.7711819 0.1865997\nMeanf  -2.235212e-11 25101.751 21628.241 -0.286790486 4.5989461 1.1215716\nNaive  -8.421053e+01  7028.726  3175.439 -0.029090287 0.6871776 0.1646681\nSNaive  0.000000e+00 28713.604 19283.871 -0.196309220 4.1647999 1.0000000\nDrift  -4.059817e-12  7028.221  3184.303 -0.011323704 0.6889589 0.1651278\n              ACF1\nSARIMA -0.01374762\nMeanf   0.95752164\nNaive   0.37633324\nSNaive  0.93334964\nDrift   0.37633324\n\n\nUpon examining the accuracy metrics, it’s evident that the Naive and drift model achieved the lowest RMSE, MAE, and MAPE values, followed by the SARIMA model. This suggests that the SARIMA model did not outperforms the benchmark models in terms of accuracy.\n\n\n\n\nCode\nautoplot(tsi_ts, xlab = \"Date\", ylab = \"Transportation Services Index\") +\n  autolayer(meanf(tsi_ts, h=12),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(tsi_ts, h=12),\n            series=\"Naïve\", PI=FALSE)+\n  autolayer(snaive(tsi_ts, h=12),\n            series=\"SNaïve\", PI=FALSE)+\n  autolayer(rwf(tsi_ts, h=12, drift=TRUE),\n            series=\"Drift\", PI=FALSE)+\n   autolayer(forecast(fit_tsi,12), \n            series=\"SARIMA\",PI=FALSE) + ggtitle(\"U.S. Freight Transportation Services Index SARIMA vs. Benchmarks\")+\n  guides(colour=guide_legend(title=\"Forecast\")) +theme_bw()\n\n\n\n\n\nWe observe that the SARIMA model best captures the trend, closely aligning with the observed data. The SNaive methods exhibit a comparable trajectory for the forecast. In contrast, the Mean and Naive benchmark models notably underperform, failing to accurately capture the underlying trend.\n\n\nCode\n# Compute accuracy\noutput1 &lt;- accuracy(forecast(fit_tsi,12))\noutput2 &lt;- accuracy(meanf(tsi_ts, h=12))\noutput3 &lt;- accuracy(naive(tsi_ts, h=12))\noutput4 &lt;- accuracy(snaive(tsi_ts, h=12))\noutput5 &lt;- accuracy(rwf(tsi_ts, drift=TRUE, h=12))\n\noutput_list &lt;- list(output1, output2, output3, output4, output5)\n\n# Put into df\noutput_df &lt;- do.call(rbind, output_list)\n\n# Set row names for the dataframe\nrow.names(output_df) &lt;- c(\"SARIMA\", \"Meanf\", \"Naive\", \"SNaive\", \"Drift\")\n\noutput_df\n\n\n                  ME      RMSE       MAE         MPE      MAPE      MASE\nSARIMA  9.533649e-02  1.474058  1.070741  0.07317726 0.9278111 0.2640729\nMeanf  -1.056836e-14 13.009848 11.112711 -1.22065210 9.5135777 2.7406872\nNaive   1.141304e-01  1.500374  1.096014  0.08659501 0.9496963 0.2703060\nSNaive  1.778491e+00  5.242155  4.054717  1.39387516 3.5019130 1.0000000\nDrift   2.500415e-15  1.496027  1.087839 -0.01244364 0.9430018 0.2682897\n               ACF1\nSARIMA -0.002323126\nMeanf   0.987698495\nNaive  -0.064131500\nSNaive  0.889680535\nDrift  -0.064131500\n\n\nUpon examining the accuracy metrics, it’s evident that the SARIMA model achieved the lowest RMSE, MAE, and MAPE values, followed by the Drift model. This suggests that the SARIMA model outperforms the benchmark models in terms of accuracy.\n\n\n\n\nCode\nautoplot(ups_ts, xlab = \"Date\", ylab = \"Stock Price\") +\n  autolayer(meanf(ups_ts, h=50),\n            series=\"Mean\", PI=FALSE) +\n  autolayer(naive(ups_ts, h=50),\n            series=\"Naïve\", PI=FALSE)+\n  autolayer(snaive(ups_ts, h=50),\n            series=\"SNaïve\", PI=FALSE)+\n  autolayer(rwf(ups_ts, h=50, drift=TRUE),\n            series=\"Drift\", PI=FALSE)+\n   autolayer(forecast(fit_ups,50), \n            series=\"SARIMA\",PI=FALSE) + ggtitle(\"UPS Stock Price SARIMA vs. Benchmarks\")+\n  guides(colour=guide_legend(title=\"Forecast\")) +theme_bw()\n\n\n\n\n\nWe observe that the SARIMA model best captures the trend, closely aligning with the observed data. The SNaive methods exhibit a comparable trajectory for the forecast. In contrast, the Mean and Naive benchmark models notably underperform, failing to accurately capture the underlying trend.\n\n\nCode\n# Compute accuracy\noutput1 &lt;- accuracy(pred_ups)\noutput2 &lt;- accuracy(meanf(ups_ts, h=50))\noutput3 &lt;- accuracy(naive(ups_ts, h=50))\noutput4 &lt;- accuracy(snaive(ups_ts, h=50))\n\n\nWarning in lag.default(y, -lag): 'k' is not an integer\n\n\nCode\noutput5 &lt;- accuracy(rwf(ups_ts, drift=TRUE, h=50))\n\noutput_list &lt;- list(output1, output2, output3, output4, output5)\n\n# Put into df\noutput_df &lt;- do.call(rbind, output_list)\n\n# Set row names for the dataframe\nrow.names(output_df) &lt;- c(\"SARIMA\", \"Meanf\", \"Naive\", \"SNaive\", \"Drift\")\n\noutput_df\n\n\n                 ME      RMSE       MAE          MPE      MAPE       MASE\nSARIMA 5.173999e-05  2.336454  1.513771  -0.01543306  1.161839 0.04821099\nMeanf  1.080126e-12 40.426672 38.180110 -10.12057135 31.863701 1.21597050\nNaive  3.660449e-02  2.337403  1.515062   0.01546450  1.162754 0.04825209\nSNaive 2.000856e+01 42.830676 31.480383  11.47406484 20.258650 1.00259579\nDrift  5.107578e-15  2.337117  1.514580  -0.01549867  1.162442 0.04823675\n             ACF1\nSARIMA 0.03201837\nMeanf  0.99795274\nNaive  0.03201852\nSNaive 0.99551309\nDrift  0.03201852\n\n\nUpon examining the accuracy metrics, it’s evident that the SARIMA model achieved the lowest RMSE, MAE, and MAPE values, followed by the Drift model. This suggests that the ARIMA model outperforms the benchmark models in terms of accuracy."
  },
  {
    "objectID": "univariate_ts_model.html#cross-validation",
    "href": "univariate_ts_model.html#cross-validation",
    "title": "Univariate TS Models (ARIMA/SARIMA)",
    "section": "Cross Validation",
    "text": "Cross Validation\n\nU.S.-Canada Freight ValueU.S. Air Transportation EmploymentU.S. Freight Transportation Services IndexUPS Stock Price\n\n\n\n\nCode\n#a seasonal cross validation using 1 steps ahead forecasts\nfarima1 &lt;- function(x, h){forecast(Arima(x, order=c(4,0,2),seasonal = c(0,1,0)),h=h)}\n\n# Compute cross-validated errors for up to 1 steps ahead\ne1 &lt;- tsCV(canada_ts, forecastfunction = farima1, h = 1)\nmae1 &lt;-abs(mean(e1,na.rm=TRUE))\nrmse1=sqrt(mean(e1^2, na.rm=TRUE)) #one-step time series cross-validation\ncat(\"1-Step Forecast MAE:\", mae1, \"\\n\")\n\n\n1-Step Forecast MAE: 0.1707379 \n\n\nCode\ncat(\"1-Step Forecast RMSE:\", rmse1, \"\\n\")\n\n\n1-Step Forecast RMSE: 3.525084 \n\n\nCode\n# Compute cross-validated errors for up to 12 steps ahead\ne &lt;- tsCV(canada_ts, forecastfunction = farima1, h = 12)\n\n# Compute the AME and RMSE values\nmae &lt;-abs(mean(e,na.rm=TRUE))\nrmse &lt;-sqrt(mean(e^2, na.rm=TRUE)) #s-step time series cross-validation\ncat(\"S-Step Forecast MAE:\", mae, \"\\n\")\n\n\nS-Step Forecast MAE: 0.6267446 \n\n\nCode\ncat(\"S-Step Forecast RMSE:\", rmse, \"\\n\")\n\n\nS-Step Forecast RMSE: 7.491664 \n\n\n\n\n\n\nCode\n#a seasonal cross validation using 1 steps ahead forecasts\nfarima1 &lt;- function(x, h){forecast(Arima(x, order=c(2,1,3),seasonal = c(0,1,0)),h=h)}\n\n# Compute cross-validated errors for up to 1 steps ahead\ne1 &lt;- tsCV(employment_ts, forecastfunction = farima1, h = 1)\nmae1 &lt;-abs(mean(e1,na.rm=TRUE))\nrmse1=sqrt(mean(e1^2, na.rm=TRUE)) #one-step time series cross-validation\ncat(\"1-Step Forecast MAE:\", mae1, \"\\n\")\n\n\n1-Step Forecast MAE: 262.7295 \n\n\nCode\ncat(\"1-Step Forecast RMSE:\", rmse1, \"\\n\")\n\n\n1-Step Forecast RMSE: 9779.526 \n\n\nCode\n# Compute cross-validated errors for up to 12 steps ahead\ne &lt;- tsCV(employment_ts, forecastfunction = farima1, h = 12)\n\n# Compute the AME and RMSE values\nmae &lt;-abs(mean(e,na.rm=TRUE))\nrmse &lt;-sqrt(mean(e^2, na.rm=TRUE)) #s-step time series cross-validation\ncat(\"S-Step Forecast MAE:\", mae, \"\\n\")\n\n\nS-Step Forecast MAE: 940.5674 \n\n\nCode\ncat(\"S-Step Forecast RMSE:\", rmse, \"\\n\")\n\n\nS-Step Forecast RMSE: 33433.24 \n\n\n\n\n\n\nCode\n#a seasonal cross validation using 1 steps ahead forecasts\nfarima1 &lt;- function(x, h){forecast(Arima(x, order=c(1,1,3),seasonal = c(0,0,0)),h=h)}\n\n# Compute cross-validated errors for up to 1 steps ahead\ne1 &lt;- tsCV(tsi_ts, forecastfunction = farima1, h = 1)\nmae1 &lt;-abs(mean(e1,na.rm=TRUE))\nrmse1=sqrt(mean(e1^2, na.rm=TRUE)) #one-step time series cross-validation\ncat(\"1-Step Forecast MAE:\", mae1, \"\\n\")\n\n\n1-Step Forecast MAE: 0.1098334 \n\n\nCode\ncat(\"1-Step Forecast RMSE:\", rmse1, \"\\n\")\n\n\n1-Step Forecast RMSE: 1.548448 \n\n\nCode\n# Compute cross-validated errors for up to 12 steps ahead\ne &lt;- tsCV(tsi_ts, forecastfunction = farima1, h = 12)\n\n# Compute the AME and RMSE values\nmae &lt;-abs(mean(e,na.rm=TRUE))\nrmse &lt;-sqrt(mean(e^2, na.rm=TRUE)) #s-step time series cross-validation\ncat(\"S-Step Forecast MAE:\", mae, \"\\n\")\n\n\nS-Step Forecast MAE: 0.8662205 \n\n\nCode\ncat(\"S-Step Forecast RMSE:\", rmse, \"\\n\")\n\n\nS-Step Forecast RMSE: 3.856692 \n\n\n\n\n#```{r} #| warning: false #a seasonal cross validation using 1 steps ahead forecasts farima1 &lt;- function(x, h){forecast(Arima(x, order=c(0,1,0),seasonal = c(0,1,0)),h=h)}\n\nCompute cross-validated errors for up to 1 steps ahead\ne1 &lt;- tsCV(ups_ts, forecastfunction = farima1, h = 1) mae1 &lt;-abs(mean(e1,na.rm=TRUE)) rmse1=sqrt(mean(e1^2, na.rm=TRUE)) #one-step time series cross-validation cat(“1-Step Forecast MAE:”, mae1, “”) cat(“1-Step Forecast RMSE:”, rmse1, “”)\n\n\nCompute cross-validated errors for up to 365 steps ahead\ne &lt;- tsCV(ups_ts, forecastfunction = farima1, h = 365)\n\n\nCompute the AME and RMSE values\nmae &lt;-abs(mean(e,na.rm=TRUE)) rmse &lt;-sqrt(mean(e^2, na.rm=TRUE)) #s-step time series cross-validation cat(“S-Step Forecast MAE:”, mae, “”) cat(“S-Step Forecast RMSE:”, rmse, “”)\n```"
  }
]